{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time\n",
    "import sklearn, sklearn.metrics\n",
    "\n",
    "w2v_size = 9000\n",
    "w2v_file = '../DataSets/Quora/w2v_res_180119.pickle'\n",
    "train_file = '../DataSets/Quora/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242506\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(w2v_file, 'rb') as f:\n",
    "    (full_dict, full_sentences, full_w2v) = pickle.load(f)\n",
    "    \n",
    "full_data = pd.read_csv(train_file)\n",
    "print(len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "default_if_na = full_w2v[-1]\n",
    "full_res = [[full_w2v[i] for i in s if i+1 < w2v_size] for s in full_sentences]\n",
    "full_res = np.array([np.mean(s, axis=0) if len(s) > 0 else default_if_na for s in full_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_features(s1, s2, vocab_size=1000):\n",
    "    st1 = set(x for x in s1 if x > vocab_size)\n",
    "    st2 = set(x for x in s2 if x > vocab_size)\n",
    "    nAB = len(set.intersection(st1, st2))\n",
    "    nAUB = len(set.union(st1, st2))\n",
    "    rAB = nAB / nAUB if nAUB > 0 else 0\n",
    "    return np.array([nAB, nAUB, rAB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full1 = full_sentences[:(len(full_sentences)//2)]\n",
    "full2 = full_sentences[(len(full_sentences)//2):]\n",
    "f0 = np.array([calc_features(full1[i], full2[i]) for i in range(len(full1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = full_res[:(len(full_res)//2)]\n",
    "p2 = full_res[(len(full_res)//2):]\n",
    "f1 = p1 * p2\n",
    "f2 = np.square(p1-2)\n",
    "f3 = 0.5*(p1 + p2)\n",
    "fX = np.hstack([f1,f2,f3,f0])\n",
    "fY = full_data.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y), (valid_X, valid_Y) = modutils.splitSample((fX, fY), pcts=[0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tf_in_x = tf.placeholder(tf.float32, shape=(None, valid_X.shape[1]))\n",
    "tf_in_y = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "tf_logit = tf.layers.dense(tf_in_x, 2)\n",
    "tf_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf_in_y, logits=tf_logit))\n",
    "tf_train = tf.train.AdamOptimizer(1e-2).minimize(tf_loss)\n",
    "\n",
    "tf_prob = tf.nn.softmax(tf_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536 -> 0.535\n",
      "Epoch 0: 0.662 -> 0.541 in 10.77 sec, gini=0.544, accur=0.709\n",
      "0.598 -> 0.543\n",
      "Epoch 1: 0.541 -> 0.531 in 10.38 sec, gini=0.570, accur=0.714\n",
      "0.501 -> 0.500\n",
      "Epoch 2: 0.531 -> 0.525 in 10.48 sec, gini=0.582, accur=0.719\n",
      "0.528 -> 0.526\n",
      "Epoch 3: 0.525 -> 0.518 in 10.49 sec, gini=0.591, accur=0.725\n",
      "0.535 -> 0.566\n",
      "Epoch 4: 0.518 -> 0.553 in 10.14 sec, gini=0.597, accur=0.693\n",
      "0.557 -> 0.526\n",
      "Epoch 5: 0.553 -> 0.513 in 10.43 sec, gini=0.601, accur=0.728\n",
      "0.542 -> 0.549\n",
      "Epoch 6: 0.513 -> 0.524 in 10.39 sec, gini=0.605, accur=0.723\n",
      "0.531 -> 0.519\n",
      "Epoch 7: 0.524 -> 0.512 in 10.33 sec, gini=0.608, accur=0.731\n",
      "0.502 -> 0.515\n",
      "Epoch 8: 0.512 -> 0.528 in 10.36 sec, gini=0.611, accur=0.720\n",
      "0.495 -> 0.496\n",
      "Epoch 9: 0.528 -> 0.509 in 9.71 sec, gini=0.612, accur=0.732\n",
      "0.533 -> 0.551\n",
      "Epoch 10: 0.509 -> 0.542 in 10.21 sec, gini=0.614, accur=0.703\n",
      "0.505 -> 0.503\n",
      "Epoch 11: 0.542 -> 0.510 in 10.38 sec, gini=0.616, accur=0.729\n",
      "0.513 -> 0.507\n",
      "Epoch 12: 0.510 -> 0.514 in 10.40 sec, gini=0.618, accur=0.726\n",
      "0.493 -> 0.510\n",
      "Epoch 13: 0.514 -> 0.519 in 10.35 sec, gini=0.620, accur=0.721\n",
      "0.501 -> 0.499\n",
      "Epoch 14: 0.519 -> 0.508 in 10.37 sec, gini=0.620, accur=0.732\n",
      "0.509 -> 0.507\n",
      "Epoch 15: 0.508 -> 0.504 in 10.39 sec, gini=0.621, accur=0.734\n",
      "0.510 -> 0.501\n",
      "Epoch 16: 0.504 -> 0.504 in 10.36 sec, gini=0.622, accur=0.736\n",
      "0.501 -> 0.481\n",
      "Epoch 17: 0.504 -> 0.503 in 10.15 sec, gini=0.624, accur=0.736\n",
      "0.489 -> 0.485\n",
      "Epoch 18: 0.503 -> 0.501 in 9.65 sec, gini=0.624, accur=0.739\n",
      "0.517 -> 0.500\n",
      "Epoch 19: 0.501 -> 0.511 in 10.18 sec, gini=0.625, accur=0.734\n",
      "0.503 -> 0.502\n",
      "Epoch 20: 0.511 -> 0.502 in 10.36 sec, gini=0.626, accur=0.737\n",
      "0.528 -> 0.511\n",
      "Epoch 21: 0.502 -> 0.522 in 10.33 sec, gini=0.627, accur=0.727\n",
      "0.531 -> 0.518\n",
      "Epoch 22: 0.522 -> 0.500 in 10.37 sec, gini=0.627, accur=0.740\n",
      "0.502 -> 0.549\n",
      "Epoch 23: 0.500 -> 0.558 in 10.41 sec, gini=0.629, accur=0.705\n",
      "0.516 -> 0.512\n",
      "Epoch 24: 0.558 -> 0.499 in 10.39 sec, gini=0.628, accur=0.740\n",
      "0.534 -> 0.542\n",
      "Epoch 25: 0.499 -> 0.536 in 10.33 sec, gini=0.630, accur=0.718\n",
      "0.540 -> 0.522\n",
      "Epoch 26: 0.536 -> 0.514 in 10.35 sec, gini=0.631, accur=0.733\n",
      "0.502 -> 0.510\n",
      "Epoch 27: 0.514 -> 0.506 in 10.35 sec, gini=0.631, accur=0.733\n",
      "0.554 -> 0.524\n",
      "Epoch 28: 0.506 -> 0.517 in 10.43 sec, gini=0.632, accur=0.732\n",
      "0.518 -> 0.506\n",
      "Epoch 29: 0.517 -> 0.514 in 10.63 sec, gini=0.632, accur=0.725\n",
      "0.508 -> 0.504\n",
      "Epoch 30: 0.514 -> 0.505 in 9.98 sec, gini=0.633, accur=0.738\n",
      "0.536 -> 0.506\n",
      "Epoch 31: 0.505 -> 0.496 in 10.27 sec, gini=0.633, accur=0.742\n",
      "0.502 -> 0.604\n",
      "Epoch 32: 0.496 -> 0.616 in 10.38 sec, gini=0.634, accur=0.672\n",
      "0.507 -> 0.483\n",
      "Epoch 33: 0.616 -> 0.500 in 10.33 sec, gini=0.633, accur=0.741\n",
      "0.522 -> 0.560\n",
      "Epoch 34: 0.500 -> 0.557 in 10.45 sec, gini=0.635, accur=0.708\n",
      "0.488 -> 0.503\n",
      "Epoch 35: 0.557 -> 0.515 in 10.30 sec, gini=0.635, accur=0.724\n",
      "0.548 -> 0.528\n",
      "Epoch 36: 0.515 -> 0.516 in 10.32 sec, gini=0.635, accur=0.731\n",
      "0.544 -> 0.511\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-ec3501458205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtl0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mtf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mtl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{0:.3f} -> {1:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtl0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \"\"\"\n\u001b[1;32m-> 1706\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3961\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3963\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "num_steps  = 5\n",
    "batch_size = 2048\n",
    "valid_dict = {tf_in_x: valid_X, tf_in_y: valid_Y}\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for n in range(num_epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        l0 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        for tX, tY in modutils.shuffleBatches((train_X, train_Y), batchSize=batch_size):\n",
    "            train_dict = {tf_in_x: tX, tf_in_y: tY}\n",
    "            tl0 = tf_loss.eval(feed_dict=train_dict)\n",
    "            for i in range(num_steps):\n",
    "                tf_train.run(feed_dict=train_dict)\n",
    "            tl1 = tf_loss.eval(feed_dict=train_dict)\n",
    "            print('{0:.3f} -> {1:.3f}'.format(tl0, tl1), end='\\r')\n",
    "\n",
    "        valid_p = tf_prob.eval(feed_dict=valid_dict)\n",
    "        gini = sklearn.metrics.roc_auc_score(valid_Y, valid_p[:,1])*2-1\n",
    "        accur = sklearn.metrics.accuracy_score(valid_Y, 1*(valid_p[:,1]>0.5))\n",
    "        l1 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        print('\\nEpoch {0}: {1:.3f} -> {2:.3f} in {3:.2f} sec, gini={4:.3f}, accur={5:.3f}'.format(n, l0, l1, t1-t0, gini, accur))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
