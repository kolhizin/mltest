{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib\n",
    "import tensorflow.contrib.rnn\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObs(length):\n",
    "    return np.random.choice(range(3), size=length)\n",
    "\n",
    "#very simple -- gru-rnn with 5 neurons cracks it\n",
    "#def genTarget(x):\n",
    "#    return ''.join([str(z) for z in x]).find('012')\n",
    "\n",
    "def genTarget(x):\n",
    "    y0 = ''.join([str(z) for z in x])\n",
    "    return y0.count(y0[:2])\n",
    "\n",
    "def genSample(num, length=20):\n",
    "    x = [genObs(length=length) for _ in range(num)]\n",
    "    y = [genTarget(t) for t in x]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def randomBatch(tensorTuple, batchSize=64):\n",
    "    ids = np.random.choice(range(tensorTuple[0].shape[0]), batchSize)\n",
    "    return (x[ids,] for x in tensorTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2],\n",
       "        [0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 1, 1],\n",
       "        [1, 2, 0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0],\n",
       "        [0, 0, 0, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 2],\n",
       "        [0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 1, 0, 2, 2],\n",
       "        [2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1, 0, 1, 2, 2, 2],\n",
       "        [0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2],\n",
       "        [2, 0, 1, 0, 0, 0, 0, 2, 2, 1, 2, 0, 1, 0, 0, 2, 0, 2, 0, 1],\n",
       "        [1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0],\n",
       "        [0, 1, 1, 0, 2, 0, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 0, 1, 2]]),\n",
       " array([2, 2, 5, 2, 3, 2, 2, 4, 3, 6]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = genSample(20000)\n",
    "valid_x, valid_y = genSample(2000)\n",
    "valid_x[:10], valid_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "RNN_SIZE = [10]\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.elu)\n",
    "#InnerCell = lambda n: tf.contrib.rnn.GRUCell(num_units=n, activation=tf.nn.elu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.float32)\n",
    "tfi_y = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "\n",
    "tfX = tf.reshape(tfi_x, shape=(tf.shape(tfi_x)[0], tf.shape(tfi_x)[1], 1))\n",
    "tfY = tf.reshape(tfi_y, shape=(tf.shape(tfi_y)[0], 1))\n",
    "\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE])\n",
    "#rnnCell = tf.contrib.rnn.MultiRNNCell([InnerCell(s) for s in RNN_SIZE])\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0])\n",
    "\n",
    "_, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfOut = tf.layers.dense(tfO[-1], 1)\n",
    "\n",
    "tfLoss = tf.sqrt(tf.reduce_mean(tf.square(tfY - tfOut)))\n",
    "tfTrain = tf.train.AdamOptimizer(1e-3).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.cast(tf.round(tfOut),dtype=tf.int64)\n",
    "\n",
    "tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tfY, dtype=tf.int64), tf.cast(tf.round(tfOut),dtype=tf.int64)), dtype=tf.float32))\n",
    "\n",
    "tfsumRMSE = tf.summary.scalar('RMSE', tfLoss)\n",
    "tfsumAccuracy = tf.summary.scalar('Accuracy', 1-tfAccuracy)\n",
    "tfsumAll = tf.summary.merge([tfsumRMSE, tfsumAccuracy])\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.463 sec): loss changed from 2.81 to 2.09\t\tVL:2.073\t\tAC:0.135\n",
      "Epoch 10 (0.452 sec): loss changed from 1.1 to 1.1\t\tVL:1.141\t\tAC:0.312\n",
      "Epoch 20 (0.451 sec): loss changed from 1.12 to 1.12\t\tVL:1.117\t\tAC:0.320\n",
      "Epoch 30 (0.446 sec): loss changed from 1.12 to 1.12\t\tVL:1.113\t\tAC:0.322\n",
      "Epoch 40 (0.45 sec): loss changed from 1.18 to 1.17\t\tVL:1.104\t\tAC:0.322\n",
      "Epoch 50 (0.426 sec): loss changed from 1.1 to 1.08\t\tVL:1.061\t\tAC:0.336\n",
      "Epoch 60 (0.426 sec): loss changed from 1.08 to 1.06\t\tVL:1.016\t\tAC:0.363\n",
      "Epoch 70 (0.462 sec): loss changed from 1.02 to 0.991\t\tVL:0.996\t\tAC:0.379\n",
      "Epoch 80 (0.459 sec): loss changed from 0.956 to 0.936\t\tVL:0.977\t\tAC:0.377\n",
      "Epoch 90 (0.449 sec): loss changed from 0.938 to 0.92\t\tVL:0.964\t\tAC:0.387\n",
      "Epoch 100 (0.474 sec): loss changed from 0.919 to 0.909\t\tVL:0.949\t\tAC:0.399\n",
      "Epoch 110 (0.442 sec): loss changed from 0.954 to 0.932\t\tVL:0.938\t\tAC:0.388\n",
      "Epoch 120 (0.426 sec): loss changed from 0.914 to 0.894\t\tVL:0.926\t\tAC:0.398\n",
      "Epoch 130 (0.426 sec): loss changed from 0.915 to 0.899\t\tVL:0.906\t\tAC:0.416\n",
      "Epoch 140 (0.444 sec): loss changed from 0.868 to 0.845\t\tVL:0.887\t\tAC:0.415\n",
      "Epoch 150 (0.47 sec): loss changed from 0.881 to 0.855\t\tVL:0.865\t\tAC:0.438\n",
      "Epoch 160 (0.431 sec): loss changed from 0.792 to 0.769\t\tVL:0.849\t\tAC:0.445\n",
      "Epoch 170 (0.445 sec): loss changed from 0.812 to 0.788\t\tVL:0.829\t\tAC:0.456\n",
      "Epoch 180 (0.449 sec): loss changed from 0.79 to 0.768\t\tVL:0.773\t\tAC:0.491\n",
      "Epoch 190 (0.433 sec): loss changed from 0.725 to 0.7\t\tVL:0.748\t\tAC:0.500\n",
      "Epoch 200 (0.451 sec): loss changed from 0.723 to 0.702\t\tVL:0.728\t\tAC:0.511\n",
      "Epoch 210 (0.461 sec): loss changed from 0.707 to 0.683\t\tVL:0.720\t\tAC:0.523\n",
      "Epoch 220 (0.507 sec): loss changed from 0.718 to 0.695\t\tVL:0.705\t\tAC:0.524\n",
      "Epoch 230 (0.522 sec): loss changed from 0.66 to 0.64\t\tVL:0.693\t\tAC:0.531\n",
      "Epoch 240 (0.466 sec): loss changed from 0.706 to 0.675\t\tVL:0.691\t\tAC:0.531\n",
      "Epoch 250 (0.447 sec): loss changed from 0.646 to 0.62\t\tVL:0.673\t\tAC:0.545\n",
      "Epoch 260 (0.455 sec): loss changed from 0.677 to 0.651\t\tVL:0.662\t\tAC:0.545\n",
      "Epoch 270 (0.441 sec): loss changed from 0.649 to 0.63\t\tVL:0.646\t\tAC:0.563\n",
      "Epoch 280 (0.446 sec): loss changed from 0.631 to 0.61\t\tVL:0.641\t\tAC:0.569\n",
      "Epoch 290 (0.509 sec): loss changed from 0.609 to 0.585\t\tVL:0.638\t\tAC:0.582\n",
      "Epoch 300 (0.424 sec): loss changed from 0.634 to 0.61\t\tVL:0.625\t\tAC:0.574\n",
      "Epoch 310 (0.423 sec): loss changed from 0.595 to 0.576\t\tVL:0.608\t\tAC:0.589\n",
      "Epoch 320 (0.449 sec): loss changed from 0.614 to 0.597\t\tVL:0.599\t\tAC:0.599\n",
      "Epoch 330 (0.43 sec): loss changed from 0.604 to 0.575\t\tVL:0.591\t\tAC:0.612\n",
      "Epoch 340 (0.434 sec): loss changed from 0.561 to 0.541\t\tVL:0.577\t\tAC:0.625\n",
      "Epoch 350 (0.414 sec): loss changed from 0.56 to 0.542\t\tVL:0.564\t\tAC:0.630\n",
      "Epoch 360 (0.443 sec): loss changed from 0.556 to 0.533\t\tVL:0.547\t\tAC:0.637\n",
      "Epoch 370 (0.429 sec): loss changed from 0.522 to 0.493\t\tVL:0.551\t\tAC:0.643\n",
      "Epoch 380 (0.453 sec): loss changed from 0.528 to 0.507\t\tVL:0.536\t\tAC:0.655\n",
      "Epoch 390 (0.439 sec): loss changed from 0.496 to 0.471\t\tVL:0.518\t\tAC:0.678\n",
      "Epoch 400 (0.439 sec): loss changed from 0.518 to 0.502\t\tVL:0.509\t\tAC:0.687\n",
      "Epoch 410 (0.432 sec): loss changed from 0.491 to 0.465\t\tVL:0.499\t\tAC:0.700\n",
      "Epoch 420 (0.528 sec): loss changed from 0.5 to 0.473\t\tVL:0.489\t\tAC:0.710\n",
      "Epoch 430 (0.442 sec): loss changed from 0.463 to 0.448\t\tVL:0.474\t\tAC:0.722\n",
      "Epoch 440 (0.503 sec): loss changed from 0.454 to 0.428\t\tVL:0.473\t\tAC:0.726\n",
      "Epoch 450 (0.448 sec): loss changed from 0.449 to 0.434\t\tVL:0.457\t\tAC:0.743\n",
      "Epoch 460 (0.441 sec): loss changed from 0.457 to 0.431\t\tVL:0.457\t\tAC:0.740\n",
      "Epoch 470 (0.465 sec): loss changed from 0.443 to 0.425\t\tVL:0.448\t\tAC:0.748\n",
      "Epoch 480 (0.449 sec): loss changed from 0.433 to 0.412\t\tVL:0.441\t\tAC:0.749\n",
      "Epoch 490 (0.424 sec): loss changed from 0.407 to 0.394\t\tVL:0.436\t\tAC:0.757\n",
      "Epoch 500 (0.472 sec): loss changed from 0.43 to 0.414\t\tVL:0.427\t\tAC:0.773\n",
      "Epoch 510 (0.46 sec): loss changed from 0.422 to 0.403\t\tVL:0.427\t\tAC:0.771\n",
      "Epoch 520 (0.443 sec): loss changed from 0.427 to 0.411\t\tVL:0.426\t\tAC:0.760\n",
      "Epoch 530 (0.467 sec): loss changed from 0.415 to 0.398\t\tVL:0.417\t\tAC:0.774\n",
      "Epoch 540 (0.431 sec): loss changed from 0.417 to 0.391\t\tVL:0.411\t\tAC:0.785\n",
      "Epoch 550 (0.443 sec): loss changed from 0.391 to 0.368\t\tVL:0.410\t\tAC:0.783\n",
      "Epoch 560 (0.451 sec): loss changed from 0.38 to 0.36\t\tVL:0.402\t\tAC:0.794\n",
      "Epoch 570 (0.457 sec): loss changed from 0.388 to 0.37\t\tVL:0.395\t\tAC:0.800\n",
      "Epoch 580 (0.414 sec): loss changed from 0.392 to 0.375\t\tVL:0.391\t\tAC:0.807\n",
      "Epoch 590 (0.439 sec): loss changed from 0.382 to 0.363\t\tVL:0.389\t\tAC:0.817\n",
      "Epoch 600 (0.416 sec): loss changed from 0.391 to 0.367\t\tVL:0.384\t\tAC:0.808\n",
      "Epoch 610 (0.438 sec): loss changed from 0.364 to 0.344\t\tVL:0.381\t\tAC:0.820\n",
      "Epoch 620 (0.452 sec): loss changed from 0.373 to 0.349\t\tVL:0.374\t\tAC:0.820\n",
      "Epoch 630 (0.51 sec): loss changed from 0.367 to 0.341\t\tVL:0.373\t\tAC:0.826\n",
      "Epoch 640 (0.533 sec): loss changed from 0.344 to 0.328\t\tVL:0.367\t\tAC:0.830\n",
      "Epoch 650 (0.445 sec): loss changed from 0.367 to 0.343\t\tVL:0.360\t\tAC:0.839\n",
      "Epoch 660 (0.444 sec): loss changed from 0.338 to 0.323\t\tVL:0.359\t\tAC:0.845\n",
      "Epoch 670 (0.489 sec): loss changed from 0.339 to 0.325\t\tVL:0.351\t\tAC:0.849\n",
      "Epoch 680 (0.54 sec): loss changed from 0.335 to 0.317\t\tVL:0.345\t\tAC:0.858\n",
      "Epoch 690 (0.537 sec): loss changed from 0.322 to 0.301\t\tVL:0.344\t\tAC:0.860\n",
      "Epoch 700 (0.437 sec): loss changed from 0.331 to 0.314\t\tVL:0.342\t\tAC:0.858\n",
      "Epoch 710 (0.449 sec): loss changed from 0.326 to 0.31\t\tVL:0.340\t\tAC:0.867\n",
      "Epoch 720 (0.45 sec): loss changed from 0.343 to 0.327\t\tVL:0.336\t\tAC:0.869\n",
      "Epoch 730 (0.457 sec): loss changed from 0.338 to 0.316\t\tVL:0.338\t\tAC:0.873\n",
      "Epoch 740 (0.431 sec): loss changed from 0.303 to 0.291\t\tVL:0.331\t\tAC:0.868\n",
      "Epoch 750 (0.427 sec): loss changed from 0.317 to 0.3\t\tVL:0.329\t\tAC:0.870\n",
      "Epoch 760 (0.461 sec): loss changed from 0.313 to 0.294\t\tVL:0.325\t\tAC:0.878\n",
      "Epoch 770 (0.421 sec): loss changed from 0.319 to 0.304\t\tVL:0.324\t\tAC:0.878\n",
      "Epoch 780 (0.442 sec): loss changed from 0.315 to 0.299\t\tVL:0.325\t\tAC:0.876\n",
      "Epoch 790 (0.432 sec): loss changed from 0.314 to 0.294\t\tVL:0.318\t\tAC:0.886\n",
      "Epoch 800 (0.411 sec): loss changed from 0.304 to 0.289\t\tVL:0.320\t\tAC:0.885\n",
      "Epoch 810 (0.461 sec): loss changed from 0.306 to 0.291\t\tVL:0.320\t\tAC:0.886\n",
      "Epoch 820 (0.434 sec): loss changed from 0.309 to 0.297\t\tVL:0.312\t\tAC:0.888\n",
      "Epoch 830 (0.483 sec): loss changed from 0.311 to 0.293\t\tVL:0.314\t\tAC:0.892\n",
      "Epoch 840 (0.456 sec): loss changed from 0.304 to 0.291\t\tVL:0.310\t\tAC:0.891\n",
      "Epoch 850 (0.466 sec): loss changed from 0.312 to 0.294\t\tVL:0.313\t\tAC:0.886\n",
      "Epoch 860 (0.425 sec): loss changed from 0.312 to 0.294\t\tVL:0.307\t\tAC:0.897\n",
      "Epoch 870 (0.53 sec): loss changed from 0.307 to 0.288\t\tVL:0.306\t\tAC:0.896\n",
      "Epoch 880 (0.449 sec): loss changed from 0.308 to 0.283\t\tVL:0.303\t\tAC:0.897\n",
      "Epoch 890 (0.466 sec): loss changed from 0.287 to 0.276\t\tVL:0.305\t\tAC:0.897\n",
      "Epoch 900 (0.458 sec): loss changed from 0.297 to 0.282\t\tVL:0.297\t\tAC:0.902\n",
      "Epoch 910 (0.44 sec): loss changed from 0.301 to 0.28\t\tVL:0.301\t\tAC:0.902\n",
      "Epoch 920 (0.435 sec): loss changed from 0.304 to 0.291\t\tVL:0.297\t\tAC:0.904\n",
      "Epoch 930 (0.415 sec): loss changed from 0.313 to 0.293\t\tVL:0.299\t\tAC:0.905\n",
      "Epoch 940 (0.424 sec): loss changed from 0.287 to 0.269\t\tVL:0.298\t\tAC:0.905\n",
      "Epoch 950 (0.437 sec): loss changed from 0.275 to 0.26\t\tVL:0.291\t\tAC:0.910\n",
      "Epoch 960 (0.456 sec): loss changed from 0.282 to 0.265\t\tVL:0.294\t\tAC:0.910\n",
      "Epoch 970 (0.426 sec): loss changed from 0.278 to 0.265\t\tVL:0.287\t\tAC:0.913\n",
      "Epoch 980 (0.431 sec): loss changed from 0.298 to 0.274\t\tVL:0.285\t\tAC:0.920\n",
      "Epoch 990 (0.441 sec): loss changed from 0.286 to 0.264\t\tVL:0.285\t\tAC:0.915\n",
      "Epoch 1000 (0.43 sec): loss changed from 0.277 to 0.259\t\tVL:0.290\t\tAC:0.909\n",
      "Epoch 1010 (0.416 sec): loss changed from 0.257 to 0.246\t\tVL:0.285\t\tAC:0.915\n",
      "Epoch 1020 (0.426 sec): loss changed from 0.262 to 0.249\t\tVL:0.283\t\tAC:0.918\n",
      "Epoch 1030 (0.441 sec): loss changed from 0.273 to 0.256\t\tVL:0.277\t\tAC:0.926\n",
      "Epoch 1040 (0.413 sec): loss changed from 0.274 to 0.259\t\tVL:0.274\t\tAC:0.928\n",
      "Epoch 1050 (0.431 sec): loss changed from 0.266 to 0.25\t\tVL:0.271\t\tAC:0.930\n",
      "Epoch 1060 (0.427 sec): loss changed from 0.26 to 0.239\t\tVL:0.272\t\tAC:0.928\n",
      "Epoch 1070 (0.47 sec): loss changed from 0.267 to 0.254\t\tVL:0.266\t\tAC:0.932\n",
      "Epoch 1080 (0.47 sec): loss changed from 0.259 to 0.242\t\tVL:0.263\t\tAC:0.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1090 (0.417 sec): loss changed from 0.251 to 0.237\t\tVL:0.267\t\tAC:0.932\n",
      "Epoch 1100 (0.451 sec): loss changed from 0.259 to 0.248\t\tVL:0.262\t\tAC:0.937\n",
      "Epoch 1110 (0.482 sec): loss changed from 0.257 to 0.243\t\tVL:0.262\t\tAC:0.937\n",
      "Epoch 1120 (0.444 sec): loss changed from 0.255 to 0.242\t\tVL:0.259\t\tAC:0.938\n",
      "Epoch 1130 (0.505 sec): loss changed from 0.247 to 0.231\t\tVL:0.258\t\tAC:0.939\n",
      "Epoch 1140 (0.437 sec): loss changed from 0.255 to 0.238\t\tVL:0.256\t\tAC:0.938\n",
      "Epoch 1150 (0.46 sec): loss changed from 0.243 to 0.227\t\tVL:0.255\t\tAC:0.946\n",
      "Epoch 1160 (0.466 sec): loss changed from 0.248 to 0.23\t\tVL:0.251\t\tAC:0.944\n",
      "Epoch 1170 (0.504 sec): loss changed from 0.245 to 0.228\t\tVL:0.255\t\tAC:0.939\n",
      "Epoch 1180 (0.471 sec): loss changed from 0.264 to 0.245\t\tVL:0.251\t\tAC:0.941\n",
      "Epoch 1190 (0.467 sec): loss changed from 0.247 to 0.232\t\tVL:0.249\t\tAC:0.947\n",
      "Epoch 1200 (0.511 sec): loss changed from 0.24 to 0.225\t\tVL:0.247\t\tAC:0.944\n",
      "Epoch 1210 (0.447 sec): loss changed from 0.253 to 0.234\t\tVL:0.247\t\tAC:0.947\n",
      "Epoch 1220 (0.459 sec): loss changed from 0.236 to 0.223\t\tVL:0.243\t\tAC:0.946\n",
      "Epoch 1230 (0.552 sec): loss changed from 0.236 to 0.217\t\tVL:0.244\t\tAC:0.946\n",
      "Epoch 1240 (0.416 sec): loss changed from 0.242 to 0.227\t\tVL:0.249\t\tAC:0.948\n",
      "Epoch 1250 (0.509 sec): loss changed from 0.229 to 0.214\t\tVL:0.241\t\tAC:0.953\n",
      "Epoch 1260 (0.521 sec): loss changed from 0.231 to 0.216\t\tVL:0.239\t\tAC:0.954\n",
      "Epoch 1270 (0.438 sec): loss changed from 0.239 to 0.224\t\tVL:0.236\t\tAC:0.952\n",
      "Epoch 1280 (0.475 sec): loss changed from 0.217 to 0.203\t\tVL:0.237\t\tAC:0.952\n",
      "Epoch 1290 (0.435 sec): loss changed from 0.23 to 0.216\t\tVL:0.236\t\tAC:0.956\n",
      "Epoch 1300 (0.467 sec): loss changed from 0.217 to 0.208\t\tVL:0.237\t\tAC:0.957\n",
      "Epoch 1310 (0.466 sec): loss changed from 0.223 to 0.213\t\tVL:0.233\t\tAC:0.955\n",
      "Epoch 1320 (0.458 sec): loss changed from 0.218 to 0.208\t\tVL:0.232\t\tAC:0.960\n",
      "Epoch 1330 (0.476 sec): loss changed from 0.229 to 0.213\t\tVL:0.233\t\tAC:0.956\n",
      "Epoch 1340 (0.436 sec): loss changed from 0.228 to 0.211\t\tVL:0.229\t\tAC:0.957\n",
      "Epoch 1350 (0.457 sec): loss changed from 0.236 to 0.217\t\tVL:0.226\t\tAC:0.961\n",
      "Epoch 1360 (0.501 sec): loss changed from 0.227 to 0.212\t\tVL:0.231\t\tAC:0.961\n",
      "Epoch 1370 (0.46 sec): loss changed from 0.225 to 0.208\t\tVL:0.222\t\tAC:0.966\n",
      "Epoch 1380 (0.462 sec): loss changed from 0.205 to 0.193\t\tVL:0.229\t\tAC:0.961\n",
      "Epoch 1390 (0.445 sec): loss changed from 0.227 to 0.211\t\tVL:0.220\t\tAC:0.965\n",
      "Epoch 1400 (0.465 sec): loss changed from 0.218 to 0.208\t\tVL:0.222\t\tAC:0.962\n",
      "Epoch 1410 (0.43 sec): loss changed from 0.213 to 0.2\t\tVL:0.222\t\tAC:0.966\n",
      "Epoch 1420 (0.489 sec): loss changed from 0.202 to 0.187\t\tVL:0.219\t\tAC:0.967\n",
      "Epoch 1430 (0.498 sec): loss changed from 0.214 to 0.2\t\tVL:0.216\t\tAC:0.963\n",
      "Epoch 1440 (0.421 sec): loss changed from 0.204 to 0.187\t\tVL:0.215\t\tAC:0.967\n",
      "Epoch 1450 (0.481 sec): loss changed from 0.22 to 0.207\t\tVL:0.216\t\tAC:0.966\n",
      "Epoch 1460 (0.455 sec): loss changed from 0.201 to 0.19\t\tVL:0.215\t\tAC:0.966\n",
      "Epoch 1470 (0.431 sec): loss changed from 0.212 to 0.198\t\tVL:0.212\t\tAC:0.967\n",
      "Epoch 1480 (0.444 sec): loss changed from 0.205 to 0.191\t\tVL:0.213\t\tAC:0.967\n",
      "Epoch 1490 (0.432 sec): loss changed from 0.196 to 0.184\t\tVL:0.211\t\tAC:0.968\n",
      "Epoch 1500 (0.509 sec): loss changed from 0.206 to 0.188\t\tVL:0.212\t\tAC:0.969\n",
      "Epoch 1510 (0.428 sec): loss changed from 0.204 to 0.187\t\tVL:0.211\t\tAC:0.967\n",
      "Epoch 1520 (0.541 sec): loss changed from 0.204 to 0.196\t\tVL:0.204\t\tAC:0.976\n",
      "Epoch 1530 (0.441 sec): loss changed from 0.209 to 0.197\t\tVL:0.205\t\tAC:0.972\n",
      "Epoch 1540 (0.421 sec): loss changed from 0.197 to 0.183\t\tVL:0.203\t\tAC:0.976\n",
      "Epoch 1550 (0.436 sec): loss changed from 0.194 to 0.181\t\tVL:0.202\t\tAC:0.972\n",
      "Epoch 1560 (0.504 sec): loss changed from 0.191 to 0.178\t\tVL:0.205\t\tAC:0.970\n",
      "Epoch 1570 (0.445 sec): loss changed from 0.197 to 0.181\t\tVL:0.206\t\tAC:0.969\n",
      "Epoch 1580 (0.454 sec): loss changed from 0.192 to 0.18\t\tVL:0.201\t\tAC:0.973\n",
      "Epoch 1590 (0.478 sec): loss changed from 0.199 to 0.183\t\tVL:0.200\t\tAC:0.972\n",
      "Epoch 1600 (0.455 sec): loss changed from 0.204 to 0.192\t\tVL:0.199\t\tAC:0.975\n",
      "Epoch 1610 (0.45 sec): loss changed from 0.203 to 0.19\t\tVL:0.196\t\tAC:0.975\n",
      "Epoch 1620 (0.495 sec): loss changed from 0.196 to 0.184\t\tVL:0.195\t\tAC:0.977\n",
      "Epoch 1630 (0.436 sec): loss changed from 0.197 to 0.182\t\tVL:0.194\t\tAC:0.976\n",
      "Epoch 1640 (0.458 sec): loss changed from 0.19 to 0.178\t\tVL:0.195\t\tAC:0.979\n",
      "Epoch 1650 (0.484 sec): loss changed from 0.187 to 0.177\t\tVL:0.194\t\tAC:0.976\n",
      "Epoch 1660 (0.47 sec): loss changed from 0.19 to 0.178\t\tVL:0.194\t\tAC:0.975\n",
      "Epoch 1670 (0.496 sec): loss changed from 0.194 to 0.184\t\tVL:0.192\t\tAC:0.979\n",
      "Epoch 1680 (0.487 sec): loss changed from 0.18 to 0.169\t\tVL:0.196\t\tAC:0.975\n",
      "Epoch 1690 (0.507 sec): loss changed from 0.184 to 0.169\t\tVL:0.191\t\tAC:0.979\n",
      "Epoch 1700 (0.482 sec): loss changed from 0.183 to 0.17\t\tVL:0.194\t\tAC:0.977\n",
      "Epoch 1710 (0.538 sec): loss changed from 0.193 to 0.171\t\tVL:0.197\t\tAC:0.975\n",
      "Epoch 1720 (0.44 sec): loss changed from 0.193 to 0.177\t\tVL:0.191\t\tAC:0.976\n",
      "Epoch 1730 (0.439 sec): loss changed from 0.177 to 0.168\t\tVL:0.187\t\tAC:0.979\n",
      "Epoch 1740 (0.431 sec): loss changed from 0.186 to 0.173\t\tVL:0.189\t\tAC:0.982\n",
      "Epoch 1750 (0.463 sec): loss changed from 0.188 to 0.177\t\tVL:0.186\t\tAC:0.979\n",
      "Epoch 1760 (0.46 sec): loss changed from 0.178 to 0.168\t\tVL:0.185\t\tAC:0.980\n",
      "Epoch 1770 (0.463 sec): loss changed from 0.183 to 0.166\t\tVL:0.189\t\tAC:0.977\n",
      "Epoch 1780 (0.462 sec): loss changed from 0.188 to 0.171\t\tVL:0.187\t\tAC:0.982\n",
      "Epoch 1790 (0.48 sec): loss changed from 0.184 to 0.173\t\tVL:0.185\t\tAC:0.983\n",
      "Epoch 1800 (0.458 sec): loss changed from 0.169 to 0.157\t\tVL:0.185\t\tAC:0.979\n",
      "Epoch 1810 (0.44 sec): loss changed from 0.18 to 0.166\t\tVL:0.186\t\tAC:0.979\n",
      "Epoch 1820 (0.441 sec): loss changed from 0.194 to 0.181\t\tVL:0.184\t\tAC:0.980\n",
      "Epoch 1830 (0.452 sec): loss changed from 0.185 to 0.172\t\tVL:0.185\t\tAC:0.982\n",
      "Epoch 1840 (0.486 sec): loss changed from 0.199 to 0.179\t\tVL:0.183\t\tAC:0.982\n",
      "Epoch 1850 (0.495 sec): loss changed from 0.175 to 0.163\t\tVL:0.189\t\tAC:0.979\n",
      "Epoch 1860 (0.488 sec): loss changed from 0.185 to 0.169\t\tVL:0.188\t\tAC:0.980\n",
      "Epoch 1870 (0.443 sec): loss changed from 0.175 to 0.161\t\tVL:0.182\t\tAC:0.982\n",
      "Epoch 1880 (0.505 sec): loss changed from 0.175 to 0.16\t\tVL:0.186\t\tAC:0.979\n",
      "Epoch 1890 (0.478 sec): loss changed from 0.175 to 0.162\t\tVL:0.179\t\tAC:0.982\n",
      "Epoch 1900 (0.426 sec): loss changed from 0.171 to 0.161\t\tVL:0.180\t\tAC:0.981\n",
      "Epoch 1910 (0.453 sec): loss changed from 0.174 to 0.16\t\tVL:0.182\t\tAC:0.985\n",
      "Epoch 1920 (0.491 sec): loss changed from 0.174 to 0.158\t\tVL:0.176\t\tAC:0.984\n",
      "Epoch 1930 (0.478 sec): loss changed from 0.179 to 0.16\t\tVL:0.179\t\tAC:0.982\n",
      "Epoch 1940 (0.468 sec): loss changed from 0.173 to 0.164\t\tVL:0.181\t\tAC:0.983\n",
      "Epoch 1950 (0.416 sec): loss changed from 0.183 to 0.165\t\tVL:0.179\t\tAC:0.984\n",
      "Epoch 1960 (0.469 sec): loss changed from 0.175 to 0.164\t\tVL:0.178\t\tAC:0.985\n",
      "Epoch 1970 (0.469 sec): loss changed from 0.166 to 0.153\t\tVL:0.178\t\tAC:0.980\n",
      "Epoch 1980 (0.439 sec): loss changed from 0.162 to 0.151\t\tVL:0.176\t\tAC:0.984\n",
      "Epoch 1990 (0.423 sec): loss changed from 0.168 to 0.159\t\tVL:0.174\t\tAC:0.983\n",
      "Epoch 2000 (0.471 sec): loss changed from 0.167 to 0.154\t\tVL:0.173\t\tAC:0.985\n",
      "Epoch 2010 (0.422 sec): loss changed from 0.169 to 0.155\t\tVL:0.175\t\tAC:0.988\n",
      "Epoch 2020 (0.426 sec): loss changed from 0.159 to 0.158\t\tVL:0.178\t\tAC:0.986\n",
      "Epoch 2030 (0.458 sec): loss changed from 0.166 to 0.154\t\tVL:0.173\t\tAC:0.986\n",
      "Epoch 2040 (0.434 sec): loss changed from 0.162 to 0.149\t\tVL:0.172\t\tAC:0.988\n",
      "Epoch 2050 (0.443 sec): loss changed from 0.164 to 0.154\t\tVL:0.174\t\tAC:0.986\n",
      "Epoch 2060 (0.427 sec): loss changed from 0.177 to 0.159\t\tVL:0.175\t\tAC:0.984\n",
      "Epoch 2070 (0.434 sec): loss changed from 0.159 to 0.146\t\tVL:0.175\t\tAC:0.983\n",
      "Epoch 2080 (0.435 sec): loss changed from 0.166 to 0.148\t\tVL:0.172\t\tAC:0.988\n",
      "Epoch 2090 (0.466 sec): loss changed from 0.167 to 0.152\t\tVL:0.170\t\tAC:0.987\n",
      "Epoch 2100 (0.473 sec): loss changed from 0.163 to 0.154\t\tVL:0.169\t\tAC:0.988\n",
      "Epoch 2110 (0.434 sec): loss changed from 0.152 to 0.139\t\tVL:0.172\t\tAC:0.986\n",
      "Epoch 2120 (0.453 sec): loss changed from 0.171 to 0.158\t\tVL:0.166\t\tAC:0.989\n",
      "Epoch 2130 (0.423 sec): loss changed from 0.172 to 0.161\t\tVL:0.167\t\tAC:0.991\n",
      "Epoch 2140 (0.477 sec): loss changed from 0.166 to 0.15\t\tVL:0.167\t\tAC:0.987\n",
      "Epoch 2150 (0.418 sec): loss changed from 0.161 to 0.148\t\tVL:0.168\t\tAC:0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2160 (0.435 sec): loss changed from 0.162 to 0.146\t\tVL:0.166\t\tAC:0.988\n",
      "Epoch 2170 (0.435 sec): loss changed from 0.169 to 0.154\t\tVL:0.169\t\tAC:0.990\n",
      "Epoch 2180 (0.466 sec): loss changed from 0.165 to 0.149\t\tVL:0.164\t\tAC:0.989\n",
      "Epoch 2190 (0.439 sec): loss changed from 0.156 to 0.143\t\tVL:0.166\t\tAC:0.988\n",
      "Epoch 2200 (0.419 sec): loss changed from 0.162 to 0.149\t\tVL:0.160\t\tAC:0.992\n",
      "Epoch 2210 (0.487 sec): loss changed from 0.157 to 0.146\t\tVL:0.166\t\tAC:0.988\n",
      "Epoch 2220 (0.436 sec): loss changed from 0.155 to 0.145\t\tVL:0.163\t\tAC:0.990\n",
      "Epoch 2230 (0.47 sec): loss changed from 0.154 to 0.142\t\tVL:0.167\t\tAC:0.988\n",
      "Epoch 2240 (0.498 sec): loss changed from 0.154 to 0.141\t\tVL:0.163\t\tAC:0.990\n",
      "Epoch 2250 (0.455 sec): loss changed from 0.15 to 0.139\t\tVL:0.159\t\tAC:0.992\n",
      "Epoch 2260 (0.455 sec): loss changed from 0.152 to 0.142\t\tVL:0.159\t\tAC:0.992\n",
      "Epoch 2270 (0.429 sec): loss changed from 0.158 to 0.144\t\tVL:0.162\t\tAC:0.992\n",
      "Epoch 2280 (0.423 sec): loss changed from 0.161 to 0.15\t\tVL:0.162\t\tAC:0.989\n",
      "Epoch 2290 (0.434 sec): loss changed from 0.151 to 0.142\t\tVL:0.161\t\tAC:0.994\n",
      "Epoch 2300 (0.433 sec): loss changed from 0.146 to 0.136\t\tVL:0.162\t\tAC:0.989\n",
      "Epoch 2310 (0.444 sec): loss changed from 0.155 to 0.144\t\tVL:0.160\t\tAC:0.990\n",
      "Epoch 2320 (0.422 sec): loss changed from 0.157 to 0.142\t\tVL:0.159\t\tAC:0.993\n",
      "Epoch 2330 (0.461 sec): loss changed from 0.158 to 0.147\t\tVL:0.156\t\tAC:0.994\n",
      "Epoch 2340 (0.434 sec): loss changed from 0.147 to 0.135\t\tVL:0.164\t\tAC:0.992\n",
      "Epoch 2350 (0.458 sec): loss changed from 0.155 to 0.147\t\tVL:0.160\t\tAC:0.990\n",
      "Epoch 2360 (0.456 sec): loss changed from 0.155 to 0.144\t\tVL:0.158\t\tAC:0.992\n",
      "Epoch 2370 (0.454 sec): loss changed from 0.157 to 0.142\t\tVL:0.157\t\tAC:0.992\n",
      "Epoch 2380 (0.505 sec): loss changed from 0.145 to 0.134\t\tVL:0.159\t\tAC:0.989\n",
      "Epoch 2390 (0.498 sec): loss changed from 0.149 to 0.135\t\tVL:0.156\t\tAC:0.991\n",
      "Epoch 2400 (0.45 sec): loss changed from 0.154 to 0.143\t\tVL:0.156\t\tAC:0.993\n",
      "Epoch 2410 (0.509 sec): loss changed from 0.155 to 0.14\t\tVL:0.158\t\tAC:0.992\n",
      "Epoch 2420 (0.463 sec): loss changed from 0.151 to 0.138\t\tVL:0.158\t\tAC:0.992\n",
      "Epoch 2430 (0.507 sec): loss changed from 0.15 to 0.137\t\tVL:0.157\t\tAC:0.992\n",
      "Epoch 2440 (0.467 sec): loss changed from 0.148 to 0.138\t\tVL:0.155\t\tAC:0.992\n",
      "Epoch 2450 (0.45 sec): loss changed from 0.162 to 0.148\t\tVL:0.155\t\tAC:0.990\n",
      "Epoch 2460 (0.443 sec): loss changed from 0.144 to 0.137\t\tVL:0.154\t\tAC:0.992\n",
      "Epoch 2470 (0.484 sec): loss changed from 0.146 to 0.14\t\tVL:0.158\t\tAC:0.993\n",
      "Epoch 2480 (0.503 sec): loss changed from 0.148 to 0.139\t\tVL:0.151\t\tAC:0.993\n",
      "Epoch 2490 (0.459 sec): loss changed from 0.156 to 0.146\t\tVL:0.151\t\tAC:0.989\n",
      "Epoch 2500 (0.511 sec): loss changed from 0.138 to 0.127\t\tVL:0.155\t\tAC:0.989\n",
      "Epoch 2510 (0.485 sec): loss changed from 0.165 to 0.148\t\tVL:0.152\t\tAC:0.993\n",
      "Epoch 2520 (0.498 sec): loss changed from 0.15 to 0.138\t\tVL:0.152\t\tAC:0.993\n",
      "Epoch 2530 (0.5 sec): loss changed from 0.15 to 0.14\t\tVL:0.152\t\tAC:0.992\n",
      "Epoch 2540 (0.488 sec): loss changed from 0.15 to 0.141\t\tVL:0.150\t\tAC:0.992\n",
      "Epoch 2550 (0.415 sec): loss changed from 0.152 to 0.142\t\tVL:0.152\t\tAC:0.993\n",
      "Epoch 2560 (0.515 sec): loss changed from 0.151 to 0.141\t\tVL:0.151\t\tAC:0.991\n",
      "Epoch 2570 (0.482 sec): loss changed from 0.151 to 0.134\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 2580 (0.452 sec): loss changed from 0.143 to 0.132\t\tVL:0.152\t\tAC:0.991\n",
      "Epoch 2590 (0.473 sec): loss changed from 0.15 to 0.139\t\tVL:0.156\t\tAC:0.989\n",
      "Epoch 2600 (0.459 sec): loss changed from 0.15 to 0.14\t\tVL:0.148\t\tAC:0.994\n",
      "Epoch 2610 (0.44 sec): loss changed from 0.142 to 0.132\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 2620 (0.53 sec): loss changed from 0.141 to 0.13\t\tVL:0.149\t\tAC:0.993\n",
      "Epoch 2630 (0.461 sec): loss changed from 0.147 to 0.137\t\tVL:0.147\t\tAC:0.994\n",
      "Epoch 2640 (0.535 sec): loss changed from 0.15 to 0.136\t\tVL:0.146\t\tAC:0.993\n",
      "Epoch 2650 (0.446 sec): loss changed from 0.147 to 0.132\t\tVL:0.150\t\tAC:0.993\n",
      "Epoch 2660 (0.418 sec): loss changed from 0.147 to 0.139\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 2670 (0.488 sec): loss changed from 0.147 to 0.126\t\tVL:0.149\t\tAC:0.993\n",
      "Epoch 2680 (0.459 sec): loss changed from 0.143 to 0.13\t\tVL:0.146\t\tAC:0.992\n",
      "Epoch 2690 (0.442 sec): loss changed from 0.147 to 0.135\t\tVL:0.145\t\tAC:0.994\n",
      "Epoch 2700 (0.481 sec): loss changed from 0.148 to 0.137\t\tVL:0.148\t\tAC:0.993\n",
      "Epoch 2710 (0.452 sec): loss changed from 0.153 to 0.14\t\tVL:0.147\t\tAC:0.992\n",
      "Epoch 2720 (0.438 sec): loss changed from 0.147 to 0.134\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 2730 (0.517 sec): loss changed from 0.147 to 0.135\t\tVL:0.146\t\tAC:0.993\n",
      "Epoch 2740 (0.477 sec): loss changed from 0.139 to 0.124\t\tVL:0.147\t\tAC:0.992\n",
      "Epoch 2750 (0.454 sec): loss changed from 0.142 to 0.134\t\tVL:0.146\t\tAC:0.995\n",
      "Epoch 2760 (0.506 sec): loss changed from 0.141 to 0.13\t\tVL:0.146\t\tAC:0.993\n",
      "Epoch 2770 (0.522 sec): loss changed from 0.144 to 0.132\t\tVL:0.149\t\tAC:0.992\n",
      "Epoch 2780 (0.46 sec): loss changed from 0.146 to 0.131\t\tVL:0.146\t\tAC:0.996\n",
      "Epoch 2790 (0.517 sec): loss changed from 0.14 to 0.13\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 2800 (0.45 sec): loss changed from 0.14 to 0.128\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2810 (0.436 sec): loss changed from 0.143 to 0.13\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2820 (0.445 sec): loss changed from 0.151 to 0.136\t\tVL:0.147\t\tAC:0.994\n",
      "Epoch 2830 (0.441 sec): loss changed from 0.136 to 0.125\t\tVL:0.144\t\tAC:0.994\n",
      "Epoch 2840 (0.428 sec): loss changed from 0.14 to 0.133\t\tVL:0.144\t\tAC:0.994\n",
      "Epoch 2850 (0.435 sec): loss changed from 0.137 to 0.128\t\tVL:0.144\t\tAC:0.992\n",
      "Epoch 2860 (0.447 sec): loss changed from 0.141 to 0.128\t\tVL:0.148\t\tAC:0.993\n",
      "Epoch 2870 (0.476 sec): loss changed from 0.142 to 0.13\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2880 (0.446 sec): loss changed from 0.146 to 0.133\t\tVL:0.145\t\tAC:0.994\n",
      "Epoch 2890 (0.445 sec): loss changed from 0.137 to 0.125\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 2900 (0.461 sec): loss changed from 0.142 to 0.128\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2910 (0.42 sec): loss changed from 0.14 to 0.129\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 2920 (0.459 sec): loss changed from 0.14 to 0.132\t\tVL:0.149\t\tAC:0.994\n",
      "Epoch 2930 (0.449 sec): loss changed from 0.143 to 0.133\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2940 (0.44 sec): loss changed from 0.146 to 0.133\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 2950 (0.441 sec): loss changed from 0.136 to 0.125\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 2960 (0.507 sec): loss changed from 0.146 to 0.131\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 2970 (0.453 sec): loss changed from 0.135 to 0.126\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 2980 (0.485 sec): loss changed from 0.143 to 0.13\t\tVL:0.150\t\tAC:0.993\n",
      "Epoch 2990 (0.458 sec): loss changed from 0.14 to 0.129\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 3000 (0.496 sec): loss changed from 0.145 to 0.131\t\tVL:0.144\t\tAC:0.995\n",
      "Epoch 3010 (0.514 sec): loss changed from 0.136 to 0.128\t\tVL:0.140\t\tAC:0.994\n",
      "Epoch 3020 (0.468 sec): loss changed from 0.145 to 0.135\t\tVL:0.144\t\tAC:0.992\n",
      "Epoch 3030 (0.455 sec): loss changed from 0.142 to 0.128\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 3040 (0.442 sec): loss changed from 0.151 to 0.138\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 3050 (0.517 sec): loss changed from 0.146 to 0.128\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 3060 (0.499 sec): loss changed from 0.139 to 0.131\t\tVL:0.139\t\tAC:0.995\n",
      "Epoch 3070 (0.491 sec): loss changed from 0.14 to 0.129\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 3080 (0.456 sec): loss changed from 0.141 to 0.128\t\tVL:0.143\t\tAC:0.995\n",
      "Epoch 3090 (0.428 sec): loss changed from 0.14 to 0.13\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 3100 (0.456 sec): loss changed from 0.145 to 0.133\t\tVL:0.140\t\tAC:0.993\n",
      "Epoch 3110 (0.454 sec): loss changed from 0.138 to 0.129\t\tVL:0.142\t\tAC:0.993\n",
      "Epoch 3120 (0.467 sec): loss changed from 0.144 to 0.129\t\tVL:0.137\t\tAC:0.996\n",
      "Epoch 3130 (0.433 sec): loss changed from 0.138 to 0.128\t\tVL:0.143\t\tAC:0.994\n",
      "Epoch 3140 (0.469 sec): loss changed from 0.135 to 0.128\t\tVL:0.141\t\tAC:0.995\n",
      "Epoch 3150 (0.464 sec): loss changed from 0.141 to 0.125\t\tVL:0.140\t\tAC:0.993\n",
      "Epoch 3160 (0.45 sec): loss changed from 0.139 to 0.128\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 3170 (0.493 sec): loss changed from 0.132 to 0.124\t\tVL:0.140\t\tAC:0.995\n",
      "Epoch 3180 (0.439 sec): loss changed from 0.143 to 0.131\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 3190 (0.478 sec): loss changed from 0.136 to 0.127\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 3200 (0.489 sec): loss changed from 0.137 to 0.128\t\tVL:0.139\t\tAC:0.996\n",
      "Epoch 3210 (0.487 sec): loss changed from 0.143 to 0.132\t\tVL:0.143\t\tAC:0.994\n",
      "Epoch 3220 (0.438 sec): loss changed from 0.138 to 0.128\t\tVL:0.142\t\tAC:0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3230 (0.451 sec): loss changed from 0.134 to 0.121\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 3240 (0.452 sec): loss changed from 0.129 to 0.121\t\tVL:0.143\t\tAC:0.993\n",
      "Epoch 3250 (0.448 sec): loss changed from 0.14 to 0.126\t\tVL:0.140\t\tAC:0.996\n",
      "Epoch 3260 (0.471 sec): loss changed from 0.132 to 0.124\t\tVL:0.139\t\tAC:0.994\n",
      "Epoch 3270 (0.427 sec): loss changed from 0.136 to 0.124\t\tVL:0.142\t\tAC:0.993\n",
      "Epoch 3280 (0.496 sec): loss changed from 0.134 to 0.121\t\tVL:0.141\t\tAC:0.990\n",
      "Epoch 3290 (0.429 sec): loss changed from 0.138 to 0.126\t\tVL:0.136\t\tAC:0.996\n",
      "Epoch 3300 (0.509 sec): loss changed from 0.143 to 0.123\t\tVL:0.143\t\tAC:0.993\n",
      "Epoch 3310 (0.47 sec): loss changed from 0.142 to 0.129\t\tVL:0.139\t\tAC:0.994\n",
      "Epoch 3320 (0.422 sec): loss changed from 0.14 to 0.125\t\tVL:0.139\t\tAC:0.993\n",
      "Epoch 3330 (0.443 sec): loss changed from 0.132 to 0.12\t\tVL:0.144\t\tAC:0.993\n",
      "Epoch 3340 (0.463 sec): loss changed from 0.141 to 0.131\t\tVL:0.139\t\tAC:0.994\n",
      "Epoch 3350 (0.455 sec): loss changed from 0.131 to 0.121\t\tVL:0.136\t\tAC:0.995\n",
      "Epoch 3360 (0.429 sec): loss changed from 0.131 to 0.123\t\tVL:0.137\t\tAC:0.994\n",
      "Epoch 3370 (0.456 sec): loss changed from 0.14 to 0.13\t\tVL:0.138\t\tAC:0.994\n",
      "Epoch 3380 (0.454 sec): loss changed from 0.127 to 0.118\t\tVL:0.139\t\tAC:0.995\n",
      "Epoch 3390 (0.45 sec): loss changed from 0.132 to 0.122\t\tVL:0.136\t\tAC:0.994\n",
      "Epoch 3400 (0.449 sec): loss changed from 0.135 to 0.124\t\tVL:0.138\t\tAC:0.994\n",
      "Epoch 3410 (0.467 sec): loss changed from 0.127 to 0.121\t\tVL:0.138\t\tAC:0.996\n",
      "Epoch 3420 (0.438 sec): loss changed from 0.139 to 0.128\t\tVL:0.136\t\tAC:0.993\n",
      "Epoch 3430 (0.433 sec): loss changed from 0.128 to 0.114\t\tVL:0.139\t\tAC:0.992\n",
      "Epoch 3440 (0.477 sec): loss changed from 0.131 to 0.119\t\tVL:0.136\t\tAC:0.994\n",
      "Epoch 3450 (0.431 sec): loss changed from 0.132 to 0.122\t\tVL:0.134\t\tAC:0.995\n",
      "Epoch 3460 (0.472 sec): loss changed from 0.138 to 0.13\t\tVL:0.134\t\tAC:0.996\n",
      "Epoch 3470 (0.428 sec): loss changed from 0.133 to 0.124\t\tVL:0.134\t\tAC:0.994\n",
      "Epoch 3480 (0.46 sec): loss changed from 0.129 to 0.12\t\tVL:0.137\t\tAC:0.997\n",
      "Epoch 3490 (0.494 sec): loss changed from 0.131 to 0.118\t\tVL:0.140\t\tAC:0.993\n",
      "Epoch 3500 (0.483 sec): loss changed from 0.129 to 0.122\t\tVL:0.134\t\tAC:0.997\n",
      "Epoch 3510 (0.466 sec): loss changed from 0.144 to 0.128\t\tVL:0.136\t\tAC:0.996\n",
      "Epoch 3520 (0.447 sec): loss changed from 0.134 to 0.12\t\tVL:0.137\t\tAC:0.996\n",
      "Epoch 3530 (0.477 sec): loss changed from 0.126 to 0.114\t\tVL:0.134\t\tAC:0.994\n",
      "Epoch 3540 (0.443 sec): loss changed from 0.133 to 0.12\t\tVL:0.136\t\tAC:0.994\n",
      "Epoch 3550 (0.583 sec): loss changed from 0.135 to 0.122\t\tVL:0.134\t\tAC:0.996\n",
      "Epoch 3560 (0.566 sec): loss changed from 0.134 to 0.125\t\tVL:0.133\t\tAC:0.995\n",
      "Epoch 3570 (0.472 sec): loss changed from 0.127 to 0.117\t\tVL:0.134\t\tAC:0.994\n",
      "Epoch 3580 (0.426 sec): loss changed from 0.132 to 0.123\t\tVL:0.134\t\tAC:0.994\n",
      "Epoch 3590 (0.444 sec): loss changed from 0.13 to 0.114\t\tVL:0.133\t\tAC:0.996\n",
      "Epoch 3600 (0.48 sec): loss changed from 0.13 to 0.116\t\tVL:0.136\t\tAC:0.995\n"
     ]
    }
   ],
   "source": [
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_SeqRNN-{0}'.format(dt_now), tf.get_default_graph())\n",
    "\n",
    "batch_size = 1000\n",
    "num_steps  = 30\n",
    "num_epochs = 5000\n",
    "\n",
    "fmtstr = 'Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.3f}\\t\\tAC:{5:1.3f}'\n",
    "valid_batch = {tfi_x: valid_x, tfi_y: valid_y}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini_x, mini_y = randomBatch((train_x, train_y), batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini_x, tfi_y:mini_y}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        lv = tfLoss.eval(feed_dict=valid_batch)\n",
    "        ac = tfAccuracy.eval(feed_dict=valid_batch)\n",
    "        summary = tfsumAll.eval(feed_dict=valid_batch)\n",
    "        tffw.add_summary(summary, i)\n",
    "        if i%10 == 0 or i == num_epochs - 1:\n",
    "            print(fmtstr.format(i,t1-t0,l0,l1,lv,ac))\n",
    "    valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 2, 2, 1, 2, 2, 2, 4, 3]),\n",
       " array([3, 3, 2, 3, 2, 2, 3, 2, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic-rnn-5     1.140 loss, 0.303 accuracy (stopped at 200 epochs)\n",
    "#gru-rnn-5       0.998 loss, 0.378 accuracy\n",
    "#gru-rnn-10      0.524 loss, 0.681 accuracy (and still improving fast) -> 0.136 loss and 0.995 accuracy\n",
    "#gru-rnn-5-5     0.590 loss, 0.664 accuracy (and still improving fast)\n",
    "valid_y[:10], valid_r[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'reversed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a8dcf376accf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'321'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'reversed'"
     ]
    }
   ],
   "source": [
    "#gru-rnn, 5, elu => 0.143 loss, 0.994 accuracy\n",
    "valid_y[:10], valid_r[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506627282.2685657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytf]",
   "language": "python",
   "name": "conda-env-pytf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
