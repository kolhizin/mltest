{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time\n",
    "import tensorflow as tf\n",
    "import sklearn, sklearn.metrics, sklearn.preprocessing, sklearn.linear_model, sklearn.ensemble, sklearn.model_selection\n",
    "import nltk, nltk.stem\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "import modutils\n",
    "\n",
    "data_dir = '../DataSets/MercariPrice/'\n",
    "src_file = data_dir + 'train_title.csv' \n",
    "stat_file = '21MerPrice04_TextStat.csv'\n",
    "w2vsrc_file = '21MerPrice04_W2VSrc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src = pd.read_csv(src_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile('[^a-z0-9\\[\\]&\\+]')\n",
    "re2 = re.compile('[\\[\\]]')\n",
    "re3 = re.compile('[0-9]+')\n",
    "re4 = re.compile('[&\\+]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src['item_text'] = src.item_description.astype(str).map(lambda x: re4.sub(' and ', re3.sub(' <num> ', re2.sub(' ', re1.sub(' ', x.lower()).replace('[rm]','<rm>')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "src['item_proc'] = src.item_text.astype(str).map(lambda x: [stemmer.stem(y.lower()) for y in x.split() if len(y) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_dict = collections.Counter([y for x in src.item_proc for y in x if len(y) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65021"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords = list(sorted(list(word_dict.items()), key=lambda x: x[1], reverse=True))\n",
    "len(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804709952583157"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x for (_,x) in allWords[:6800]]) / sum([x for (_,x) in allWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('wildflow', 56), 3.7488962513045823e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 6800\n",
    "allWords[idx], allWords[idx][1] / sum([x for (_,x) in allWords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary coverage properties:\n",
    "\n",
    "<table>\n",
    "<th>Dictionary size</th><th>Last word</th><th>Last-word frequency</th>\n",
    "<tr><td>50% / 100 words</td><td>'by'</td><td>23600 / 0.16%</td></tr>\n",
    "<tr><td>75% / 500 words</td><td>'decor'</td><td>4409 / 0.03%</td></tr>\n",
    "<tr><td>90% / 1700 words</td><td>'butteri'</td><td>843 / 5.7e-3%</td></tr>\n",
    "<tr><td>95% / 3200 words</td><td>'swaddl'</td><td>273 / 1.8e-3%</td></tr>\n",
    "<tr><td>97% / 5000 words</td><td>'gameplay'</td><td>109 / 7.3e-4%</td></tr>\n",
    "<tr><td>98% / 6800 words</td><td>'lap'</td><td>57 / 3.8e-4%</td></tr>\n",
    "<tr><td>99% / 11500 words</td><td>'grovia'</td><td>17 / 1.1e-4%</td></tr>\n",
    "<tr><td>99.5% / 20000 words</td><td>'goon'</td><td>5 / 3.4e-5%</td></tr>\n",
    "<tr><td>99.7% / 29000 words</td><td>'cinnamarol'</td><td>2 / 1.3e-5%</td></tr>\n",
    "<tr><td>99.9% / 53000 words</td><td>'volm'</td><td>1 / 6.7e-6%</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topNwords = list(sorted(list(word_dict.items()), key=lambda x: x[1], reverse=True))[:6800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "statNwords = [(z[0],z[1],tuple(src.fcst_diff_simple_title[src.item_proc.map(lambda x: z[0] in x)].agg(['mean', 'std'])))\n",
    "              for z in topNwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<num>', 848931, (0.051297657066670693, 0.58452474698813783)),\n",
       " ('box', 43846, (0.20456952926852379, 0.65494762688800934)),\n",
       " ('<rm>', 88744, (0.12990638636404458, 0.61274165886665655)),\n",
       " ('authent', 26868, (0.23631473579978479, 0.63025086254346996)),\n",
       " ('retail', 20313, (0.23935557697420937, 0.58869535329390232)),\n",
       " ('and', 408742, (0.05121744858037202, 0.58124049340977157)),\n",
       " ('with', 186851, (0.073057848124179856, 0.58620271856202033)),\n",
       " ('the', 260826, (0.057850948562996767, 0.5872065789159443)),\n",
       " ('come', 38352, (0.16481804952543094, 0.66297236020213213)),\n",
       " ('origin', 21377, (0.20382794468309259, 0.64026241892653202))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(statNwords, key=lambda x: abs(x[2][0]/x[2][1])*(x[1]**0.5), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(stat_file, 'wb') as f:\n",
    "    pickle.dump(statNwords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapper = {x[0]:i for (i,x) in enumerate(statNwords)}\n",
    "\n",
    "def word2idx(w):\n",
    "    if w in mapper:\n",
    "        return mapper[w]+1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def idx2word(i):\n",
    "    if i == 0:\n",
    "        return '<unk>'\n",
    "    if i-1 >= len(statNwords):\n",
    "        return '<err>'\n",
    "    return statNwords[i-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_src = list(src.item_proc.map(lambda x: [word2idx(z) for z in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(w2vsrc_file, 'wb') as f:\n",
    "    pickle.dump(w2v_src, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load state\n",
    "\n",
    "with open(stat_file, 'rb') as f:\n",
    "    statNwords = pickle.load(f)\n",
    "\n",
    "with open(w2vsrc_file, 'rb') as f:\n",
    "    w2v_src = pickle.load(f)\n",
    "    \n",
    "mapper = {x[0]:i for (i,x) in enumerate(statNwords)}\n",
    "\n",
    "def word2idx(w):\n",
    "    if w in mapper:\n",
    "        return mapper[w]+1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def idx2word(i):\n",
    "    if i == 0:\n",
    "        return '<unk>'\n",
    "    if i-1 >= len(statNwords):\n",
    "        return '<err>'\n",
    "    return statNwords[i-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_batch(data, ids):\n",
    "    tmp = np.array([[data[r[0]][r[1]], data[r[0]][r[2]]] for r in ids])\n",
    "    return tmp[:,0], tmp[:,1]\n",
    "\n",
    "def yield_batch(data, batch_size, max_skip=3, p_take=0.8, num_batches=-1):\n",
    "    batch_id = 0\n",
    "    data_len = len(data)\n",
    "    while True:\n",
    "        batch_id += 1\n",
    "        if num_batches > 0 and batch_id > num_batches:\n",
    "            break\n",
    "        ids = []\n",
    "        while len(ids) < batch_size:\n",
    "            id0 = np.random.randint(data_len)\n",
    "            if len(data[id0]) == 0:\n",
    "                continue\n",
    "            idi = np.random.randint(len(data[id0]))\n",
    "            for j in range(max(0, idi-max_skip), min(len(data[id0]), idi+max_skip+1)):\n",
    "                if j==idi:\n",
    "                    continue\n",
    "                if np.random.uniform() > p_take:\n",
    "                    continue\n",
    "                ids.append((id0, idi, j))\n",
    "        \n",
    "        yield form_batch(data, ids[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete.\n"
     ]
    }
   ],
   "source": [
    "DICT_SIZE = len(statNwords) + 1\n",
    "EMBED_SIZE = 50\n",
    "NCE_NUM_SAMPLED = 50\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    tf_in_word = tf.placeholder(tf.int32, shape=(None, ))\n",
    "    tf_in_context = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    \n",
    "with tf.name_scope('Embedding'):\n",
    "    tf_embedding = tf.Variable(np.random.normal(size=(DICT_SIZE, EMBED_SIZE)) / np.sqrt(EMBED_SIZE), dtype=tf.float32)\n",
    "    tf_embedded_word = tf.nn.embedding_lookup(tf_embedding, tf_in_word)\n",
    "    \n",
    "with tf.name_scope('Training'):\n",
    "    tf_nce_beta = tf.Variable(np.random.normal(size=(DICT_SIZE, EMBED_SIZE))/np.sqrt(EMBED_SIZE), dtype=tf.float32)\n",
    "    tf_nce_intercept = tf.Variable(np.zeros(shape=(DICT_SIZE)), dtype=tf.float32)\n",
    "    tf_nce_loss = tf.reduce_mean(\n",
    "                    tf.nn.nce_loss(weights=tf_nce_beta, biases=tf_nce_intercept,\n",
    "                                   labels=tf_in_context, inputs=tf_embedded_word,\n",
    "                                   num_sampled=NCE_NUM_SAMPLED, num_classes=DICT_SIZE))\n",
    "    tf_train = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(tf_nce_loss)\n",
    "    \n",
    "with tf.name_scope('Validation'):\n",
    "    tf_valid_dictionary = tf.constant(np.array(range(DICT_SIZE)))\n",
    "    tf_valid_embedding = tf.nn.embedding_lookup(tf_embedding, tf_valid_dictionary)\n",
    "    tf_valid_in_norm = tf_embedded_word / tf.sqrt(tf.reduce_sum(tf.square(tf_embedded_word), 1, keep_dims=True))\n",
    "    tf_valid_dic_norm = tf_valid_embedding / tf.sqrt(tf.reduce_sum(tf.square(tf_valid_embedding), 1, keep_dims=True))\n",
    "    tf_valid_similarity = tf.matmul(tf_valid_in_norm, tf_valid_dic_norm, transpose_b=True)\n",
    "    \n",
    "print('Graph creation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_set = [x for x in yield_batch(w2v_src, max_skip=1, batch_size=32768, num_batches=16)]\n",
    "(valid_x, valid_y) = (np.hstack(x) for x in list(zip(*valid_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss=152.263\n",
      "['two', 'factori', 'copyright', 'layer', 'salon', 'mode', 'said', 'vase', 'whatev', 'citizen']\n",
      "['this', 'rc', 'inch', 'yin', 'nightgown', 'lula', 'till', 'resili', 'episod', 'tattoo']\n",
      "['awesom', 'creek', 'slim', 'tiger', 'faux', 'critter', 'pointi', 'anyway', 'been', 'breakout']\n",
      "['bad', 'rcari', 'ergonom', 'envelop', 'starter', 'phase', 'desir', 'matrix', 'beatl', 'far']\n",
      "['price', 'fixabl', 'bangtan', 'rooki', 'cc', 'spiderman', 'georg', 'colour', 'allig', 'stippl']\n",
      "Step complete in 93.83 sec, loss=5.323\n",
      "['two', 'three', 'case', 'much', 'order', 'bracelet', 'palett', 'everyth', 'purs', 'design']\n",
      "['this', 'it', 'that', 'there', 'everyth', 'which', 'also', 'alway', 'last', 'miss']\n",
      "['awesom', 'much', 'fair', 'ador', 'pattern', 'bracelet', 'band', 'complet', 'unisex', 'scent']\n",
      "['bad', 'hit', 'those', 'envelop', 'aren', 'max', 'singl', 'pm', 'interior', 'balm']\n",
      "['price', 'unless', 'there', 'this', 'which', 'miss', 'firm', 'that', 'also', 'each']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-00.ckpt\n",
      "Step complete in 93.88 sec, loss=4.109\n",
      "['two', 'three', 'one', 'four', 'both', 'five', 'total', 'mix', 'mac', 'pouch']\n",
      "['this', 'multipl', 'which', 'it', 'anoth', 'individu', 'alreadi', 'who', 'that', 'she']\n",
      "['awesom', 'wonder', 'amaz', 'fair', 'almost', 'complet', 'decent', 'though', 'great', 'unisex']\n",
      "['bad', 'hit', 'bent', 'snug', 'process', 'obvious', 'found', 'surfac', 'sad', 'he']\n",
      "['price', 'cost', 'sorri', 'valu', 'msrp', 'worth', 'label', 'obo', 'inseam', 'current']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-01.ckpt\n",
      "Step complete in 93.99 sec, loss=4.006\n",
      "['two', 'three', 'four', 'five', 'both', 'singl', 'one', 'ten', 'tube', 'six']\n",
      "['this', 'itself', 'current', 'truli', 'individu', 'her', 'it', 'anoth', 'which', 'previous']\n",
      "['awesom', 'wonder', 'amaz', 'fabul', 'great', 'almost', 'perfect', 'decent', 'dope', 'incred']\n",
      "['bad', 'doesnt', 'seper', 'rather', 'poor', 'indic', 'tonight', 'sad', 'therefor', 'happen']\n",
      "['price', 'cost', 'sorri', 'releas', 'worth', 'msrp', 'obo', 'label', 'appropri', 'inventori']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-02.ckpt\n",
      "Step complete in 93.91 sec, loss=3.901\n",
      "['two', 'three', 'five', 'four', 'singl', 'six', 'both', 'tube', 'one', 'eight']\n",
      "['this', 'itself', 'current', 'her', 'text', 'specif', 'stuck', 'their', 'multipl', 'especi']\n",
      "['awesom', 'amaz', 'dope', 'great', 'wonder', 'fabul', 'accur', 'expens', 'almost', 'alik']\n",
      "['bad', 'poor', 'dwd', 'tonight', 'drag', 'outgrown', 'sad', 'weird', 'wont', 'hide']\n",
      "['price', 'unit', 'cost', 'cheapest', 'sorri', 'somewhat', 'orgin', 'markdown', 'worth', 'artwork']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-03.ckpt\n",
      "Step complete in 93.92 sec, loss=3.676\n",
      "['two', 'three', 'four', 'five', 'six', 'both', 'eight', 'ten', 'one', 'rear']\n",
      "['this', 'current', 'stuck', 'overstock', 'itself', 'their', 'certain', 'tonight', 'her', 'grate']\n",
      "['awesom', 'amaz', 'dope', 'great', 'burlap', 'effortless', 'accur', 'fabul', 'alik', 'cool']\n",
      "['bad', 'poor', 'weird', 'outgrown', 'visual', 'negat', 'itchi', 'mention', 'engin', 'bulki']\n",
      "['price', 'cheapest', 'sorri', 'cost', 'unit', 'orgin', 'markdown', 'shoelac', 'uncut', 'paperwork']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-04.ckpt\n",
      "Step complete in 93.96 sec, loss=3.934\n",
      "['two', 'three', 'four', 'eight', 'six', 'five', 'both', 'ten', 'neither', 'summertim']\n",
      "['this', 'stuck', 'impuls', 'att', 'current', 'especi', 'tonight', 'overstock', 'jesus', 'her']\n",
      "['awesom', 'amaz', 'dope', 'burlap', 'great', 'effortless', 'fantast', 'accur', 'minimalist', 'ornat']\n",
      "['bad', 'poor', 'weird', 'bulki', 'mention', 'posit', 'forward', 'itchi', 'funni', 'expect']\n",
      "['price', 'cheapest', 'cost', 'sorri', 'paperwork', 'worth', 'spent', 'spec', 'shoelac', 'artwork']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-05.ckpt\n",
      "Step complete in 96.25 sec, loss=3.774\n",
      "['two', 'three', 'four', 'six', 'eight', 'five', 'ten', 'both', 'divid', 'one']\n",
      "['this', 'impuls', 'att', 'stuck', 'swag', 'sick', 'auction', 'jesus', 'elsewher', 'launch']\n",
      "['awesom', 'dope', 'amaz', 'great', 'burlap', 'effortless', 'ornat', 'exquisit', 'bae', 'nice']\n",
      "['bad', 'poor', 'weird', 'posit', 'mention', 'itchi', 'bulki', 'merch', 'expect', 'goal']\n",
      "['price', 'cost', 'cheapest', 'label', 'paperwork', 'updat', 'relat', 'howev', 'sorri', 'worth']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-06.ckpt\n",
      "Step complete in 97.22 sec, loss=4.228\n",
      "['two', 'three', 'four', 'six', 'five', 'eight', 'ten', 'one', 'both', 'temp']\n",
      "['this', 'jesus', 'auction', 'stuck', 'impuls', 'tonight', 'trilog', 'notif', 'it', 'especi']\n",
      "['awesom', 'amaz', 'dope', 'burlap', 'great', 'effortless', 'exquisit', 'ornat', 'fantast', 'swag']\n",
      "['bad', 'weird', 'posit', 'poor', 'baggi', 'expect', 'forward', 'bulki', 'neat', 'mention']\n",
      "['price', 'cost', 'cheapest', 'relat', 'howev', 'retail', 'paperwork', 'sorri', 'updat', 'worth']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-07.ckpt\n",
      "Step complete in 94.65 sec, loss=3.601\n",
      "['two', 'three', 'four', 'six', 'one', 'five', 'eight', 'ten', 'sever', 'temp']\n",
      "['this', 'her', 'auction', 'it', 'jesus', 'mod', 'trilog', 'sick', 'notif', 'especi']\n",
      "['awesom', 'amaz', 'dope', 'great', 'effortless', 'burlap', 'fantast', 'exquisit', 'nice', 'cool']\n",
      "['bad', 'baggi', 'posit', 'weird', 'merch', 'bulki', 'forward', 'tailor', 'unnotic', 'narrow']\n",
      "['price', 'cost', 'cheapest', 'label', 'relat', 'updat', 'sorri', 'retail', 'ship', 'howev']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-08.ckpt\n",
      "Step complete in 94.36 sec, loss=4.059\n",
      "['two', 'three', 'four', 'six', 'one', 'five', 'sever', 'divid', 'multipl', 'both']\n",
      "['this', 'jesus', 'auction', 'mod', 'her', 'it', 'trilog', 'sick', 'especi', 'pix']\n",
      "['awesom', 'amaz', 'dope', 'burlap', 'great', 'nice', 'fantast', 'exquisit', 'effortless', 'cool']\n",
      "['bad', 'posit', 'baggi', 'weird', 'bulki', 'just', 'unfortun', 'unnotic', 'goal', 'ok']\n",
      "['price', 'cost', 'cheapest', 'updat', 'label', 'ship', 'relat', 'catalog', 'sorri', 'retail']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-09.ckpt\n",
      "Step complete in 97.20 sec, loss=3.685\n",
      "['two', 'three', 'four', 'one', 'six', 'five', 'eight', 'both', 'ten', 'sever']\n",
      "['this', 'it', 'auction', 'jesus', 'sick', 'trilog', 'especi', 'her', 'etern', 'wow']\n",
      "['awesom', 'amaz', 'burlap', 'great', 'dope', 'nice', 'fantast', 'excel', 'gopro', 'particular']\n",
      "['bad', 'baggi', 'posit', 'just', 'ok', 'prepar', 'weird', 'poor', 'bulki', 'expect']\n",
      "['price', 'cost', 'label', 'ship', 'sorri', 'updat', 'relat', 'retail', 'firm', 'valu']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-10.ckpt\n",
      "Step complete in 97.84 sec, loss=3.970\n",
      "['two', 'three', 'four', 'one', 'five', 'six', 'eight', 'ten', 'sever', 'either']\n",
      "['this', 'jesus', 'it', 'auction', 'her', 'obsess', 'itself', 'especi', 'sick', 'wow']\n",
      "['awesom', 'amaz', 'great', 'burlap', 'dope', 'nice', 'fantast', 'fabul', 'good', 'effortless']\n",
      "['bad', 'prepar', 'baggi', 'ok', 'posit', 'just', 'poor', 'weird', 'mention', 'funni']\n",
      "['price', 'cost', 'ship', 'label', 'retail', 'cheapest', 'firm', 'howev', 'relat', 'bundl']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-11.ckpt\n",
      "Step complete in 98.16 sec, loss=3.699\n",
      "['two', 'three', 'four', 'one', 'six', 'ten', 'five', 'eight', 'camp', 'either']\n",
      "['this', 'it', 'auction', 'jesus', 'especi', 'her', 'obsess', 'wow', 'quot', 'trilog']\n",
      "['awesom', 'amaz', 'great', 'nice', 'dope', 'burlap', 'effortless', 'fantast', 'cool', 'gopro']\n",
      "['bad', 'ok', 'posit', 'baggi', 'just', 'prepar', 'poor', 'funni', 'mention', 'weird']\n",
      "['price', 'label', 'ship', 'cost', 'retail', 'there', 'relat', 'updat', 'firm', 'cheapest']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-12.ckpt\n",
      "Step complete in 98.20 sec, loss=3.672\n",
      "['two', 'three', 'four', 'one', 'six', 'ten', 'five', 'eight', 'either', 'sever']\n",
      "['this', 'it', 'especi', 'auction', 'her', 'quot', 'parent', 'jesus', 'there', 'his']\n",
      "['awesom', 'amaz', 'great', 'nice', 'dope', 'burlap', 'fantast', 'excel', 'good', 'perfect']\n",
      "['bad', 'posit', 'ok', 'prepar', 'poor', 'relat', 'just', 'mention', 'baggi', 'funni']\n",
      "['price', 'cost', 'ship', 'retail', 'label', 'updat', 'firm', 'there', 'sorri', 'bundl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-13.ckpt\n",
      "Step complete in 96.76 sec, loss=3.870\n",
      "['two', 'three', 'one', 'four', 'six', 'five', 'ten', 'both', 'either', 'eight']\n",
      "['this', 'it', 'especi', 'her', 'itself', 'quot', 'jesus', 'his', 'their', 'fabul']\n",
      "['awesom', 'amaz', 'great', 'nice', 'fantast', 'dope', 'good', 'perfect', 'excel', 'innov']\n",
      "['bad', 'ok', 'poor', 'just', 'baggi', 'posit', 'relat', 'prepar', 'mention', 'weird']\n",
      "['price', 'cost', 'ship', 'retail', 'label', 'sorri', '<rm>', 'updat', 'firm', 'paid']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-14.ckpt\n",
      "Step complete in 95.88 sec, loss=3.745\n",
      "['two', 'three', 'four', 'one', 'five', 'ten', 'six', 'either', 'eight', 'sever']\n",
      "['this', 'it', 'especi', 'her', 'his', 'itself', 'quot', 'jesus', 'either', 'ideal']\n",
      "['awesom', 'amaz', 'great', 'fantast', 'burlap', 'dope', 'good', 'nice', 'perfect', 'effortless']\n",
      "['bad', 'just', 'ok', 'posit', 'mention', 'baggi', 'expens', 'prepar', 'funni', 'poor']\n",
      "['price', 'ship', 'cost', 'retail', 'updat', '<rm>', 'firm', 'label', 'bundl', 'sorri']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-15.ckpt\n",
      "Step complete in 95.97 sec, loss=3.901\n",
      "['two', 'three', 'one', 'four', 'six', 'five', 'ten', 'either', 'both', 'sever']\n",
      "['this', 'it', 'especi', 'his', 'her', 'there', 'either', 'start', '<unk>', 'youtub']\n",
      "['awesom', 'amaz', 'great', 'fantast', 'nice', 'burlap', 'good', 'perfect', 'excel', 'accur']\n",
      "['bad', 'posit', 'just', 'mention', 'expens', 'ok', 'baggi', 'prepar', 'poor', 'unfortun']\n",
      "['price', 'cost', 'ship', 'label', 'retail', '<rm>', 'updat', 'if', 'firm', 'paid']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-16.ckpt\n",
      "Step complete in 95.75 sec, loss=3.771\n",
      "['two', 'three', 'four', 'one', 'six', 'ten', 'five', 'sever', 'both', 'either']\n",
      "['this', 'it', 'especi', 'her', 'either', 'there', 'his', 'their', '<unk>', 'the']\n",
      "['awesom', 'amaz', 'great', 'fantast', 'good', 'nice', 'perfect', 'excel', 'burlap', 'dope']\n",
      "['bad', 'posit', 'mention', 'just', 'expens', 'ok', 'destroy', 'prepar', 'baggi', 'tact']\n",
      "['price', 'cost', 'ship', 'retail', 'updat', '<rm>', 'label', 'paid', 'howev', 'thank']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-17.ckpt\n",
      "Step complete in 96.77 sec, loss=3.754\n",
      "['two', 'three', 'four', 'one', 'five', 'six', 'ten', 'sever', 'both', 'either']\n",
      "['this', 'it', 'especi', 'their', 'her', 'either', 'there', '<unk>', 'the', 'anoth']\n",
      "['awesom', 'amaz', 'great', 'fantast', 'excel', 'perfect', 'good', 'nice', 'burlap', 'cool']\n",
      "['bad', 'posit', 'just', 'ok', 'expens', 'done', 'destroy', 'mention', 'baggi', 'photograph']\n",
      "['price', 'ship', 'label', 'cost', 'retail', '<rm>', 'paid', 'thank', 'if', 'firm']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-18.ckpt\n",
      "Step complete in 97.05 sec, loss=3.651\n",
      "['two', 'three', 'four', 'one', 'six', 'five', 'ten', 'both', '<num>', 'sever']\n",
      "['this', 'it', 'especi', 'her', 'his', '<unk>', 'the', 'their', 'either', 'that']\n",
      "['awesom', 'amaz', 'great', 'cool', 'fantast', 'nice', 'perfect', 'good', 'excel', 'dope']\n",
      "['bad', 'posit', 'just', 'ok', 'destroy', 'done', 'tact', 'expens', 'unfortun', 'untouch']\n",
      "['price', 'cost', 'ship', 'retail', '<rm>', 'label', 'paid', 'worth', 'firm', 'bundl']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-19.ckpt\n",
      "Step complete in 96.68 sec, loss=4.137\n",
      "['two', 'three', 'four', 'six', 'one', 'five', 'sever', 'both', 'ten', 'either']\n",
      "['this', 'it', 'her', 'his', 'especi', 'either', 'their', 'that', 'the', '<unk>']\n",
      "['awesom', 'amaz', 'great', 'nice', 'fantast', 'good', 'cool', 'perfect', 'excel', 'burlap']\n",
      "['bad', 'posit', 'just', 'done', 'destroy', 'ok', 'unfortun', 'untouch', 'spec', 'did']\n",
      "['price', 'paid', 'cost', 'retail', 'ship', '<rm>', 'label', 'worth', 'thank', 'bundl']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-20.ckpt\n",
      "Step complete in 96.79 sec, loss=3.656\n",
      "['two', 'three', 'four', 'six', 'one', 'five', 'ten', 'sever', 'both', 'either']\n",
      "['this', 'it', 'his', 'especi', 'her', 'there', 'either', 'their', '<unk>', 'that']\n",
      "['awesom', 'amaz', 'great', 'nice', 'fantast', 'perfect', 'cool', 'excel', 'good', 'burlap']\n",
      "['bad', 'posit', 'just', 'done', 'ok', 'destroy', 'damag', 'expens', 'untouch', 'photograph']\n",
      "['price', 'cost', 'ship', 'retail', '<rm>', 'paid', 'worth', 'label', 'if', 'bundl']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-21.ckpt\n",
      "Step complete in 95.84 sec, loss=3.799\n",
      "['two', 'three', 'four', 'six', 'five', 'one', 'ten', 'sever', 'both', 'either']\n",
      "['this', 'it', 'his', 'her', 'either', 'there', 'that', 'their', 'especi', '<unk>']\n",
      "['awesom', 'amaz', 'great', 'good', 'cool', 'perfect', 'excel', 'nice', 'fantast', 'fabul']\n",
      "['bad', 'posit', 'just', 'done', 'destroy', 'ok', 'photograph', 'untouch', 'damag', 'flaw']\n",
      "['price', 'cost', '<rm>', 'retail', 'ship', 'paid', 'worth', 'bundl', 'label', 'thank']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-22.ckpt\n",
      "Step complete in 97.57 sec, loss=3.743\n",
      "['two', 'three', 'six', 'five', 'four', 'one', 'both', 'ten', 'sever', 'either']\n",
      "['this', 'it', 'his', 'her', 'there', '<unk>', 'either', 'especi', 'their', 'that']\n",
      "['awesom', 'amaz', 'great', 'cool', 'nice', 'perfect', 'good', 'excel', 'fantast', 'dope']\n",
      "['bad', 'posit', 'just', 'ok', 'done', 'untouch', 'expens', 'destroy', 'damag', 'photograph']\n",
      "['price', 'cost', 'retail', 'paid', 'ship', '<rm>', 'worth', 'bundl', 'label', 'thank']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-23.ckpt\n",
      "Step complete in 101.04 sec, loss=3.667\n",
      "['two', 'three', 'five', 'six', 'four', 'one', 'both', 'ten', 'sever', '<num>']\n",
      "['this', 'it', 'her', '<unk>', 'there', 'his', 'either', 'that', 'which', 'the']\n",
      "['awesom', 'amaz', 'great', 'excel', 'perfect', 'nice', 'good', 'fantast', 'cool', 'camo']\n",
      "['bad', 'posit', 'just', 'done', 'untouch', 'ok', 'good', 'tact', 'expens', 'although']\n",
      "['price', 'cost', 'retail', 'label', '<rm>', 'paid', 'ship', 'bundl', 'thank', 'worth']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-24.ckpt\n",
      "Step complete in 104.26 sec, loss=4.738\n",
      "['two', 'three', 'five', 'four', 'six', 'one', 'ten', 'both', 'either', 'sever']\n",
      "['this', 'it', 'her', '<unk>', 'his', 'either', 'there', 'the', 'that', 'their']\n",
      "['awesom', 'amaz', 'great', 'excel', 'cool', 'nice', 'good', 'perfect', 'fantast', 'fabul']\n",
      "['bad', 'posit', 'just', 'done', 'ok', 'untouch', 'good', 'flaw', 'tact', 'flawless']\n",
      "['price', 'cost', 'paid', 'retail', 'label', 'ship', '<rm>', 'worth', 'bundl', 'if']\n",
      "Model saved at checkpoint: D:/Jupyter/Models-21MerPrice04-W2V/model-25.ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ba242f991114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0myield_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_src\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_skip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtrain_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtf_in_word\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_in_context\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mtf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_valid_similarity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimvalid_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \"\"\"\n\u001b[1;32m-> 1706\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3961\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3963\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tfsSaver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "simvalid_x = np.array([word2idx('two'), word2idx('this'), word2idx('awesom'), word2idx('bad'), word2idx('price')])\n",
    "simvalid_dict = {tf_in_word: simvalid_x}\n",
    "valid_dict = {tf_in_word: valid_x, tf_in_context: valid_y.reshape(-1, 1)}\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sim = tf_valid_similarity.eval(feed_dict=simvalid_dict)\n",
    "    loss = tf_nce_loss.eval(feed_dict=valid_dict)\n",
    "    print('Starting loss={:.3f}'.format(loss))\n",
    "    for q in range(len(sim)):\n",
    "        print([idx2word(z) for z in list(reversed(sim[q,:].argsort()))[:10]])\n",
    "        \n",
    "    for i in range(num_epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        for (train_x, train_y) in yield_batch(w2v_src, max_skip=1, batch_size=512, num_batches=10000):\n",
    "            train_dict = {tf_in_word: train_x, tf_in_context: train_y.reshape(-1, 1)}\n",
    "            tf_train.run(feed_dict=train_dict)\n",
    "\n",
    "        sim = tf_valid_similarity.eval(feed_dict=simvalid_dict)\n",
    "        loss = tf_nce_loss.eval(feed_dict=valid_dict)\n",
    "        dic_embed = tf_valid_dic_norm.eval()\n",
    "        t1 = time.perf_counter()\n",
    "        print('Step complete in {0:.2f} sec, loss={1:.3f}'.format(t1-t0, loss))\n",
    "        for q in range(len(sim)):\n",
    "            print([idx2word(z) for z in list(reversed(sim[q,:].argsort()))[:10]])\n",
    "        p = tfsSaver.save(tfs, 'D:/Jupyter/Models-21MerPrice04-W2V/model-{0:02d}.ckpt'.format(i))\n",
    "        print('Model saved at checkpoint: {0}'.format(p))\n",
    "    \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nine', 'restor', 'duffl', 'criss', 'ed'],\n",
       " ['this', 'it', 'that', 'littl', 'as'],\n",
       " ['awesom', 'except', 'almost', 'amaz', 'disc'],\n",
       " ['bad', 'hope', 'everyon', 'incred', 'tiger'],\n",
       " ['price', 'unless', 'is', 'includ', 'ship']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[idx2word(z) for z in list(reversed(sim1[i,:].argsort()))[:5]] for i in range(len(sim1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src_var = src.copy()\n",
    "for (x,_,_) in tmpDict:\n",
    "    src_var['f_{0}'.format(x)] = 1*src_var.item_proc.map(lambda z: x in z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n",
      "Parser   : 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = src_var[['f_{}'.format(x) for (x,_,_) in tmpDict]].values\n",
    "Y = src_var.fcst_diff_simple_title.values\n",
    "(Xtrain, Ytrain), (Xvalid, Yvalid), (Xtest, Ytest) = modutils.splitSample((X,Y), [0.3,0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#mgb0 = sklearn.ensemble.GradientBoostingRegressor(min_samples_leaf=100).fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlr0 = sklearn.linear_model.LinearRegression().fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsqr=0.1150 (train), 0.0945 (test)\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Ptrain = mlr0.predict(Xtrain)\n",
    "Ptest = mlr0.predict(Xtest)\n",
    "print('Rsqr={:.4f} (train), {:.4f} (test)'.format(sklearn.metrics.r2_score(Ytrain, Ptrain),\n",
    "                                                  sklearn.metrics.r2_score(Ytest, Ptest))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytf]",
   "language": "python",
   "name": "conda-env-pytf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
