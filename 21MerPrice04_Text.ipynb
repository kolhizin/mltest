{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time\n",
    "import tensorflow as tf\n",
    "import sklearn, sklearn.metrics, sklearn.preprocessing, sklearn.linear_model, sklearn.ensemble, sklearn.model_selection\n",
    "import nltk, nltk.stem\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "import modutils\n",
    "\n",
    "data_dir = '../DataSets/MercariPrice/'\n",
    "src_file = data_dir + 'train_title.csv' \n",
    "stat_file = '21MerPrice04_TextStat.csv'\n",
    "w2vsrc_file = '21MerPrice04_W2VSrc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src = pd.read_csv(src_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile('[^a-z0-9\\[\\]&\\+]')\n",
    "re2 = re.compile('[\\[\\]]')\n",
    "re3 = re.compile('[0-9]+')\n",
    "re4 = re.compile('[&\\+]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src['item_text'] = src.item_description.astype(str).map(lambda x: re4.sub(' and ', re3.sub(' <num> ', re2.sub(' ', re1.sub(' ', x.lower()).replace('[rm]','<rm>')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "src['item_proc'] = src.item_text.astype(str).map(lambda x: [stemmer.stem(y.lower()) for y in x.split() if len(y) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_dict = collections.Counter([y for x in src.item_proc for y in x if len(y) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65021"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords = list(sorted(list(word_dict.items()), key=lambda x: x[1], reverse=True))\n",
    "len(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804709952583157"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x for (_,x) in allWords[:6800]]) / sum([x for (_,x) in allWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('wildflow', 56), 3.7488962513045823e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 6800\n",
    "allWords[idx], allWords[idx][1] / sum([x for (_,x) in allWords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary coverage properties:\n",
    "\n",
    "<table>\n",
    "<th>Dictionary size</th><th>Last word</th><th>Last-word frequency</th>\n",
    "<tr><td>50% / 100 words</td><td>'by'</td><td>23600 / 0.16%</td></tr>\n",
    "<tr><td>75% / 500 words</td><td>'decor'</td><td>4409 / 0.03%</td></tr>\n",
    "<tr><td>90% / 1700 words</td><td>'butteri'</td><td>843 / 5.7e-3%</td></tr>\n",
    "<tr><td>95% / 3200 words</td><td>'swaddl'</td><td>273 / 1.8e-3%</td></tr>\n",
    "<tr><td>97% / 5000 words</td><td>'gameplay'</td><td>109 / 7.3e-4%</td></tr>\n",
    "<tr><td>98% / 6800 words</td><td>'lap'</td><td>57 / 3.8e-4%</td></tr>\n",
    "<tr><td>99% / 11500 words</td><td>'grovia'</td><td>17 / 1.1e-4%</td></tr>\n",
    "<tr><td>99.5% / 20000 words</td><td>'goon'</td><td>5 / 3.4e-5%</td></tr>\n",
    "<tr><td>99.7% / 29000 words</td><td>'cinnamarol'</td><td>2 / 1.3e-5%</td></tr>\n",
    "<tr><td>99.9% / 53000 words</td><td>'volm'</td><td>1 / 6.7e-6%</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topNwords = list(sorted(list(word_dict.items()), key=lambda x: x[1], reverse=True))[:6800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "statNwords = [(z[0],z[1],tuple(src.fcst_diff_simple_title[src.item_proc.map(lambda x: z[0] in x)].agg(['mean', 'std'])))\n",
    "              for z in topNwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<num>', 848931, (0.051297657066670693, 0.58452474698813783)),\n",
       " ('box', 43846, (0.20456952926852379, 0.65494762688800934)),\n",
       " ('<rm>', 88744, (0.12990638636404458, 0.61274165886665655)),\n",
       " ('authent', 26868, (0.23631473579978479, 0.63025086254346996)),\n",
       " ('retail', 20313, (0.23935557697420937, 0.58869535329390232)),\n",
       " ('and', 408742, (0.05121744858037202, 0.58124049340977157)),\n",
       " ('with', 186851, (0.073057848124179856, 0.58620271856202033)),\n",
       " ('the', 260826, (0.057850948562996767, 0.5872065789159443)),\n",
       " ('come', 38352, (0.16481804952543094, 0.66297236020213213)),\n",
       " ('origin', 21377, (0.20382794468309259, 0.64026241892653202))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(statNwords, key=lambda x: abs(x[2][0]/x[2][1])*(x[1]**0.5), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(stat_file, 'wb') as f:\n",
    "    pickle.dump(statNwords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapper = {x[0]:i for (i,x) in enumerate(statNwords)}\n",
    "\n",
    "def word2idx(w):\n",
    "    if w in mapper:\n",
    "        return mapper[w]+1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def idx2word(i):\n",
    "    if i == 0:\n",
    "        return '<unk>'\n",
    "    if i-1 >= len(statNwords):\n",
    "        return '<err>'\n",
    "    return statNwords[i-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_src = list(src.item_proc.map(lambda x: [word2idx(z) for z in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593376"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(w2vsrc_file, 'wb') as f:\n",
    "    pickle.dump(w2v_src, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load state\n",
    "\n",
    "with open(stat_file, 'rb') as f:\n",
    "    statNwords = pickle.load(f)\n",
    "\n",
    "with open(w2vsrc_file, 'rb') as f:\n",
    "    w2v_src = pickle.load(f)\n",
    "    \n",
    "mapper = {x[0]:i for (i,x) in enumerate(statNwords)}\n",
    "\n",
    "def word2idx(w):\n",
    "    if w in mapper:\n",
    "        return mapper[w]+1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def idx2word(i):\n",
    "    if i == 0:\n",
    "        return '<unk>'\n",
    "    if i-1 >= len(statNwords):\n",
    "        return '<err>'\n",
    "    return statNwords[i-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_batch(data, ids):\n",
    "    tmp = np.array([[data[r[0]][r[1]], data[r[0]][r[2]]] for r in ids])\n",
    "    return tmp[:,0], tmp[:,1]\n",
    "\n",
    "def yield_batch(data, batch_size, max_skip=3, p_take=0.8, num_batches=-1):\n",
    "    batch_id = 0\n",
    "    data_len = len(data)\n",
    "    while True:\n",
    "        if num_batches > 0 and batch_id > num_batches:\n",
    "            break\n",
    "        ids = []\n",
    "        while len(ids) < batch_size:\n",
    "            id0 = np.random.randint(data_len)\n",
    "            idi = np.random.randint(len(data[id0]))\n",
    "            for j in range(max(0, idi-max_skip), min(len(data[id0]), idi+max_skip+1)):\n",
    "                if j==idi:\n",
    "                    continue\n",
    "                if np.random.uniform() > p_take:\n",
    "                    continue\n",
    "                ids.append((id0, idi, j))\n",
    "        yield form_batch(data, ids[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  76    7]\n",
      " [  76  410]\n",
      " [  76    1]\n",
      " [   1 1805]\n",
      " [   1   21]\n",
      " [   1   56]\n",
      " [   1 1624]\n",
      " [   1    2]\n",
      " [ 131 1251]\n",
      " [ 131   57]]\n"
     ]
    }
   ],
   "source": [
    "DICT_SIZE = len(statNwords) + 1\n",
    "EMBED_SIZE = 200\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    tf_in_word = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    tf_in_context = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    \n",
    "with tf.name_scope('Embedding'):\n",
    "    tf_embedding = tf.Variable(np.random.normal(size=(DICT_SIZE, EMBED_SIZE)) / np.sqrt(DICT_SIZE * EMBED_SIZE))\n",
    "    tf_embedded_word = tf.nn.embedding_lookup(tf_embedding, tf_in_word)\n",
    "    \n",
    "with tf.name_scope('Training'):\n",
    "    tf_nce_beta = tf.Variable(np.random.normal(size=(DICT_SIZE, EMBED_SIZE))/np.sqrt(EMBED_SIZE))\n",
    "    tf_nce_intercept = tf.Variable(np.zeros(size=(DICT_SIZE))\n",
    "    tf.nn.nce_loss()\n",
    "\n",
    "print('Graph creation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89204199]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.random.normal(size=(32,1))  / np.sqrt(32)\n",
    "np.sqrt(np.dot(tmp.transpose(), tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src_var = src.copy()\n",
    "for (x,_,_) in tmpDict:\n",
    "    src_var['f_{0}'.format(x)] = 1*src_var.item_proc.map(lambda z: x in z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n",
      "Parser   : 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = src_var[['f_{}'.format(x) for (x,_,_) in tmpDict]].values\n",
    "Y = src_var.fcst_diff_simple_title.values\n",
    "(Xtrain, Ytrain), (Xvalid, Yvalid), (Xtest, Ytest) = modutils.splitSample((X,Y), [0.3,0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#mgb0 = sklearn.ensemble.GradientBoostingRegressor(min_samples_leaf=100).fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlr0 = sklearn.linear_model.LinearRegression().fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsqr=0.1150 (train), 0.0945 (test)\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Ptrain = mlr0.predict(Xtrain)\n",
    "Ptest = mlr0.predict(Xtest)\n",
    "print('Rsqr={:.4f} (train), {:.4f} (test)'.format(sklearn.metrics.r2_score(Ytrain, Ptrain),\n",
    "                                                  sklearn.metrics.r2_score(Ytest, Ptest))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
