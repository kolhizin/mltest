{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import struct\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "\n",
    "root_dir = \"D:/Jupyter/\";\n",
    "logs_dir = root_dir + \"Logs/\"\n",
    "data_dir = root_dir + 'Datasets/'\n",
    "\n",
    "def mnist_read_imgs(fname):\n",
    "    with open(fname, mode='rb') as f:\n",
    "        (_, img_num, img_xsize, img_ysize) = struct.unpack('>IIII',f.read(4 * 4))\n",
    "        data_img = np.fromfile(f, dtype=np.uint8).reshape(img_num, img_xsize, img_ysize)\n",
    "    return data_img\n",
    "\n",
    "def mnist_read_lbls(fname):\n",
    "    with open(data_dir + 'MNIST/train-labels.idx1-ubyte', mode='rb') as f:\n",
    "        (_, lab_num) = struct.unpack('>II', f.read(4 * 2))\n",
    "        data_lab = np.fromfile(f, dtype=np.uint8)\n",
    "    return data_lab\n",
    "\n",
    "def minibatch(X, y, num=1000):\n",
    "    inds = np.random.choice(range(X.shape[0]), size=num)\n",
    "    return X[inds], y[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_X = mnist_read_imgs(data_dir+'MNIST/train-images.idx3-ubyte')\n",
    "src_y = mnist_read_lbls(data_dir+'MNIST/train-labels.idx1-ubyte')\n",
    "\n",
    "random_seed = 42\n",
    "(dev_X, test_X, dev_y, test_y) = sklearn.model_selection.train_test_split(src_X, src_y, random_state=random_seed, test_size=0.2)\n",
    "(train_X, valid_X, train_y, valid_y) = sklearn.model_selection.train_test_split(dev_X, dev_y, random_state=random_seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist2d_transform_imgs(x):\n",
    "    return x.reshape(x.shape[0], x.shape[1], x.shape[2], 1) / 255\n",
    "\n",
    "def mnist2d_transform_lbls(y):\n",
    "    return np.array([1.0*(y==i) for i in range(10)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train2d_X, valid2d_X, test2d_X) = (mnist2d_transform_imgs(x) for x in (train_X, valid_X, test_X))\n",
    "(train2d_y, valid2d_y, test2d_y) = (mnist2d_transform_lbls(y) for y in (train_y, valid_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def tf_max_pool_2x2(x):\n",
    "  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def tf_weight_variable(shape):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def tf_bias_variable(shape):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = tf_weight_variable([3, 3, 1, 15]) #3x3 15 instead 5x5 32\n",
    "        b_conv1 = tf_bias_variable([15])\n",
    "        h_conv1 = tf.nn.relu(tf_conv2d(x, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = tf_max_pool_2x2(h_conv1)\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = tf_weight_variable([3, 3, 15, 15]) #3x3 15 instead 5x5 64\n",
    "        b_conv2 = tf_bias_variable([15])\n",
    "        h_conv2 = tf.nn.relu(tf_conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = tf_max_pool_2x2(h_conv2)\n",
    "\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = tf_weight_variable([7 * 7 * 15, 100])\n",
    "        b_fc1 = tf_bias_variable([100])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*15])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = tf_weight_variable([100, 10])\n",
    "        b_fc2 = tf_bias_variable([10])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "log_dir = root_dir + 'Logs/' + dt_now + '-GOOGLE-TF'\n",
    "\n",
    "#tfLR = tf.placeholder(shape=(),dtype=tf.float32)\n",
    "tfInput = tf.placeholder(shape=(None,28,28,1),dtype=tf.float32)\n",
    "tfLabels = tf.placeholder(shape=(None,10),dtype=tf.float32)\n",
    "\n",
    "tfLogits, tfPKeep = deepnn(tfInput)\n",
    "\n",
    "tfLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tfLabels, logits=tfLogits))\n",
    "\n",
    "tfOutProb = tf.nn.softmax(tfLogits, name='OutputProbs')\n",
    "tfAccuracy = 1.0-tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tfOutProb, axis=1),tf.argmax(tfLabels, axis=1)), dtype=tf.float32))\n",
    "tfAccuracySummary = tf.summary.scalar('Accuracy', tfAccuracy)\n",
    "\n",
    "#tfTrain = tf.train.RMSPropOptimizer(1e-4).minimize(tfLoss)\n",
    "tfTrain = tf.train.AdamOptimizer(1e-4).minimize(tfLoss)\n",
    "\n",
    "\n",
    "tffw = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2865\n",
      "2.20936\n",
      "1.99161\n",
      "1.65117\n",
      "1.1338\n",
      "0.838299\n",
      "0.71089\n",
      "0.416916\n",
      "0.488635\n",
      "0.507289\n",
      "0.402624\n",
      "0.420364\n",
      "0.255835\n",
      "0.388277\n",
      "0.234811\n",
      "0.480529\n",
      "0.2737\n",
      "0.337841\n",
      "0.287743\n",
      "0.139425\n",
      "0.242976\n",
      "0.263951\n",
      "0.467871\n",
      "0.192354\n",
      "0.205917\n",
      "0.168718\n",
      "0.24461\n",
      "0.0969818\n",
      "0.0849472\n",
      "0.336965\n",
      "0.131955\n",
      "0.211244\n",
      "0.149919\n",
      "0.0991082\n",
      "0.0807481\n",
      "0.115081\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4bb9fe1e2483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#batch = mnist.train.next_batch(50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2d_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain2d_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtfInput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfLabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfPKeep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b4e3e42d8101>\u001b[0m in \u001b[0;36mminibatch\u001b[1;34m(X, y, num)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vX, vy = minibatch(valid2d_X, valid2d_y, num=5000)\n",
    "valid_batch = {tfInput: vX, tfLabels: vy, tfPKeep: 1.0}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "        #batch = mnist.train.next_batch(50)\n",
    "        tX, ty = minibatch(train2d_X, train2d_y, num=50)\n",
    "        tfTrain.run(feed_dict={tfInput: tX, tfLabels: ty, tfPKeep: 0.5})\n",
    "        if i % 100 == 0:\n",
    "            print(tfLoss.eval(feed_dict={tfInput: tX, tfLabels: ty, tfPKeep: 1.0}))\n",
    "            valid_acc_str = tfAccuracySummary.eval(feed_dict=valid_batch)\n",
    "            tffw.add_summary(valid_acc_str, i / 100)\n",
    "        #print('step %d, training accuracy %g' % (i, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytfgpu]",
   "language": "python",
   "name": "conda-env-pytfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
