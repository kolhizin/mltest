{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "src_file = '../DataSets/Quora/w2v_src_180115.pickle'\n",
    "tfidf_file = '../DataSets/Quora/tfidf_src_180124.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(src_file, 'rb') as f:\n",
    "    (full_dict, full_sentences) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "totfreq = np.sum([x[1] for x in full_dict])\n",
    "idfs = [np.log(totfreq/x[1]) for x in full_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = full_sentences[:(len(full_sentences)//2)]\n",
    "p2 = full_sentences[(len(full_sentences)//2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tfidf(corpus, idfs, vocab_size=100, verbose=True):\n",
    "    res = []\n",
    "    for i in range(vocab_size):\n",
    "        tfidf = [(i, x.count(i), len(x)) for x in corpus]\n",
    "        res.append(tfidf)\n",
    "        if verbose:\n",
    "            print('{0}/{1}\\t\\t'.format(i, vocab_size), end='\\r')\n",
    "    if verbose:\n",
    "        print('Finalizing', end='\\r')\n",
    "    r = list(map(list, zip(*res)))\n",
    "    r = [[(y[0], y[1]/y[2]*idfs[y[0]]) for y in x if y[1] > 0] for x in r]\n",
    "    if verbose:\n",
    "        print('Complete  ')\n",
    "    return r\n",
    "\n",
    "def features_oov(p1, p2, vocab_size=100):\n",
    "    r = []\n",
    "    for i in range(len(p1)):\n",
    "        s1 = set([x for x in p1[i] if x > vocab_size])\n",
    "        s2 = set([x for x in p2[i] if x > vocab_size])\n",
    "        fAB = len(set.intersection(s1, s2))\n",
    "        fAUB = len(set.union(s1, s2))\n",
    "        fRAB = fAB / fAUB if fAUB > 0 else 0\n",
    "        r.append([fAB, fAUB, fRAB])\n",
    "    return r\n",
    "\n",
    "def features_all(p1, p2, idfs, vocab_size=100, verbose=True):\n",
    "    pt1 = transform_tfidf(p1, idfs, vocab_size=vocab_size, verbose=verbose)\n",
    "    pt2 = transform_tfidf(p2, idfs, vocab_size=vocab_size, verbose=verbose)\n",
    "    foov = features_oov(p1, p2, vocab_size=vocab_size)\n",
    "    return pt1, pt2, foov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete  \n",
      "Complete  \n",
      "Done 10000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 20000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 30000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 40000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 50000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 60000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 70000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 80000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 90000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 100000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 110000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 120000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 130000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 140000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 150000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 160000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 170000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 180000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 190000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 200000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 210000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 220000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 230000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 240000 of 242506\n",
      "Complete  \n",
      "Complete  \n",
      "Done 250000 of 242506\n",
      "Wall time: 11h 57min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "batch = 10000\n",
    "step = 0\n",
    "while step < len(p1):\n",
    "    tmp = features_all(p1[step:(step+batch)], p2[step:(step+batch)], idfs, vocab_size=1000)\n",
    "    res.append(tmp)\n",
    "    step += batch\n",
    "    print('Done {0} of {1}'.format(step, len(p1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_p1 = []\n",
    "src_p2 = []\n",
    "src_foov = []\n",
    "src_vocab_size = 1000\n",
    "for x in res:\n",
    "    src_p1 += x[0]\n",
    "    src_p2 += x[1]\n",
    "    src_foov += x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_data = [(src_p1[i], src_p2[i], src_foov[i]) for i in range(len(src_p1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(tfidf_file, 'wb') as f:\n",
    "    pickle.dump((src_data, src_vocab_size), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
