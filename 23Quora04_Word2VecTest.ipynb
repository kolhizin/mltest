{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "w2v_src_file = '../DataSets/Quora/w2v_src_180115.pickle'\n",
    "w2v_model = '../Models-23Quora03-W2V/model-02.ckpt'\n",
    "w2v_size = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recode_max_dict(sentences, full_dict, dict_size):\n",
    "    last_ind = dict_size - 1\n",
    "    new_dict = full_dict[:last_ind]\n",
    "    new_num = sum([x[1] for x in full_dict[last_ind:]])\n",
    "    new_freq = sum([x[2] for x in full_dict[last_ind:]])\n",
    "    new_dict.append(('<UNK>', new_num, new_freq, 1))\n",
    "    \n",
    "    new_sentences = [[min(last_ind, z) for z in x] for x in sentences]\n",
    "    return (new_sentences, new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(w2v_src_file, 'rb') as f:\n",
    "    (full_dict, full_sentences) = pickle.load(f)\n",
    "    \n",
    "(w2v_src, w2v_dict) = recode_max_dict(full_sentences, full_dict, dict_size=w2v_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load state    \n",
    "mapper = {x[0]:i for (i,x) in enumerate(w2v_dict)}\n",
    "\n",
    "def word2idx(w):\n",
    "    if w in mapper:\n",
    "        return mapper[w]\n",
    "    else:\n",
    "        return mapper['<UNK>']\n",
    "    \n",
    "def idx2word(i):\n",
    "    if type(i) is list:\n",
    "        return [idx2word(x) for x in i]\n",
    "    if type(i) is np.ndarray:\n",
    "        return np.array([idx2word(x) for x in i])\n",
    "    if i >= len(w2v_dict):\n",
    "        return '<ERR>'\n",
    "    return w2v_dict[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete.\n"
     ]
    }
   ],
   "source": [
    "DICT_SIZE = len(w2v_dict)\n",
    "EMBED_SIZE = 200\n",
    "NCE_NUM_SAMPLED = 100\n",
    "\n",
    "init_embeding = np.random.multivariate_normal(np.zeros(EMBED_SIZE), np.identity(EMBED_SIZE), size=DICT_SIZE)/np.sqrt(EMBED_SIZE)\n",
    "init_beta = np.random.multivariate_normal(np.zeros(EMBED_SIZE), np.identity(EMBED_SIZE), size=DICT_SIZE)/np.sqrt(EMBED_SIZE)\n",
    "init_intercept = np.zeros((DICT_SIZE,))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    tf_in_word = tf.placeholder(tf.int32, shape=(None, ), name='in_word')\n",
    "    tf_in_context = tf.placeholder(tf.int32, shape=(None, 1), name='in_context')\n",
    "    tf_in_regularization = tf.placeholder_with_default(0.1, shape=(), name='in_regularization')\n",
    "    \n",
    "with tf.name_scope('Embedding'):\n",
    "    tf_embedding = tf.Variable(init_embeding, dtype=tf.float32)\n",
    "    tf_embedded_word = tf.nn.embedding_lookup(tf_embedding, tf_in_word, name='out_embedding')\n",
    "    \n",
    "with tf.name_scope('Training'):\n",
    "    tf_nce_beta = tf.Variable(init_beta, dtype=tf.float32)\n",
    "    tf_nce_intercept = tf.Variable(init_intercept, dtype=tf.float32)\n",
    "    tf_nce_loss = tf.reduce_mean(\n",
    "                    tf.nn.nce_loss(weights=tf_nce_beta, biases=tf_nce_intercept,\n",
    "                                   labels=tf_in_context, inputs=tf_embedded_word,\n",
    "                                   num_sampled=NCE_NUM_SAMPLED, num_classes=DICT_SIZE))\n",
    "    #tf_reg_loss = tf.sqrt(tf.reduce_mean(tf.square(tf_embedding))) #bad loss\n",
    "    tf_reg_loss = tf.sqrt(tf.reduce_mean(tf.square(tf.reduce_mean(tf_embedding, axis=0)))) #center of embedding is 0\n",
    "    tf_full_loss = tf_nce_loss + tf_in_regularization * tf_reg_loss\n",
    "    tf_train = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(tf_full_loss)\n",
    "    \n",
    "with tf.name_scope('Validation'):\n",
    "    tf_valid_dictionary = tf.constant(np.array(range(DICT_SIZE)))\n",
    "    tf_valid_embedding = tf.nn.embedding_lookup(tf_embedding, tf_valid_dictionary)\n",
    "    tf_valid_in_norm = tf_embedded_word / tf.sqrt(tf.reduce_sum(tf.square(tf_embedded_word), 1, keep_dims=True))\n",
    "    tf_valid_dic_norm = tf_valid_embedding / tf.sqrt(tf.reduce_sum(tf.square(tf_valid_embedding), 1, keep_dims=True))\n",
    "    tf_valid_similarity = tf.matmul(tf_valid_in_norm, tf_valid_dic_norm, transpose_b=True)\n",
    "    \n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_W2V', tf.get_default_graph())\n",
    "tffw.close()\n",
    "print('Graph creation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Models-23Quora03-W2V/model-02.ckpt\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "tfsSaver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfsSaver.restore(tfs, save_path=w2v_model)\n",
    "    dic_embed = tf_valid_dic_norm.eval()\n",
    "    \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(wrd, embed=dic_embed):\n",
    "    if type(wrd) is str:\n",
    "        return embed[word2idx(wrd)]\n",
    "    if type(wrd) is list:\n",
    "        return [word2vec(x) for x in wrd]\n",
    "    if type(wrd) is np.ndarray:\n",
    "        return [word2vec(x) for x in wrd]\n",
    "    return None\n",
    "\n",
    "def topNids(vec, embed=dic_embed):\n",
    "    dists = np.sqrt(np.sum(np.square(embed - vec), axis=1))\n",
    "    dord = np.argsort(dists)\n",
    "    return (dord, dists[dord], np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_embed = dic_embed - dic_embed.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['solve', 'translate', 'tackle', 'handle', 'fix', 'simplify',\n",
       "        'treat', 'identify', 'relate', 'resolve'],\n",
       "       dtype='<U9'),\n",
       " array([ 0.        ,  0.80219698,  0.8729493 ,  0.94723475,  0.94835615,\n",
       "         0.95306551,  0.95552576,  0.9576475 ,  0.97037911,  0.97669458], dtype=float32),\n",
       " 1.4155799)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = word2vec('solve', n2_embed)\n",
    "print(np.sqrt(np.sum(np.square(v))))\n",
    "res = topNids(v, n2_embed)\n",
    "idx2word(res[0][:10]), res[1][:10], res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01188699138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['she', 'he', 'he/she', \"he's\", \"she's\", \"i've\", 'everyone',\n",
       "        'dumbledore', 'anybody', 'boyfriend'],\n",
       "       dtype='<U10'),\n",
       " array([ 0.        ,  0.39814789,  0.75271419,  0.88412588,  0.95190096,\n",
       "         0.96305999,  0.97022316,  0.97119915,  0.98680196,  0.99613919]),\n",
       " 1.4185787155359437)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = word2vec('she', pca_embed)\n",
    "print(np.sqrt(np.sum(np.square(v))))\n",
    "res = topNids(v, pca_embed)\n",
    "idx2word(res[0][:10]), res[1][:10], res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2_embed = n_embed / np.sqrt(np.square(n_embed).sum(axis=1)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.99999994,  1.        ,  1.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.square(n2_embed).sum(axis=1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_embed = sklearn.decomposition.PCA().fit_transform(n2_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.6333091 , -0.54214307, -0.52956626, -0.5003707 , -0.55046846,\n",
       "        -0.54390562, -0.54141343, -0.47641616, -0.50917155, -0.48353662,\n",
       "        -0.45214015, -0.42458806, -0.43480314, -0.4115022 , -0.39524293,\n",
       "        -0.43762931, -0.3771256 , -0.35240305, -0.38641964, -0.43003585,\n",
       "        -0.41754688, -0.43939526, -0.31356668, -0.33419397, -0.413508  ,\n",
       "        -0.33128372, -0.35395492, -0.30495326, -0.33358539, -0.36043662,\n",
       "        -0.33728471, -0.27333219, -0.27416362, -0.32134146, -0.29503932,\n",
       "        -0.31137491, -0.27792932, -0.29527525, -0.28394695, -0.30838947,\n",
       "        -0.29131041, -0.27624538, -0.28829076, -0.28900215, -0.26731326,\n",
       "        -0.27431599, -0.29866832, -0.27918682, -0.24630253, -0.29479382,\n",
       "        -0.26452575, -0.24393355, -0.26333232, -0.27787186, -0.22743721,\n",
       "        -0.24611424, -0.24179171, -0.26989162, -0.27518141, -0.25935061,\n",
       "        -0.2580018 , -0.26187867, -0.28574267, -0.23549507, -0.26484246,\n",
       "        -0.24259327, -0.26928762, -0.28356649, -0.2423091 , -0.25419875,\n",
       "        -0.23893644, -0.21321614, -0.22207174, -0.24005352, -0.2122419 ,\n",
       "        -0.2261347 , -0.22647439, -0.23497258, -0.23571391, -0.21216964,\n",
       "        -0.20834922, -0.24639356, -0.22430536, -0.22383712, -0.22004702,\n",
       "        -0.24506653, -0.23736194, -0.21869626, -0.21412855, -0.22760867,\n",
       "        -0.22987837, -0.20350588, -0.22481597, -0.18764409, -0.21953452,\n",
       "        -0.21496433, -0.22450093, -0.20631854, -0.2034623 , -0.22260908,\n",
       "        -0.211185  , -0.21398629, -0.21292859, -0.20377991, -0.19245667,\n",
       "        -0.19587326, -0.20629921, -0.19045683, -0.18972408, -0.19379695,\n",
       "        -0.18970993, -0.20567046, -0.21247381, -0.19090915, -0.19064054,\n",
       "        -0.18638364, -0.19741397, -0.21702167, -0.19035505, -0.16723726,\n",
       "        -0.19383213, -0.19696157, -0.18409788, -0.20563094, -0.20335047,\n",
       "        -0.20304654, -0.17241163, -0.1894388 , -0.18661626, -0.17193482,\n",
       "        -0.19198609, -0.16792369, -0.22570056, -0.18157011, -0.18940228,\n",
       "        -0.19115798, -0.20021402, -0.19021282, -0.1672574 , -0.17645361,\n",
       "        -0.19786611, -0.19043122, -0.17321483, -0.21700075, -0.18043598,\n",
       "        -0.179978  , -0.16139428, -0.1813562 , -0.16642397, -0.1824837 ,\n",
       "        -0.18203372, -0.18016645, -0.17392643, -0.17960814, -0.17083934,\n",
       "        -0.15081536, -0.17619524, -0.18257028, -0.15361225, -0.21020165,\n",
       "        -0.15454604, -0.16839339, -0.19251257, -0.17359647, -0.15842123,\n",
       "        -0.1609915 , -0.15772975, -0.16070627, -0.15942316, -0.18795618,\n",
       "        -0.15684911, -0.16634388, -0.15169595, -0.16406997, -0.15142542,\n",
       "        -0.17890991, -0.170526  , -0.1553564 , -0.14742173, -0.15455413,\n",
       "        -0.14896986, -0.13634917, -0.15604227, -0.15679803, -0.15073713,\n",
       "        -0.15427825, -0.14051839, -0.14661231, -0.15020898, -0.1356734 ,\n",
       "        -0.14105107, -0.13779716, -0.1490377 , -0.14984693, -0.14007499,\n",
       "        -0.15228724, -0.13854856, -0.15142369, -0.15591852, -0.1356721 ]),\n",
       " array([ 0.69125164,  0.75096259,  0.61277243,  0.73991086,  0.60241992,\n",
       "         0.57523921,  0.54821088,  0.5762577 ,  0.52548512,  0.48753467,\n",
       "         0.474551  ,  0.53354598,  0.53036692,  0.53270647,  0.53713021,\n",
       "         0.46960254,  0.43416109,  0.47482407,  0.42162566,  0.50168606,\n",
       "         0.49539521,  0.45815518,  0.54222447,  0.36171574,  0.45098087,\n",
       "         0.39162707,  0.38248393,  0.35487635,  0.3611358 ,  0.40041952,\n",
       "         0.34369298,  0.4047283 ,  0.35629824,  0.3214649 ,  0.30122148,\n",
       "         0.36245569,  0.3069499 ,  0.30379922,  0.41891681,  0.31351722,\n",
       "         0.37578439,  0.29459702,  0.32643312,  0.34393257,  0.33490833,\n",
       "         0.27627215,  0.32640581,  0.28129654,  0.25042922,  0.30792122,\n",
       "         0.27582393,  0.27866967,  0.28854546,  0.2829498 ,  0.2983508 ,\n",
       "         0.29186049,  0.29334662,  0.34810763,  0.28692342,  0.3288161 ,\n",
       "         0.26084814,  0.27226213,  0.29529844,  0.24149709,  0.27890441,\n",
       "         0.25583697,  0.27129862,  0.30520856,  0.24564273,  0.27053684,\n",
       "         0.25364419,  0.2245784 ,  0.25021787,  0.30166551,  0.24528238,\n",
       "         0.25268791,  0.26420638,  0.23640391,  0.2381564 ,  0.22906263,\n",
       "         0.22830592,  0.2611276 ,  0.26600521,  0.24165653,  0.22652892,\n",
       "         0.27096956,  0.25445349,  0.22704485,  0.21443447,  0.22881324,\n",
       "         0.24043111,  0.20421286,  0.23789525,  0.23998667,  0.24289833,\n",
       "         0.24990706,  0.22569919,  0.21413528,  0.21457841,  0.22748727,\n",
       "         0.21797896,  0.22655952,  0.25898295,  0.23397378,  0.27731742,\n",
       "         0.20735055,  0.21491946,  0.23160755,  0.20347053,  0.19597531,\n",
       "         0.1925699 ,  0.22081852,  0.24905411,  0.2015691 ,  0.23319783,\n",
       "         0.20761253,  0.20376875,  0.23099798,  0.20869358,  0.19676747,\n",
       "         0.19555676,  0.25043135,  0.19428631,  0.21309867,  0.23171743,\n",
       "         0.24432288,  0.24478167,  0.20109185,  0.19958262,  0.17864911,\n",
       "         0.19734062,  0.23840474,  0.26517187,  0.22156017,  0.19801032,\n",
       "         0.22183681,  0.20201729,  0.22509651,  0.21831373,  0.22031356,\n",
       "         0.20776546,  0.19341183,  0.19148388,  0.24863399,  0.18109424,\n",
       "         0.20442953,  0.19523908,  0.21465903,  0.21330248,  0.18875082,\n",
       "         0.20080314,  0.18876191,  0.18670525,  0.18825835,  0.17776377,\n",
       "         0.1697202 ,  0.23532519,  0.18909359,  0.15513709,  0.21507949,\n",
       "         0.16470151,  0.25219221,  0.20114679,  0.17796915,  0.17628498,\n",
       "         0.18421078,  0.1643361 ,  0.17007808,  0.17920759,  0.20594318,\n",
       "         0.158573  ,  0.20037725,  0.15482977,  0.1668499 ,  0.19601746,\n",
       "         0.19060268,  0.19725534,  0.18673116,  0.16999931,  0.17452065,\n",
       "         0.18009945,  0.15181399,  0.16951367,  0.16305659,  0.16154504,\n",
       "         0.17170222,  0.15858792,  0.1564904 ,  0.15165504,  0.1532046 ,\n",
       "         0.14346762,  0.13807434,  0.17406597,  0.15218117,  0.18084113,\n",
       "         0.15957681,  0.15352222,  0.16762132,  0.16023266,  0.14353544]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_embed.min(axis=0), pca_embed.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
