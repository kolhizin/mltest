{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time\n",
    "import sklearn, sklearn.metrics\n",
    "\n",
    "w2v_size = 9000\n",
    "w2v_file = '../DataSets/Quora/w2v_res_180119.pickle'\n",
    "train_file = '../DataSets/Quora/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242506\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(w2v_file, 'rb') as f:\n",
    "    (full_dict, full_sentences, full_w2v) = pickle.load(f)\n",
    "    \n",
    "full_seqs = list(zip(full_sentences[:(len(full_sentences)//2)], full_sentences[(len(full_sentences)//2):]))\n",
    "    \n",
    "full_data = pd.read_csv(train_file)\n",
    "print(len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_seq(sentence, w2v_dict, length):\n",
    "    res = [w2v_dict[x] for x in sentence if x + 1 < len(w2v_dict)]\n",
    "    return np.array(res[:length] + [np.zeros_like(w2v_dict[0])] * max(0, length - len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = np.array([len([z for z in x if z < len(full_w2v)]) for x in full_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  14.,  19.,  24.,  33.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(lens, [50, 75, 90, 95, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_SeqLen = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_x1 = np.array([create_seq(x[0], full_w2v, p_SeqLen) for x in full_seqs])\n",
    "data_x2 = np.array([create_seq(x[1], full_w2v, p_SeqLen) for x in full_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_y = full_data.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_x1, train_x2, train_y), (valid_x1, valid_x2, valid_y) = modutils.splitSample((data_x1, data_x2, data_y), pcts=[0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete.\n"
     ]
    }
   ],
   "source": [
    "#p_RNN_SIZE = [full_w2v.shape[1]]\n",
    "p_RNN_SIZE = [10]\n",
    "p_HID_SIZE = 10\n",
    "\n",
    "EncoderCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.elu)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    tf_in_x1 = tf.placeholder(tf.float32, shape=(None, p_SeqLen, full_w2v.shape[1]))\n",
    "    tf_in_x2 = tf.placeholder(tf.float32, shape=(None, p_SeqLen, full_w2v.shape[1]))\n",
    "    tf_in_y = tf.placeholder(tf.int32, shape=(None))\n",
    "    \n",
    "    tf_full_x = tf.concat([tf_in_x1, tf_in_x2], axis=0)\n",
    "\n",
    "with tf.name_scope('RNN'):\n",
    "    rnnEncoderCell = tf.nn.rnn_cell.MultiRNNCell([EncoderCell(s) for s in p_RNN_SIZE], state_is_tuple=True)\n",
    "    \n",
    "    _, tf_FinState0 = tf.nn.dynamic_rnn(rnnEncoderCell, inputs=tf_full_x, dtype=tf.float32, time_major=False)\n",
    "    tf_FinState = tf_FinState0[-1] #get latest layer in RNN\n",
    "\n",
    "with tf.name_scope('FC'):\n",
    "    tf_FinState1, tf_FinState2 = tf.split(tf_FinState, 2)\n",
    "    tf_FinStateC = tf.concat([0.5*(tf_FinState1+tf_FinState2),\n",
    "                              tf_FinState1*tf_FinState2,\n",
    "                              tf.squared_difference(tf_FinState1, tf_FinState2)], axis=1)\n",
    "    tf_logit0 = tf.layers.dense(tf_FinStateC, p_HID_SIZE, activation=tf.nn.elu)\n",
    "    tf_logit = tf.layers.dense(tf_logit0, 2)\n",
    "    \n",
    "with tf.name_scope('Output'):\n",
    "    tf_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf_in_y, logits=tf_logit))\n",
    "    tf_train = tf.train.AdamOptimizer(1e-2).minimize(tf_loss)\n",
    "\n",
    "    tf_prob = tf.nn.softmax(tf_logit)\n",
    "    \n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "    \n",
    "print('Graph creation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549 -> 0.548\t2.24 sec\n",
      "Epoch 0: 0.702 -> 0.540 in 364.02 sec, gini=0.555, accur=0.723\n",
      "0.520 -> 0.519\t2.35 sec\n",
      "Epoch 1: 0.540 -> 0.521 in 361.67 sec, gini=0.602, accur=0.733\n",
      "0.492 -> 0.485\t2.17 sec\n",
      "Epoch 2: 0.521 -> 0.498 in 381.93 sec, gini=0.635, accur=0.750\n",
      "0.489 -> 0.480\t2.22 sec\n",
      "Epoch 3: 0.498 -> 0.498 in 373.73 sec, gini=0.646, accur=0.750\n",
      "0.495 -> 0.495\t2.34 sec\n",
      "Epoch 4: 0.498 -> 0.488 in 357.16 sec, gini=0.657, accur=0.757\n",
      "0.483 -> 0.482\t1.25 sec sec\n",
      "Epoch 5: 0.488 -> 0.482 in 35309.83 sec, gini=0.664, accur=0.761\n",
      "0.498 -> 0.496\t2.32 sec\n",
      "Epoch 6: 0.482 -> 0.479 in 379.38 sec, gini=0.674, accur=0.764\n",
      "0.465 -> 0.460\t2.23 sec\n",
      "Epoch 7: 0.479 -> 0.468 in 385.19 sec, gini=0.686, accur=0.771\n",
      "0.428 -> 0.425\t2.22 sec\n",
      "Epoch 8: 0.468 -> 0.466 in 382.35 sec, gini=0.691, accur=0.773\n",
      "0.456 -> 0.458\t2.19 sec\n",
      "Epoch 9: 0.466 -> 0.464 in 374.08 sec, gini=0.696, accur=0.774\n",
      "0.434 -> 0.430\t2.22 sec\n",
      "Epoch 10: 0.464 -> 0.458 in 357.68 sec, gini=0.704, accur=0.777\n",
      "0.434 -> 0.432\t2.29 sec\n",
      "Epoch 11: 0.458 -> 0.456 in 369.07 sec, gini=0.705, accur=0.779\n",
      "0.444 -> 0.439\t2.25 sec\n",
      "Epoch 12: 0.456 -> 0.451 in 384.51 sec, gini=0.711, accur=0.783\n",
      "0.444 -> 0.437\t2.12 sec\n",
      "Epoch 13: 0.451 -> 0.457 in 385.13 sec, gini=0.714, accur=0.777\n",
      "0.441 -> 0.436\t2.26 sec\n",
      "Epoch 14: 0.457 -> 0.458 in 359.55 sec, gini=0.709, accur=0.779\n",
      "0.409 -> 0.409\t2.11 sec sec\n",
      "Epoch 15: 0.458 -> 0.452 in 45698.35 sec, gini=0.718, accur=0.781\n",
      "0.435 -> 0.433\t2.16 sec\n",
      "Epoch 16: 0.452 -> 0.449 in 368.73 sec, gini=0.721, accur=0.785\n",
      "0.433 -> 0.421\t2.09 sec\n",
      "Epoch 17: 0.449 -> 0.444 in 363.36 sec, gini=0.722, accur=0.788\n",
      "0.418 -> 0.416\t2.20 sec\n",
      "Epoch 18: 0.444 -> 0.445 in 372.97 sec, gini=0.724, accur=0.788\n",
      "0.417 -> 0.410\t2.19 sec\n",
      "Epoch 19: 0.445 -> 0.445 in 364.79 sec, gini=0.725, accur=0.787\n",
      "0.417 -> 0.418\t2.21 sec\n",
      "Epoch 20: 0.445 -> 0.444 in 369.67 sec, gini=0.727, accur=0.788\n",
      "0.412 -> 0.413\t2.11 sec\n",
      "Epoch 21: 0.444 -> 0.440 in 372.78 sec, gini=0.731, accur=0.790\n",
      "0.405 -> 0.399\t2.29 sec sec\n",
      "Epoch 22: 0.440 -> 0.438 in 35472.90 sec, gini=0.732, accur=0.792\n",
      "0.424 -> 0.416\t2.07 sec\n",
      "Epoch 23: 0.438 -> 0.443 in 368.39 sec, gini=0.727, accur=0.788\n",
      "0.434 -> 0.428\t2.18 sec\n",
      "Epoch 24: 0.443 -> 0.440 in 357.61 sec, gini=0.733, accur=0.788\n",
      "0.395 -> 0.393\t2.01 sec\n",
      "Epoch 25: 0.440 -> 0.438 in 361.10 sec, gini=0.735, accur=0.790\n",
      "0.437 -> 0.431\t2.18 sec\n",
      "Epoch 26: 0.438 -> 0.441 in 360.24 sec, gini=0.734, accur=0.789\n",
      "0.410 -> 0.410\t2.44 sec\n",
      "Epoch 27: 0.441 -> 0.439 in 359.34 sec, gini=0.736, accur=0.793\n",
      "0.400 -> 0.396\t2.10 secsec\n",
      "Epoch 28: 0.439 -> 0.439 in 4249.28 sec, gini=0.735, accur=0.790\n",
      "0.401 -> 0.398\t1.42 sec\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-8b3f32786f71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0ml0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffleBatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mtrain_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtf_in_x1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_in_x2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_in_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtY\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Jupyter\\mltest\\modutils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensorTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensorTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "num_steps  = 2\n",
    "batch_size = 2048\n",
    "valid_dict = {tf_in_x1: valid_x1, tf_in_x2: valid_x2, tf_in_y: valid_y}\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for n in range(num_epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        l0 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        for tX1, tX2, tY in modutils.shuffleBatches((train_x1, train_x2, train_y), batchSize=batch_size):\n",
    "            train_dict = {tf_in_x1: tX1, tf_in_x2: tX2, tf_in_y: tY}\n",
    "            tt0 = time.perf_counter()\n",
    "            tl0 = tf_loss.eval(feed_dict=train_dict)\n",
    "            for i in range(num_steps):\n",
    "                tf_train.run(feed_dict=train_dict)\n",
    "            tl1 = tf_loss.eval(feed_dict=train_dict)\n",
    "            tt1 = time.perf_counter()\n",
    "            print('{0:.3f} -> {1:.3f}\\t{2:.2f} sec'.format(tl0, tl1, tt1-tt0), end='\\r')\n",
    "\n",
    "        valid_p = tf_prob.eval(feed_dict=valid_dict)\n",
    "        gini = sklearn.metrics.roc_auc_score(valid_y, valid_p[:,1])*2-1\n",
    "        accur = sklearn.metrics.accuracy_score(valid_y, 1*(valid_p[:,1]>0.5))\n",
    "        l1 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        print('\\nEpoch {0}: {1:.3f} -> {2:.3f} in {3:.2f} sec, gini={4:.3f}, accur={5:.3f}'.format(n, l0, l1, t1-t0, gini, accur))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#p_RNN_SIZE = [10]\n",
    "#p_HID_SIZE = 10\n",
    "#on epoch 10 - gini 70, on epoch 28 gini 73.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
