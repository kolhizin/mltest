{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObs(length):\n",
    "    return np.random.choice(range(2), size=length)\n",
    "\n",
    "def genTarget(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def genSample(num, length=20):\n",
    "    x = [genObs(length=length) for _ in range(num)]\n",
    "    y = [genTarget(t) for t in x]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def randomBatch(tensorTuple, batchSize=64):\n",
    "    ids = np.random.choice(range(tensorTuple[0].shape[0]), batchSize)\n",
    "    return (x[ids,] for x in tensorTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0]]),\n",
       " array([14, 12, 11,  9, 10, 10, 17, 12, 11, 10]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = genSample(10000)\n",
    "valid_x, valid_y = genSample(1000)\n",
    "valid_x[:10], valid_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "RNN_SIZE = [3]\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.BasicRNNCell(num_units=n, activation=tf.nn.relu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.float32)\n",
    "tfi_y = tf.placeholder(shape=(None), dtype=tf.int64)\n",
    "\n",
    "tfX = tf.reshape(tfi_x, shape=(tf.shape(tfi_x)[0], tf.shape(tfi_x)[1], 1))\n",
    "tfYC = tf.reshape(tfi_y, shape=(tf.shape(tfi_y)[0], 1))\n",
    "tfY = tf.one_hot(tfi_y, SEQ_LEN + 1, dtype=tf.float32)\n",
    "tfY1 = tf.one_hot(tfi_y, 2, dtype=tf.float32)\n",
    "\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE])\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0])\n",
    "\n",
    "_, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfOut = tf.layers.dense(tfO[-1], 1)\n",
    "#tfOut = tf.layers.dense(tfi_x, 1)\n",
    "\n",
    "#tfLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tfY1, logits=tfOut))\n",
    "#tfLoss = tf.reduce_mean(tf.nn.l2_loss(tf.cast(tfi_y, dtype=tf.float32) - tfOut))\n",
    "#tfLoss = tf.reduce_mean(tf.abs(tf.cast(tfi_y, dtype=tf.float32) - tfOut))\n",
    "tfLoss = tf.reduce_mean(tf.pow(tf.cast(tfYC, dtype=tf.float32) - tfOut, 2))\n",
    "tfTrain = tf.train.AdamOptimizer(1e-2).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.cast(tf.round(tfOut),dtype=tf.int64)\n",
    "\n",
    "tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tfYC, tf.cast(tf.round(tfOut),dtype=tf.int64)), dtype=tf.float32))\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.255 sec): loss changed from 1.08e+02 to 91.6\t\tVL:9.584\t\tAC:0.000\n",
      "Epoch 1 (0.251 sec): loss changed from 90.6 to 6.53\t\tVL:2.601\t\tAC:0.145\n",
      "Epoch 2 (0.254 sec): loss changed from 6.52 to 4.68\t\tVL:2.206\t\tAC:0.164\n",
      "Epoch 3 (0.258 sec): loss changed from 4.73 to 4.26\t\tVL:2.101\t\tAC:0.168\n",
      "Epoch 4 (0.219 sec): loss changed from 4.14 to 3.88\t\tVL:2.034\t\tAC:0.175\n",
      "Epoch 5 (0.224 sec): loss changed from 4.04 to 3.77\t\tVL:1.972\t\tAC:0.189\n",
      "Epoch 6 (0.206 sec): loss changed from 3.84 to 3.67\t\tVL:1.924\t\tAC:0.205\n",
      "Epoch 7 (0.213 sec): loss changed from 3.52 to 3.34\t\tVL:1.877\t\tAC:0.204\n",
      "Epoch 8 (0.212 sec): loss changed from 3.35 to 3.19\t\tVL:1.835\t\tAC:0.210\n",
      "Epoch 9 (0.208 sec): loss changed from 3.19 to 3.02\t\tVL:1.790\t\tAC:0.213\n",
      "Epoch 10 (0.21 sec): loss changed from 2.98 to 2.82\t\tVL:1.740\t\tAC:0.224\n",
      "Epoch 11 (0.207 sec): loss changed from 3.03 to 2.78\t\tVL:1.676\t\tAC:0.226\n",
      "Epoch 12 (0.213 sec): loss changed from 2.58 to 2.33\t\tVL:1.593\t\tAC:0.238\n",
      "Epoch 13 (0.215 sec): loss changed from 2.4 to 2.06\t\tVL:1.476\t\tAC:0.263\n",
      "Epoch 14 (0.208 sec): loss changed from 2.04 to 1.57\t\tVL:1.300\t\tAC:0.292\n",
      "Epoch 15 (0.211 sec): loss changed from 1.74 to 1.0\t\tVL:0.989\t\tAC:0.377\n",
      "Epoch 16 (0.211 sec): loss changed from 0.962 to 0.297\t\tVL:0.547\t\tAC:0.633\n",
      "Epoch 17 (0.214 sec): loss changed from 0.287 to 0.0402\t\tVL:0.204\t\tAC:0.984\n",
      "Epoch 18 (0.211 sec): loss changed from 0.0387 to 0.00399\t\tVL:0.068\t\tAC:1.000\n",
      "Epoch 19 (0.222 sec): loss changed from 0.00395 to 0.00355\t\tVL:0.064\t\tAC:1.000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_steps  = 50\n",
    "num_epochs = 20\n",
    "\n",
    "valid_batch = {tfi_x: valid_x, tfi_y: valid_y}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini_x, mini_y = randomBatch((train_x, train_y), batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini_x, tfi_y:mini_y}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        lv = np.sqrt(tfLoss.eval(feed_dict=valid_batch))\n",
    "        ac = tfAccuracy.eval(feed_dict=valid_batch)\n",
    "        \n",
    "        print('Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.3f}\\t\\tAC:{5:1.3f}'.format(i,t1-t0,l0,l1,lv,ac))\n",
    "    valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14, 12, 11,  9, 10, 10, 17, 12, 11, 10,  6, 13, 10,  9, 12]),\n",
       " array([[14],\n",
       "        [12],\n",
       "        [11],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [10],\n",
       "        [17],\n",
       "        [12],\n",
       "        [11],\n",
       "        [10],\n",
       "        [ 6],\n",
       "        [13],\n",
       "        [10],\n",
       "        [ 9],\n",
       "        [12]], dtype=int64))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y[:15],valid_r[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
