{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_sample_v0(length=-1):\n",
    "    seq_length = length\n",
    "    if seq_length == -1:\n",
    "        seq_length = np.random.poisson(16)\n",
    "    x = [np.random.choice([0,1,2],p=[0.4,0.4,0.2]) for i in range(seq_length)]\n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        xscore = 0\n",
    "        yscore = 0\n",
    "        if x[i]==0:\n",
    "            xscore += 5\n",
    "        if x[i]==1:\n",
    "            yscore += 5\n",
    "        if i-3 >= 0 and x[i-3]==2:\n",
    "            xscore += 10\n",
    "            \n",
    "        p = np.exp(xscore) / (np.exp(xscore) + np.exp(yscore))\n",
    "        y.append(np.random.choice([0, 1], p=[p,1-p]))\n",
    "    return x,y\n",
    "\n",
    "def gen_sample_v1(length=-1):\n",
    "    seq_length = length\n",
    "    if seq_length == -1:\n",
    "        seq_length = np.random.poisson(16)\n",
    "    x = [np.random.choice([0,1,2],p=[0.4,0.4,0.2]) for i in range(seq_length)]\n",
    "    y = []\n",
    "    xscore = 0\n",
    "    yscore = 0\n",
    "    for i in range(len(x)):        \n",
    "        if x[i]==0:\n",
    "            xscore += 1\n",
    "        if x[i]==1:\n",
    "            yscore += 1\n",
    "        if x[i]==2:\n",
    "            xscore = 0\n",
    "            yscore = 0\n",
    "        p = np.exp(xscore) / (np.exp(xscore) + np.exp(yscore))\n",
    "        y.append(np.random.choice([0, 1], p=[p,1-p]))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*[gen_sample_v1(32) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x26afb3c4d30>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_length = 16\n",
    "num_units = 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_src_x = tf.placeholder(shape=(None, src_length), dtype=tf.int32)\n",
    "tf_src_y = tf.placeholder(shape=(None, src_length), dtype=tf.int32)\n",
    "tf_x = tf.one_hot(tf_src_x, 3)\n",
    "tf_y = tf.one_hot(tf_src_y, 2)\n",
    "\n",
    "tf_cell = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "#tf_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units=num_units, activation=tf.nn.relu) for _ in range(16)])\n",
    "\n",
    "tf_out, _ = tf.nn.dynamic_rnn(tf_cell, inputs=tf_x, dtype=tf.float32)\n",
    "tf_res = tf.layers.dense(tf_out, 2, use_bias=True)\n",
    "\n",
    "tf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=tf_res, labels=tf_y))\n",
    "tf_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf_y,axis=2), tf.argmax(tf_res,axis=2)), dtype=tf.float32))\n",
    "tf_prob = tf.nn.softmax(tf_res)\n",
    "tf_train = tf.train.AdamOptimizer(1e-2).minimize(tf_loss)\n",
    "\n",
    "tf.summary.FileWriter('D:/Jupyter/Logs/09A_SeqRNN_1', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Train 0.749 -> 0.266, Validation: 0.26532354950904846\n",
      "Step 1: Train 0.267 -> 0.179, Validation: 0.19088079035282135\n",
      "Step 2: Train 0.186 -> 0.14, Validation: 0.17797407507896423\n",
      "Step 3: Train 0.165 -> 0.143, Validation: 0.18310041725635529\n",
      "Step 4: Train 0.167 -> 0.146, Validation: 0.18441306054592133\n",
      "Step 5: Train 0.167 -> 0.128, Validation: 0.16877979040145874\n",
      "Step 6: Train 0.161 -> 0.143, Validation: 0.16809624433517456\n",
      "Step 7: Train 0.174 -> 0.146, Validation: 0.17310667037963867\n",
      "Step 8: Train 0.164 -> 0.135, Validation: 0.17497003078460693\n",
      "Step 9: Train 0.163 -> 0.135, Validation: 0.1705898493528366\n",
      "Step 10: Train 0.147 -> 0.127, Validation: 0.1703033298254013\n"
     ]
    }
   ],
   "source": [
    "num_steps = 200\n",
    "num_epochs = 20\n",
    "seq_length = 16\n",
    "batch_size = 200\n",
    "valid_size = 1000\n",
    "\n",
    "\n",
    "valid_x, valid_y = zip(*[gen_sample_v0(seq_length) for i in range(valid_size)])\n",
    "valid_batch = {tf_src_x: valid_x, tf_src_y: valid_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        train_x, train_y = zip(*[gen_sample_v0(seq_length) for i in range(batch_size)])\n",
    "        train_batch = {tf_src_x: train_x, tf_src_y: train_y}\n",
    "\n",
    "        start_loss = tf_loss.eval(feed_dict=train_batch)\n",
    "        for j in range(num_steps):\n",
    "            tf_train.run(feed_dict=train_batch)\n",
    "        \n",
    "        end_loss = tf_loss.eval(feed_dict=train_batch)\n",
    "        valid_loss = tf_loss.eval(feed_dict=valid_batch)\n",
    "        \n",
    "        print('Step {0}: Train {1:1.3} -> {2:1.3}, Validation: {3}'.format(i, start_loss, end_loss, valid_loss))\n",
    "    final_p, final_loss, final_accuracy = sess.run([tf_prob, tf_loss, tf_accuracy], feed_dict=valid_batch)\n",
    "print('Final Cross-Entropy Loss: {0:1.4}\\nFinal Accuracy: {1:1.4}'.format(final_loss, final_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for V-0\n",
    "### BasicRNNCell\n",
    "1) 1 unit $\\rightarrow$ Loss = $0.3230$, Accuracy = $0.8501$\n",
    "\n",
    "2) 2 units $\\rightarrow$ Loss = $0.2982$, Accuracy = $0.8465$\n",
    "\n",
    "3) 3 units $\\rightarrow$ Loss = $0.1743$, Accuracy = $0.9051$\n",
    "\n",
    "4) 4 units $\\rightarrow$ Loss = $0.1536$, Accuracy = $0.9103$ (Almost instant convergence)\n",
    "\n",
    "5) 5 units $\\rightarrow$ Loss = $0.1490$, Accuracy = $0.9089$ (Almost instant convergence)\n",
    "\n",
    "6) 10 units $\\rightarrow$ Loss = $0.1681$, Accuracy = $0.9084$ (Almost instant convergence & overtraining)\n",
    "\n",
    "7) 30 units $\\rightarrow$ Loss = $0.2426$, Accuracy = $0.9071$ (No convergence, overtraining on train sample)\n",
    "\n",
    "### BasicLSTMCell\n",
    "1) 1 unit $\\rightarrow$ Loss = $0.2911$, Accuracy = $0.8503$\n",
    "\n",
    "2) 2 units $\\rightarrow$ Loss = $0.2168$, Accuracy = $0.8944$ (Slow convergence)\n",
    "\n",
    "3) 3 units $\\rightarrow$ Loss = $0.1515$, Accuracy = $0.9087$\n",
    "\n",
    "4) 4 units $\\rightarrow$ Loss = $0.1680$, Accuracy = $0.9134$ \n",
    "\n",
    "5) 5 units $\\rightarrow$ Loss = $0.1732$, Accuracy = $0.9100$ \n",
    "\n",
    "6) 10 units $\\rightarrow$ Loss = $0.1855$, Accuracy = $0.9113$ (Overtraining)\n",
    "\n",
    "### GRUCell\n",
    "1) 1 unit $\\rightarrow$ Loss = $0.3166$, Accuracy = $0.8268$\n",
    "\n",
    "2) 2 units $\\rightarrow$ Loss = $0.2756$, Accuracy = $0.8586$\n",
    "\n",
    "3) 3 units $\\rightarrow$ Loss = $0.1854$, Accuracy = $0.9062$\n",
    "\n",
    "4) 4 units $\\rightarrow$ Loss = $0.1680$, Accuracy = $0.9134$ \n",
    "\n",
    "5) 5 units $\\rightarrow$ Loss = $0.1732$, Accuracy = $0.9100$ \n",
    "\n",
    "6) 10 units $\\rightarrow$ Loss = $0.1855$, Accuracy = $0.9113$ (Overtraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.52 0.99 0.99 4.3e-06 0.0059 0.98 0.0023 0.0055 0.0052 0.54 0.99 0.99 6.6e-06 0.99 0.003 0.0022'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
