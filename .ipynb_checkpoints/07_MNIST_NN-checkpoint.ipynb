{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import struct\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "\n",
    "root_dir = \"D:/Jupyter/\";\n",
    "logs_dir = root_dir + \"Logs/\"\n",
    "data_dir = root_dir + 'Datasets/'\n",
    "\n",
    "def mnist_read_imgs(fname):\n",
    "    with open(fname, mode='rb') as f:\n",
    "        (_, img_num, img_xsize, img_ysize) = struct.unpack('>IIII',f.read(4 * 4))\n",
    "        data_img = np.fromfile(f, dtype=np.uint8).reshape(img_num, img_xsize, img_ysize)\n",
    "    return data_img\n",
    "\n",
    "def mnist_read_lbls(fname):\n",
    "    with open(data_dir + 'MNIST/train-labels.idx1-ubyte', mode='rb') as f:\n",
    "        (_, lab_num) = struct.unpack('>II', f.read(4 * 2))\n",
    "        data_lab = np.fromfile(f, dtype=np.uint8)\n",
    "    return data_lab\n",
    "\n",
    "def minibatch(X, y, num=1000):\n",
    "    inds = np.random.choice(range(X.shape[0]), size=num)\n",
    "    return X[inds], y[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_X = mnist_read_imgs(data_dir+'MNIST/train-images.idx3-ubyte')\n",
    "src_y = mnist_read_lbls(data_dir+'MNIST/train-labels.idx1-ubyte')\n",
    "\n",
    "random_seed = 42\n",
    "(dev_X, test_X, dev_y, test_y) = sklearn.model_selection.train_test_split(src_X, src_y, random_state=random_seed, test_size=0.2)\n",
    "(train_X, valid_X, train_y, valid_y) = sklearn.model_selection.train_test_split(dev_X, dev_y, random_state=random_seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Neural Networks\n",
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist1d_transform_imgs(x):\n",
    "    return x.reshape(x.shape[0], x.shape[1] * x.shape[2]) / 255\n",
    "\n",
    "def mnist1d_transform_lbls(y):\n",
    "    return np.array([1.0*(y==i) for i in range(10)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train1d_X, valid1d_X, test1d_X) = (mnist1d_transform_imgs(x) for x in (train_X, valid_X, test_X))\n",
    "(train1d_y, valid1d_y, test1d_y) = (mnist1d_transform_lbls(y) for y in (train_y, valid_y, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-hidden layer network\n",
    "Current accuracy on validation is __92.5%__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "log_dir = root_dir + 'Logs/' + dt_now + '-LR-S-B5k'\n",
    "\n",
    "tf_LearningRate = tf.placeholder(shape=(), name='LearningRate', dtype=tf.float32)\n",
    "tf_Input = tf.placeholder(shape=(None, 784), name='Input', dtype=tf.float32)\n",
    "tf_Labels = tf.placeholder(shape=(None, 10), name='Labels', dtype=tf.float32)\n",
    "\n",
    "tf_Output = tf.layers.dense(tf_Input, 10, use_bias=True, name='LogisticRegression')\n",
    "\n",
    "tf_OutProb = tf.nn.softmax(tf_Output)\n",
    "\n",
    "tf_Error = -tf.reduce_mean(tf.reduce_sum(tf_Labels * tf.log(tf_OutProb), reduction_indices=1))\n",
    "tf_Optimizer = tf.train.GradientDescentOptimizer(tf_LearningRate)\n",
    "tf_TrainStep = tf_Optimizer.minimize(tf_Error)\n",
    "\n",
    "tf_Initialize = tf.global_variables_initializer()\n",
    "\n",
    "tf_ErrorSummary = tf.summary.scalar('Error', tf_Error)\n",
    "tf_FW = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_steps = 100\n",
    "batch_size = 5000\n",
    "learning_rate = 0.5\n",
    "fulltrain_batch = {tf_Input: train1d_X, tf_Labels:train1d_y}\n",
    "validation_batch = {tf_Input: valid1d_X, tf_Labels: valid1d_y}\n",
    "test_batch = {tf_Input: test1d_X, tf_Labels: test1d_y}\n",
    "with tf.Session() as sess:\n",
    "    tf_Initialize.run()\n",
    "    for i in range(num_epochs):\n",
    "        if i > 10:\n",
    "            learning_rate = 0.2\n",
    "        if i > 50:\n",
    "            learning_rate = 0.1\n",
    "        tX, ty = minibatch(train1d_X, train1d_y, num=batch_size)\n",
    "        batch = {tf_Input: tX, tf_Labels:ty, tf_LearningRate: learning_rate}\n",
    "        for j in range(num_steps):\n",
    "            tf_TrainStep.run(feed_dict=batch)\n",
    "        \n",
    "        sumstr = tf_ErrorSummary.eval(feed_dict=validation_batch)\n",
    "        tf_FW.add_summary(sumstr, i)\n",
    "    train1d_nn0_prob = tf_OutProb.eval(feed_dict=fulltrain_batch)\n",
    "    valid1d_nn0_prob = tf_OutProb.eval(feed_dict=validation_batch)\n",
    "    test1d_nn0_prob = tf_OutProb.eval(feed_dict=test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 933,    0,    2,    1,    5,   11,    2,    0,    8,    1],\n",
       "       [   0, 1076,    2,    0,    1,    6,    1,    1,    9,    3],\n",
       "       [   8,   12,  818,   18,   10,    4,   12,   13,   20,    8],\n",
       "       [   2,    2,   23,  928,    2,   25,    2,    9,   26,    3],\n",
       "       [   1,    4,    7,    1,  887,    0,    8,    3,   11,   39],\n",
       "       [   5,    6,    7,   29,    5,  753,   15,    1,   19,    4],\n",
       "       [   4,    5,    5,    0,   11,   16,  903,    0,    4,    0],\n",
       "       [   1,    7,    7,    3,    5,    3,    1,  901,    0,   50],\n",
       "       [   4,   16,    7,   21,    1,   23,    5,    2,  816,   27],\n",
       "       [   5,    4,    0,    8,   26,    6,    0,   25,    3,  863]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.92479166666666668"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(sklearn.metrics.confusion_matrix(valid_y, np.argmax(valid1d_nn0_prob, axis=1)))\n",
    "sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn0_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-hidden layer network\n",
    "Current accuracy on validation is __97.3%__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "log_dir = root_dir + 'Logs/' + dt_now + '-H200-LR-S-B5k'\n",
    "\n",
    "tf_LearningRate = tf.placeholder(shape=(), name='LearningRate', dtype=tf.float32)\n",
    "tf_Input = tf.placeholder(shape=(None, 784), name='Input', dtype=tf.float32)\n",
    "tf_Labels = tf.placeholder(shape=(None, 10), name='Labels', dtype=tf.float32)\n",
    "\n",
    "tf_Hidden = tf.layers.dense(tf_Input, 200, use_bias=True, activation=tf.nn.elu, name='Hidden-1')\n",
    "tf_Output = tf.layers.dense(tf_Hidden, 10, use_bias=True, name='SoftMax')\n",
    "\n",
    "tf_OutProb = tf.nn.softmax(tf_Output)\n",
    "\n",
    "tf_Error = -tf.reduce_mean(tf.reduce_sum(tf_Labels * tf.log(tf_OutProb), reduction_indices=1))\n",
    "tf_Optimizer = tf.train.GradientDescentOptimizer(tf_LearningRate)\n",
    "tf_TrainStep = tf_Optimizer.minimize(tf_Error)\n",
    "\n",
    "tf_Initialize = tf.global_variables_initializer()\n",
    "\n",
    "tf_ErrorSummary = tf.summary.scalar('Error', tf_Error)\n",
    "tf_FW = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_steps = 100\n",
    "batch_size = 5000\n",
    "learning_rate = 0.5\n",
    "fulltrain_batch = {tf_Input: train1d_X, tf_Labels:train1d_y}\n",
    "validation_batch = {tf_Input: valid1d_X, tf_Labels: valid1d_y}\n",
    "test_batch = {tf_Input: test1d_X, tf_Labels: test1d_y}\n",
    "with tf.Session() as sess:\n",
    "    tf_Initialize.run()\n",
    "    for i in range(num_epochs):\n",
    "        if i > 10:\n",
    "            learning_rate = 0.2\n",
    "        if i > 50:\n",
    "            learning_rate = 0.1\n",
    "        tX, ty = minibatch(train1d_X, train1d_y, num=batch_size)\n",
    "        batch = {tf_Input: tX, tf_Labels:ty, tf_LearningRate: learning_rate}\n",
    "        for j in range(num_steps):\n",
    "            tf_TrainStep.run(feed_dict=batch)\n",
    "        \n",
    "        sumstr = tf_ErrorSummary.eval(feed_dict=validation_batch)\n",
    "        tf_FW.add_summary(sumstr, i)\n",
    "    train1d_nn1_prob = tf_OutProb.eval(feed_dict=fulltrain_batch)\n",
    "    valid1d_nn1_prob = tf_OutProb.eval(feed_dict=validation_batch)\n",
    "    test1d_nn1_prob = tf_OutProb.eval(feed_dict=test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97281249999999997"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn1_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-hidden layer network\n",
    "With 300-300 combination, dropout and res-net hack arrived at __98.1%__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "log_dir = root_dir + 'Logs/' + dt_now + '-H300-H300-DROP-RES-LR-S-B5k-GD'\n",
    "\n",
    "tf_Training = tf.placeholder(shape=(), name='Training', dtype=tf.bool)\n",
    "tf_LearningRate = tf.placeholder(shape=(), name='LearningRate', dtype=tf.float32)\n",
    "tf_Input = tf.placeholder(shape=(None, 784), name='Input', dtype=tf.float32)\n",
    "tf_Labels = tf.placeholder(shape=(None, 10), name='Labels', dtype=tf.float32)\n",
    "\n",
    "tf_Hidden1 = tf.layers.dense(tf_Input, 300, use_bias=True, activation=tf.nn.relu, name='Hidden-1')\n",
    "tf_Hidden2 = tf.layers.dense(tf.layers.dropout(tf_Hidden1, training=tf_Training),\n",
    "                             300, use_bias=True, activation=tf.nn.relu, name='Hidden-2')\n",
    "tf_Output = tf.layers.dense(tf.layers.dropout(tf.concat([tf_Hidden1, tf_Hidden2], axis=1), training=tf_Training),\n",
    "                            10, use_bias=True, name='SoftMax')\n",
    "\n",
    "tf_OutProb = tf.nn.softmax(tf_Output)\n",
    "\n",
    "#tf_Error = -tf.reduce_mean(tf.reduce_sum(tf_Labels * tf.log(tf_OutProb), reduction_indices=1))\n",
    "tf_Error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_Labels, logits=tf_Output))\n",
    "tf_TrainStep = tf.train.GradientDescentOptimizer(tf_LearningRate).minimize(tf_Error)\n",
    "\n",
    "tf_Initialize = tf.global_variables_initializer()\n",
    "\n",
    "tf_ErrorSummary = tf.summary.scalar('Error', tf_Error)\n",
    "tf_FW = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_steps = 100\n",
    "batch_size = 5000\n",
    "learning_rate = 0.5\n",
    "fulltrain_batch = {tf_Training: False, tf_Input: train1d_X, tf_Labels:train1d_y}\n",
    "validation_batch = {tf_Training: False, tf_Input: valid1d_X, tf_Labels: valid1d_y}\n",
    "test_batch = {tf_Training: False, tf_Input: test1d_X, tf_Labels: test1d_y}\n",
    "with tf.Session() as sess:\n",
    "    tf_Initialize.run()\n",
    "    for i in range(num_epochs):\n",
    "        if i > 10:\n",
    "            learning_rate = 0.2\n",
    "        if i > 25:\n",
    "            learning_rate = 0.1\n",
    "        tX, ty = minibatch(train1d_X, train1d_y, num=batch_size)\n",
    "        batch = {tf_Training: True, tf_Input: tX, tf_Labels:ty, tf_LearningRate: learning_rate}\n",
    "        for j in range(num_steps):\n",
    "            tf_TrainStep.run(feed_dict=batch)\n",
    "        \n",
    "        sumstr = tf_ErrorSummary.eval(feed_dict=validation_batch)\n",
    "        tf_FW.add_summary(sumstr, i)\n",
    "    train1d_nn2_prob = tf_OutProb.eval(feed_dict=fulltrain_batch)\n",
    "    valid1d_nn2_prob = tf_OutProb.eval(feed_dict=validation_batch)\n",
    "    test1d_nn2_prob = tf_OutProb.eval(feed_dict=test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98052083333333329"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn2_prob, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99843749999999998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.98062499999999997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.98024999999999995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sklearn.metrics.accuracy_score(train_y, np.argmax(train1d_nn2_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn2_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(test_y, np.argmax(test1d_nn2_prob, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99382812499999995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.97437499999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.97233333333333338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sklearn.metrics.accuracy_score(train_y, np.argmax(train1d_nn1_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn1_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(test_y, np.argmax(test1d_nn1_prob, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92942708333333335"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.92343750000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.92133333333333334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sklearn.metrics.accuracy_score(train_y, np.argmax(train1d_nn0_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(valid_y, np.argmax(valid1d_nn0_prob, axis=1)))\n",
    "display(sklearn.metrics.accuracy_score(test_y, np.argmax(test1d_nn0_prob, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytfgpu]",
   "language": "python",
   "name": "conda-env-pytfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
