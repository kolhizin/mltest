{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, os.path\n",
    "\n",
    "data_dir = '../DataSets/FaceNet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(image_paths, image_size, batch_size, max_nrof_epochs, num_threads):\n",
    "    \"\"\"\n",
    "    Creates Tensorflow Queue to batch load images. Applies transformations to images as they are loaded.\n",
    "    :param image_paths: image paths to load\n",
    "    :param image_size: size to resize images to\n",
    "    :param batch_size: num of images to load in batch\n",
    "    :param max_nrof_epochs: total number of epochs to read through image list\n",
    "    :param num_threads: num threads to use\n",
    "    :return: images and labels of batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    images = ops.convert_to_tensor(image_paths, dtype=tf.string)\n",
    "\n",
    "    # Makes an input queue\n",
    "    input_queue = tf.train.slice_input_producer(images,\n",
    "                                                num_epochs=max_nrof_epochs, shuffle=False)\n",
    "\n",
    "    imgs = []\n",
    "    for _ in range(num_threads):\n",
    "        image = read_image_from_disk(filename=input_queue)\n",
    "        image = tf.random_crop(image, size=[image_size, image_size, 3])\n",
    "        image.set_shape((image_size, image_size, 3))\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "\n",
    "        imgs.append(image)\n",
    "\n",
    "    image_batch = tf.train.batch_join(imgs, batch_size=batch_size, capacity=4 * num_threads, enqueue_many=False, allow_smaller_final_batch=True)\n",
    "    return image_batch\n",
    "\n",
    "\n",
    "def read_image_from_disk(filename):\n",
    "    \"\"\"\n",
    "    Consumes input tensor and loads image\n",
    "    :param filename_to_label_tuple: \n",
    "    :type filename_to_label_tuple: list\n",
    "    :return: tuple of image and label\n",
    "    \"\"\"\n",
    "    file_contents = tf.read_file(filename)\n",
    "    example = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "    return example\n",
    "\n",
    "\n",
    "def get_dataset(input_directory):\n",
    "    imgs = [f for f in os.listdir(img_path) if os.path.isfile(img_path+f) and f.split('.')[-1].lower() in ('jpg', 'jpeg')]\n",
    "    return [(f, input_directory+f) for f in imgs]\n",
    "\n",
    "class ImageClass():\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_embeddings(input_directory, model_fname, classifier_output_path, batch_size, num_threads, num_epochs,\n",
    "         min_images_per_labels, split_ratio):\n",
    "    \"\"\"\n",
    "    Loads images from :param input_dir, creates embeddings using a model defined at :param model_path, and trains\n",
    "     a classifier outputted to :param output_path\n",
    "     \n",
    "    :param input_directory: Path to directory containing pre-processed images\n",
    "    :param model_path: Path to protobuf graph file for facenet model\n",
    "    :param classifier_output_path: Path to write pickled classifier\n",
    "    :param batch_size: Batch size to create embeddings\n",
    "    :param num_threads: Number of threads to utilize for queuing\n",
    "    :param num_epochs: Number of epochs for each image\n",
    "    :param min_images_per_labels: Minimum number of images per class\n",
    "    :param split_ratio: Ratio to split train/test dataset\n",
    "    :param is_train: bool denoting if training or evaluate\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "        dataset = get_dataset(input_directory)\n",
    "        images = _load_images(dataset, image_size=160, batch_size=batch_size, num_threads=num_threads, num_epochs=1)\n",
    "\n",
    "        _load_model(model_fname)\n",
    "\n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embedding_layer = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "        emb_array, label_array = _create_embeddings(embedding_layer, images, labels, images_placeholder,\n",
    "                                                    phase_train_placeholder, sess)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads=threads)\n",
    "    return emb_array\n",
    "\n",
    "def _load_images(dataset, image_size, batch_size, num_threads, num_epochs, random_flip=False,\n",
    "                            random_brightness=False, random_contrast=False):\n",
    "    image_paths = [x[1] for x in dataset]\n",
    "    images = read_data(image_paths, image_size, batch_size, num_epochs, num_threads)\n",
    "    return images\n",
    "\n",
    "\n",
    "def _load_model(model_fname):\n",
    "    \"\"\"\n",
    "    Load frozen protobuf graph\n",
    "    :param model_filepath: Path to protobuf graph\n",
    "    :type model_filepath: str\n",
    "    \"\"\"\n",
    "    #t_input = 'input:0'\n",
    "    #t_output = 'MobilenetV1/Predictions/Reshape:0'\n",
    "    tf_graph_def = tf.GraphDef()\n",
    "    with open(model_fname, 'rb') as f:\n",
    "        tf_graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(tf_graph_def, name='')\n",
    "\n",
    "\n",
    "def _create_embeddings(embedding_layer, images, images_placeholder, phase_train_placeholder, sess):\n",
    "    \"\"\"\n",
    "    Uses model to generate embeddings from :param images.\n",
    "    :param embedding_layer: \n",
    "    :param images: \n",
    "    :param images_placeholder: \n",
    "    :param phase_train_placeholder: \n",
    "    :param sess: \n",
    "    :return: (tuple): image embeddings and labels\n",
    "    \"\"\"\n",
    "    emb_array = None\n",
    "    try:\n",
    "        i = 0\n",
    "        while True:\n",
    "            batch_images = sess.run(images)\n",
    "            emb = sess.run(embedding_layer,feed_dict={images_placeholder: batch_images, phase_train_placeholder: False})\n",
    "\n",
    "            emb_array = np.concatenate([emb_array, emb]) if emb_array is not None else emb\n",
    "            i += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    return emb_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_embeddings(data_dir + 'proc_images/', data_dir+'')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
