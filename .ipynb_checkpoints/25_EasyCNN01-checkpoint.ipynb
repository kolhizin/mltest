{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time, datetime\n",
    "import sklearn, sklearn.metrics, sklearn.decomposition\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "dev_batches = 'D:/Jupyter/DataSets/prv/dev0_batch{0:03d}.npy'\n",
    "train_batches = range(3)\n",
    "test_batches = range(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_graph(input_shape, cnn_arch, fc_arch, num_classes):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.name_scope('Input'):\n",
    "        tf_in_x = tf.placeholder(tf.float32, shape=(None, input_shape[0], input_shape[1], 1))\n",
    "        tf_in_y = tf.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "    tf_temp = tf_in_x\n",
    "    for (i, (conv_filters, conv_size, conv_stride, pool_size, pool_stride)) in enumerate(cnn_arch):\n",
    "        with tf.name_scope('Conv-MaxPool-{:02d}'.format(i)):\n",
    "            tf_temp = tf.layers.conv2d(tf_temp, conv_filters, conv_size, conv_stride, activation=tf.nn.relu)\n",
    "            tf_temp = tf.layers.max_pooling2d(tf_temp, pool_size, pool_stride)\n",
    "\n",
    "    with tf.name_scope('FC'):\n",
    "        tf_temp = tf.contrib.layers.flatten(tf_temp)\n",
    "        for sz in fc_arch:\n",
    "            tf_temp = tf.layers.dense(tf_temp, sz, activation=tf.nn.elu)\n",
    "            \n",
    "        tf_final = tf.layers.dense(tf_temp, num_classes)\n",
    "        tf_prob = tf.nn.softmax(tf_final)\n",
    "        tf_predicted = tf.cast(tf.argmax(tf_prob, axis=1), dtype=tf.int32)\n",
    "\n",
    "    with tf.name_scope('LOSS'):\n",
    "        tf_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf_in_y, logits=tf_final))\n",
    "        tf_train = tf.train.AdamOptimizer(1e-3).minimize(tf_loss)\n",
    "        \n",
    "        tf_rocauc, tf_upd_rocuac = tf.metrics.auc(labels=tf_in_y, predictions=tf_prob[:,1], num_thresholds=10000)\n",
    "        tf_gini = tf_rocauc * 2 - 1\n",
    "        tf_accuracy, tf_upd_accuracy = tf.metrics.accuracy(labels=tf_in_y, predictions=tf_predicted)\n",
    "        tf_update_metrics = tf.group(tf_upd_rocuac, tf_upd_accuracy)\n",
    "        \n",
    "        tfsummary_logloss = tf.summary.scalar('Log-Loss', tf_loss)\n",
    "        tfsummary_gini = tf.summary.scalar('1-Gini', 1-tf_gini)\n",
    "        tfsummary_accuracy = tf.summary.scalar('1-Accuracy', 1-tf_accuracy)\n",
    "        tfsummary = tf.summary.merge([tfsummary_logloss, tfsummary_gini, tfsummary_accuracy])\n",
    "\n",
    "    return {'in':{'data':tf_in_x, 'label':tf_in_y},\n",
    "            'out':{'logit':tf_final, 'prob':tf_prob},\n",
    "            'run':{'loss': tf_loss, 'upd_metrics':tf_update_metrics,\n",
    "                   'gini':tf_gini, 'accuracy':tf_accuracy,\n",
    "                   'train': tf_train, 'summary':tfsummary}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph created\n",
      "Preparation complete\n"
     ]
    }
   ],
   "source": [
    "graph_descr = build_cnn_graph((128, 128), [(20, 5, 1, 3, 3)], [], 2)\n",
    "model_name = '25EasyCNN01'\n",
    "\n",
    "tffw_graph = tf.summary.FileWriter('D:/Jupyter/Logs/Graph_{}'.format(model_name), tf.get_default_graph())\n",
    "model_ckpt_name = '../Models/{0}/model'.format(model_name)+'-{:02d}.ckpt'\n",
    "\n",
    "print('Graph created')\n",
    "\n",
    "batch_steps = 1\n",
    "batch_size  = 64\n",
    "calc_batch_size = 1024\n",
    "\n",
    "set2dict = lambda x: {graph_descr['in']['data']: x[0],\n",
    "                           graph_descr['in']['label']: x[1]}\n",
    "\n",
    "\n",
    "print('Preparation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_tf_calc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-70cd19763de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             test_res.append(run_tf_calc(tfs, (test_x, test_y), batch_size, set2dict,\n\u001b[0m\u001b[0;32m     29\u001b[0m                                   [graph_descr['run']['loss'], graph_descr['out']['prob']]))\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_tf_calc' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "tffw_train = tf.summary.FileWriter('D:/Jupyter/Logs/Run_{0}-{1}-T'.format(model_name, dt_now), tf.get_default_graph())\n",
    "tffw_valid = tf.summary.FileWriter('D:/Jupyter/Logs/Run_{0}-{1}-V'.format(model_name, dt_now), tf.get_default_graph())\n",
    "tfsSaver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    tfs.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for n in range(num_epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        for batch in train_batches:\n",
    "            data = np.load(dev_batches.format(batch))\n",
    "            train_x = data[:,2:].reshape(-1,128,128,1)\n",
    "            train_y = data[:,1].reshape(-1).astype(np.int32)\n",
    "            modutils.runEpoch(tfs, (train_x, train_y), batch_size, set2dict,\n",
    "                          graph_descr['run']['train'],\n",
    "                         op_loss=graph_descr['run']['loss'], verbatim=True)\n",
    "            \n",
    "        test_res = []\n",
    "        for batch in test_batches:\n",
    "            data = np.load(dev_batches.format(batch))\n",
    "            test_x = data[:,2:].reshape(-1,128,128,1)\n",
    "            test_y = data[:,1].reshape(-1).astype(np.int32)\n",
    "            test_res.append(modutils.runDataset(tfs, (test_x, test_y), batch_size, set2dict,\n",
    "                                  [graph_descr['run']['loss'], graph_descr['out']['prob']]))\n",
    "            \n",
    "        \n",
    "        #test_res = run_tf_calc(tfs, test_set, calc_batch_size, set2dict,\n",
    "        #                       [graph_descr['run']['loss'], graph_descr['out']['prob']])\n",
    "        \n",
    "        #test_loss = np.sum([x[1] * x[2][0] for x in test_res]) / np.sum([x[1] for x in test_res])\n",
    "        #test_p = np.concatenate([x[2][1] for x in test_res])\n",
    "        #gini = sklearn.metrics.roc_auc_score(test_y, test_p[:,1])*2-1\n",
    "        #accur = sklearn.metrics.accuracy_score(test_y, 1*(test_p[:,1]>0.5))\n",
    "        \n",
    "        #tfs.run(graph_descr['run']['upd_metrics'], stat_train_dict)\n",
    "        #train_stats = tfs.run([graph_descr['run']['loss'], graph_descr['run']['gini'],\n",
    "        #                     graph_descr['run']['accuracy'], graph_descr['run']['summary']], stat_train_dict)\n",
    "        #tffw_train.add_summary(train_stats[-1], n)\n",
    "        \n",
    "        #tfs.run(graph_descr['run']['upd_metrics'], stat_valid_dict)\n",
    "        #valid_stats = tfs.run([graph_descr['run']['loss'], graph_descr['run']['gini'],\n",
    "        #                     graph_descr['run']['accuracy'], graph_descr['run']['summary']], stat_valid_dict)\n",
    "        #tffw_valid.add_summary(valid_stats[-1], n)\n",
    "        \n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        p = tfsSaver.save(tfs, model_ckpt_name.format(n))\n",
    "        print('Model saved at checkpoint: {0}'.format(p))        \n",
    "        print('Epoch {0}: {1:.3f} in {2:.2f} sec'.format(n, 0, t1-t0))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
