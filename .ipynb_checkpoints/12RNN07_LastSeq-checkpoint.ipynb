{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObs(length):\n",
    "    return np.random.choice(range(3), size=length)\n",
    "\n",
    "#very simple -- gru-rnn with 5 neurons cracks it\n",
    "#def genTarget(x):\n",
    "#    return ''.join([str(z) for z in x]).find('012')\n",
    "\n",
    "def genTarget(x):\n",
    "    y0 = ''.join([str(z) for z in x])\n",
    "    return y0.count(y0[:2])\n",
    "\n",
    "def genSample(num, length=20):\n",
    "    x = [genObs(length=length) for _ in range(num)]\n",
    "    y = [genTarget(t) for t in x]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def randomBatch(tensorTuple, batchSize=64):\n",
    "    ids = np.random.choice(range(tensorTuple[0].shape[0]), batchSize)\n",
    "    return (x[ids,] for x in tensorTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1],\n",
       "        [2, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 0, 2, 0],\n",
       "        [2, 2, 1, 2, 1, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 0, 0, 2],\n",
       "        [2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 2, 1, 1, 2, 0],\n",
       "        [1, 2, 1, 0, 1, 0, 2, 1, 1, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2],\n",
       "        [1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 1],\n",
       "        [0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1],\n",
       "        [2, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 0, 1, 1, 1, 2, 2],\n",
       "        [2, 0, 2, 2, 0, 2, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 1, 0, 1, 1],\n",
       "        [2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2]]),\n",
       " array([3, 4, 2, 2, 1, 2, 2, 2, 4, 3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = genSample(20000)\n",
    "valid_x, valid_y = genSample(2000)\n",
    "valid_x[:10], valid_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "RNN_SIZE = [5,5]\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.elu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.float32)\n",
    "tfi_y = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "\n",
    "tfX = tf.reshape(tfi_x, shape=(tf.shape(tfi_x)[0], tf.shape(tfi_x)[1], 1))\n",
    "tfY = tf.reshape(tfi_y, shape=(tf.shape(tfi_y)[0], 1))\n",
    "\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE])\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0])\n",
    "\n",
    "_, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfOut = tf.layers.dense(tfO[-1], 1)\n",
    "\n",
    "tfLoss = tf.sqrt(tf.reduce_mean(tf.square(tfY - tfOut)))\n",
    "tfTrain = tf.train.AdamOptimizer(1e-3).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.cast(tf.round(tfOut),dtype=tf.int64)\n",
    "\n",
    "tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tfY, dtype=tf.int64), tf.cast(tf.round(tfOut),dtype=tf.int64)), dtype=tf.float32))\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.579 sec): loss changed from 3.72 to 3.2\t\tVL:3.118\t\tAC:0.000\n",
      "Epoch 10 (0.572 sec): loss changed from 1.12 to 1.12\t\tVL:1.141\t\tAC:0.306\n",
      "Epoch 20 (0.564 sec): loss changed from 1.14 to 1.14\t\tVL:1.145\t\tAC:0.303\n",
      "Epoch 30 (0.561 sec): loss changed from 1.16 to 1.16\t\tVL:1.147\t\tAC:0.303\n",
      "Epoch 40 (0.558 sec): loss changed from 1.14 to 1.14\t\tVL:1.141\t\tAC:0.303\n",
      "Epoch 50 (0.558 sec): loss changed from 1.14 to 1.14\t\tVL:1.141\t\tAC:0.303\n",
      "Epoch 60 (0.563 sec): loss changed from 1.16 to 1.16\t\tVL:1.141\t\tAC:0.303\n",
      "Epoch 70 (0.566 sec): loss changed from 1.11 to 1.11\t\tVL:1.140\t\tAC:0.303\n",
      "Epoch 80 (0.584 sec): loss changed from 1.1 to 1.1\t\tVL:1.139\t\tAC:0.303\n",
      "Epoch 90 (0.559 sec): loss changed from 1.15 to 1.15\t\tVL:1.142\t\tAC:0.303\n",
      "Epoch 100 (0.564 sec): loss changed from 1.17 to 1.16\t\tVL:1.141\t\tAC:0.303\n",
      "Epoch 110 (0.612 sec): loss changed from 1.17 to 1.17\t\tVL:1.140\t\tAC:0.303\n",
      "Epoch 120 (0.588 sec): loss changed from 1.15 to 1.15\t\tVL:1.140\t\tAC:0.303\n",
      "Epoch 130 (0.602 sec): loss changed from 1.14 to 1.14\t\tVL:1.140\t\tAC:0.303\n",
      "Epoch 140 (0.59 sec): loss changed from 1.14 to 1.14\t\tVL:1.145\t\tAC:0.303\n",
      "Epoch 150 (0.711 sec): loss changed from 1.12 to 1.12\t\tVL:1.135\t\tAC:0.303\n",
      "Epoch 160 (0.56 sec): loss changed from 1.09 to 1.08\t\tVL:1.081\t\tAC:0.341\n",
      "Epoch 170 (0.58 sec): loss changed from 0.998 to 0.992\t\tVL:1.036\t\tAC:0.364\n",
      "Epoch 180 (0.674 sec): loss changed from 1.01 to 0.994\t\tVL:1.025\t\tAC:0.368\n",
      "Epoch 190 (0.573 sec): loss changed from 1.0 to 0.98\t\tVL:1.012\t\tAC:0.373\n",
      "Epoch 200 (0.568 sec): loss changed from 0.955 to 0.941\t\tVL:0.988\t\tAC:0.385\n",
      "Epoch 210 (0.569 sec): loss changed from 0.96 to 0.939\t\tVL:0.963\t\tAC:0.391\n",
      "Epoch 220 (0.566 sec): loss changed from 0.944 to 0.923\t\tVL:0.953\t\tAC:0.404\n",
      "Epoch 230 (0.572 sec): loss changed from 0.91 to 0.886\t\tVL:0.949\t\tAC:0.417\n",
      "Epoch 240 (0.571 sec): loss changed from 0.889 to 0.873\t\tVL:0.929\t\tAC:0.410\n",
      "Epoch 250 (0.574 sec): loss changed from 0.917 to 0.898\t\tVL:0.919\t\tAC:0.424\n",
      "Epoch 260 (0.582 sec): loss changed from 0.894 to 0.88\t\tVL:0.914\t\tAC:0.428\n",
      "Epoch 270 (0.566 sec): loss changed from 0.884 to 0.864\t\tVL:0.911\t\tAC:0.427\n",
      "Epoch 280 (0.594 sec): loss changed from 0.901 to 0.876\t\tVL:0.897\t\tAC:0.436\n",
      "Epoch 290 (0.574 sec): loss changed from 0.883 to 0.857\t\tVL:0.897\t\tAC:0.444\n",
      "Epoch 300 (0.558 sec): loss changed from 0.855 to 0.842\t\tVL:0.875\t\tAC:0.454\n",
      "Epoch 310 (0.585 sec): loss changed from 0.859 to 0.842\t\tVL:0.860\t\tAC:0.460\n",
      "Epoch 320 (0.577 sec): loss changed from 0.854 to 0.823\t\tVL:0.853\t\tAC:0.457\n",
      "Epoch 330 (0.567 sec): loss changed from 0.808 to 0.783\t\tVL:0.835\t\tAC:0.481\n",
      "Epoch 340 (0.727 sec): loss changed from 0.788 to 0.765\t\tVL:0.815\t\tAC:0.488\n",
      "Epoch 350 (0.565 sec): loss changed from 0.793 to 0.77\t\tVL:0.792\t\tAC:0.500\n",
      "Epoch 360 (0.568 sec): loss changed from 0.783 to 0.765\t\tVL:0.784\t\tAC:0.502\n",
      "Epoch 370 (0.558 sec): loss changed from 0.774 to 0.753\t\tVL:0.767\t\tAC:0.514\n",
      "Epoch 380 (0.583 sec): loss changed from 0.749 to 0.729\t\tVL:0.749\t\tAC:0.517\n",
      "Epoch 390 (0.563 sec): loss changed from 0.723 to 0.704\t\tVL:0.737\t\tAC:0.541\n",
      "Epoch 400 (0.567 sec): loss changed from 0.691 to 0.669\t\tVL:0.721\t\tAC:0.553\n",
      "Epoch 410 (0.556 sec): loss changed from 0.731 to 0.707\t\tVL:0.712\t\tAC:0.559\n",
      "Epoch 420 (0.566 sec): loss changed from 0.7 to 0.681\t\tVL:0.696\t\tAC:0.568\n",
      "Epoch 430 (0.555 sec): loss changed from 0.684 to 0.665\t\tVL:0.689\t\tAC:0.578\n",
      "Epoch 440 (0.586 sec): loss changed from 0.668 to 0.641\t\tVL:0.670\t\tAC:0.583\n",
      "Epoch 450 (0.585 sec): loss changed from 0.626 to 0.607\t\tVL:0.659\t\tAC:0.611\n",
      "Epoch 460 (0.597 sec): loss changed from 0.642 to 0.628\t\tVL:0.646\t\tAC:0.623\n",
      "Epoch 470 (0.579 sec): loss changed from 0.658 to 0.637\t\tVL:0.627\t\tAC:0.632\n",
      "Epoch 480 (0.613 sec): loss changed from 0.644 to 0.621\t\tVL:0.609\t\tAC:0.653\n",
      "Epoch 490 (0.571 sec): loss changed from 0.583 to 0.561\t\tVL:0.606\t\tAC:0.656\n",
      "Epoch 499 (0.646 sec): loss changed from 0.606 to 0.591\t\tVL:0.590\t\tAC:0.664\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_steps  = 30\n",
    "num_epochs = 500\n",
    "\n",
    "fmtstr = 'Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.3f}\\t\\tAC:{5:1.3f}'\n",
    "valid_batch = {tfi_x: valid_x, tfi_y: valid_y}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini_x, mini_y = randomBatch((train_x, train_y), batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini_x, tfi_y:mini_y}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        lv = tfLoss.eval(feed_dict=valid_batch)\n",
    "        ac = tfAccuracy.eval(feed_dict=valid_batch)\n",
    "        if i%10 == 0 or i == num_epochs - 1:\n",
    "            print(fmtstr.format(i,t1-t0,l0,l1,lv,ac))\n",
    "    valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 2, 2, 1, 2, 2, 2, 4, 3]),\n",
       " array([3, 3, 2, 3, 2, 2, 3, 2, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic-rnn-5     1.140 loss, 0.303 accuracy (stopped at 200 epochs)\n",
    "#gru-rnn-5       0.998 loss, 0.378 accuracy\n",
    "#gru-rnn-10      0.524 loss, 0.681 accuracy (and still improving fast)\n",
    "#gru-rnn-5-5     0.590 loss, 0.664 accuracy (and still improving fast)\n",
    "valid_y[:10], valid_r[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'reversed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a8dcf376accf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'321'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'reversed'"
     ]
    }
   ],
   "source": [
    "#gru-rnn, 5, elu => 0.143 loss, 0.994 accuracy\n",
    "valid_y[:10], valid_r[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
