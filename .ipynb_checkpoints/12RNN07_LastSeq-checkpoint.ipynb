{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObs(length):\n",
    "    return np.random.choice(range(3), size=length)\n",
    "\n",
    "#very simple -- gru-rnn with 5 neurons cracks it\n",
    "#def genTarget(x):\n",
    "#    return ''.join([str(z) for z in x]).find('012')\n",
    "\n",
    "def genTarget(x):\n",
    "    y0 = ''.join([str(z) for z in x])\n",
    "    return y0.count(y0[:2])\n",
    "\n",
    "def genSample(num, length=20):\n",
    "    x = [genObs(length=length) for _ in range(num)]\n",
    "    y = [genTarget(t) for t in x]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def randomBatch(tensorTuple, batchSize=64):\n",
    "    ids = np.random.choice(range(tensorTuple[0].shape[0]), batchSize)\n",
    "    return (x[ids,] for x in tensorTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 1, 2, 0, 0, 2, 2, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 2, 1, 1, 2, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 2],\n",
       "        [0, 2, 2, 0, 0, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 1, 0, 0, 2, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 1],\n",
       "        [0, 2, 2, 1, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 2],\n",
       "        [0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 1, 2, 1],\n",
       "        [0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0],\n",
       "        [0, 2, 1, 2, 0, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 2, 1, 0, 0, 0]]),\n",
       " array([3, 4, 3, 1, 1, 2, 2, 4, 2, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = genSample(60000)\n",
    "valid_x, valid_y = genSample(5000)\n",
    "test_x, test_y = genSample(5000)\n",
    "valid_x[:10], valid_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "RNN_SIZE = [10]\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.elu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.float32)\n",
    "tfi_y = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "\n",
    "tfX = tf.reshape(tfi_x, shape=(tf.shape(tfi_x)[0], tf.shape(tfi_x)[1], 1))\n",
    "tfY = tf.reshape(tfi_y, shape=(tf.shape(tfi_y)[0], 1))\n",
    "\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE])\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0])\n",
    "\n",
    "_, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfOut = tf.layers.dense(tfO[-1], 1)\n",
    "\n",
    "tfLoss = tf.sqrt(tf.reduce_mean(tf.square(tfY - tfOut)))\n",
    "tfTrain = tf.train.GradientDescentOptimizer(1e-5).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.cast(tf.round(tfOut),dtype=tf.int64)\n",
    "\n",
    "tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tfY, dtype=tf.int64), tf.cast(tf.round(tfOut),dtype=tf.int64)), dtype=tf.float32))\n",
    "\n",
    "tfsLoss = tf.summary.scalar('RMSE', tfLoss)\n",
    "tfsAccuracy = tf.summary.scalar('Accuracy', 1-tfAccuracy)\n",
    "tfsAll = tf.summary.merge([tfsLoss, tfsAccuracy])\n",
    "tfsSaver = tf.train.Saver()\n",
    "\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.55 sec): loss changed from 2.8 to 2.33\t\tVL:2.302\t\tAC:0.117\n",
      "Epoch 10 (0.634 sec): loss changed from 1.14 to 1.14\t\tVL:1.143\t\tAC:0.311\n",
      "Epoch 20 (0.617 sec): loss changed from 1.1 to 1.1\t\tVL:1.135\t\tAC:0.311\n",
      "Epoch 30 (0.539 sec): loss changed from 1.16 to 1.16\t\tVL:1.130\t\tAC:0.312\n",
      "Epoch 40 (0.605 sec): loss changed from 1.14 to 1.14\t\tVL:1.130\t\tAC:0.312\n",
      "Epoch 50 (0.6 sec): loss changed from 1.15 to 1.15\t\tVL:1.129\t\tAC:0.312\n",
      "Epoch 60 (0.683 sec): loss changed from 1.15 to 1.15\t\tVL:1.130\t\tAC:0.312\n",
      "Epoch 70 (0.625 sec): loss changed from 1.14 to 1.13\t\tVL:1.128\t\tAC:0.312\n",
      "Epoch 80 (0.533 sec): loss changed from 1.1 to 1.1\t\tVL:1.128\t\tAC:0.313\n",
      "Epoch 90 (0.678 sec): loss changed from 1.12 to 1.12\t\tVL:1.127\t\tAC:0.312\n",
      "Epoch 100 (0.733 sec): loss changed from 1.13 to 1.12\t\tVL:1.120\t\tAC:0.312\n",
      "Epoch 110 (0.622 sec): loss changed from 1.03 to 1.02\t\tVL:1.040\t\tAC:0.357\n",
      "Epoch 120 (0.535 sec): loss changed from 1.01 to 0.995\t\tVL:1.025\t\tAC:0.360\n",
      "Epoch 130 (0.67 sec): loss changed from 0.992 to 0.989\t\tVL:1.013\t\tAC:0.363\n",
      "Epoch 140 (0.718 sec): loss changed from 0.999 to 0.982\t\tVL:1.008\t\tAC:0.360\n",
      "Epoch 150 (0.526 sec): loss changed from 0.951 to 0.947\t\tVL:1.000\t\tAC:0.364\n",
      "Epoch 160 (0.658 sec): loss changed from 0.984 to 0.977\t\tVL:0.994\t\tAC:0.367\n",
      "Epoch 170 (0.522 sec): loss changed from 0.982 to 0.973\t\tVL:0.985\t\tAC:0.373\n",
      "Epoch 180 (0.522 sec): loss changed from 0.943 to 0.933\t\tVL:0.965\t\tAC:0.374\n",
      "Epoch 190 (0.604 sec): loss changed from 0.898 to 0.882\t\tVL:0.936\t\tAC:0.390\n",
      "Epoch 200 (0.517 sec): loss changed from 0.906 to 0.884\t\tVL:0.887\t\tAC:0.417\n",
      "Epoch 210 (0.695 sec): loss changed from 0.838 to 0.81\t\tVL:0.777\t\tAC:0.479\n",
      "Epoch 220 (0.618 sec): loss changed from 0.675 to 0.653\t\tVL:0.705\t\tAC:0.546\n",
      "Epoch 230 (0.524 sec): loss changed from 0.665 to 0.635\t\tVL:0.666\t\tAC:0.577\n",
      "Epoch 240 (0.569 sec): loss changed from 0.653 to 0.632\t\tVL:0.641\t\tAC:0.601\n",
      "Epoch 250 (0.526 sec): loss changed from 0.634 to 0.619\t\tVL:0.619\t\tAC:0.607\n",
      "Epoch 260 (0.658 sec): loss changed from 0.626 to 0.608\t\tVL:0.615\t\tAC:0.619\n",
      "Epoch 270 (0.63 sec): loss changed from 0.608 to 0.595\t\tVL:0.602\t\tAC:0.633\n",
      "Epoch 280 (0.711 sec): loss changed from 0.595 to 0.581\t\tVL:0.588\t\tAC:0.645\n",
      "Epoch 290 (0.617 sec): loss changed from 0.57 to 0.554\t\tVL:0.582\t\tAC:0.654\n",
      "Epoch 300 (0.516 sec): loss changed from 0.566 to 0.551\t\tVL:0.573\t\tAC:0.650\n",
      "Epoch 310 (0.515 sec): loss changed from 0.558 to 0.541\t\tVL:0.565\t\tAC:0.659\n",
      "Epoch 320 (0.613 sec): loss changed from 0.549 to 0.529\t\tVL:0.555\t\tAC:0.651\n",
      "Epoch 330 (0.575 sec): loss changed from 0.534 to 0.518\t\tVL:0.550\t\tAC:0.664\n",
      "Epoch 340 (0.518 sec): loss changed from 0.529 to 0.505\t\tVL:0.544\t\tAC:0.669\n",
      "Epoch 350 (0.519 sec): loss changed from 0.538 to 0.509\t\tVL:0.533\t\tAC:0.675\n",
      "Epoch 360 (0.516 sec): loss changed from 0.522 to 0.504\t\tVL:0.526\t\tAC:0.679\n",
      "Epoch 370 (0.517 sec): loss changed from 0.54 to 0.515\t\tVL:0.516\t\tAC:0.689\n",
      "Epoch 380 (0.597 sec): loss changed from 0.499 to 0.474\t\tVL:0.507\t\tAC:0.700\n",
      "Epoch 390 (0.702 sec): loss changed from 0.496 to 0.475\t\tVL:0.497\t\tAC:0.708\n",
      "Epoch 400 (0.513 sec): loss changed from 0.476 to 0.45\t\tVL:0.479\t\tAC:0.726\n",
      "Epoch 410 (0.519 sec): loss changed from 0.467 to 0.451\t\tVL:0.465\t\tAC:0.739\n",
      "Epoch 420 (0.636 sec): loss changed from 0.463 to 0.438\t\tVL:0.454\t\tAC:0.751\n",
      "Epoch 430 (0.626 sec): loss changed from 0.428 to 0.413\t\tVL:0.442\t\tAC:0.772\n",
      "Epoch 440 (0.565 sec): loss changed from 0.417 to 0.396\t\tVL:0.437\t\tAC:0.777\n",
      "Epoch 450 (0.651 sec): loss changed from 0.424 to 0.407\t\tVL:0.424\t\tAC:0.784\n",
      "Epoch 460 (0.589 sec): loss changed from 0.429 to 0.407\t\tVL:0.417\t\tAC:0.790\n",
      "Epoch 470 (0.546 sec): loss changed from 0.411 to 0.393\t\tVL:0.411\t\tAC:0.806\n",
      "Epoch 480 (0.517 sec): loss changed from 0.394 to 0.372\t\tVL:0.399\t\tAC:0.812\n",
      "Epoch 490 (0.673 sec): loss changed from 0.383 to 0.368\t\tVL:0.395\t\tAC:0.820\n",
      "Model saved at checkpoint: D:/Jupyter/mltest/Models-12RNN07/model-0500.ckpt\n",
      "Epoch 500 (0.516 sec): loss changed from 0.397 to 0.367\t\tVL:0.379\t\tAC:0.829\n",
      "Epoch 510 (0.787 sec): loss changed from 0.394 to 0.374\t\tVL:0.375\t\tAC:0.833\n",
      "Epoch 520 (0.715 sec): loss changed from 0.358 to 0.336\t\tVL:0.366\t\tAC:0.843\n",
      "Epoch 530 (0.678 sec): loss changed from 0.352 to 0.334\t\tVL:0.354\t\tAC:0.856\n",
      "Epoch 540 (0.523 sec): loss changed from 0.34 to 0.32\t\tVL:0.346\t\tAC:0.862\n",
      "Epoch 550 (0.746 sec): loss changed from 0.347 to 0.331\t\tVL:0.340\t\tAC:0.870\n",
      "Epoch 560 (0.544 sec): loss changed from 0.332 to 0.311\t\tVL:0.327\t\tAC:0.879\n",
      "Epoch 570 (0.544 sec): loss changed from 0.332 to 0.313\t\tVL:0.322\t\tAC:0.888\n",
      "Epoch 580 (0.605 sec): loss changed from 0.301 to 0.281\t\tVL:0.314\t\tAC:0.894\n",
      "Epoch 590 (0.565 sec): loss changed from 0.305 to 0.289\t\tVL:0.308\t\tAC:0.903\n",
      "Epoch 600 (0.627 sec): loss changed from 0.308 to 0.286\t\tVL:0.306\t\tAC:0.903\n",
      "Epoch 610 (0.597 sec): loss changed from 0.298 to 0.285\t\tVL:0.295\t\tAC:0.914\n",
      "Epoch 620 (0.562 sec): loss changed from 0.292 to 0.269\t\tVL:0.303\t\tAC:0.905\n",
      "Epoch 630 (0.635 sec): loss changed from 0.303 to 0.288\t\tVL:0.289\t\tAC:0.918\n",
      "Epoch 640 (0.523 sec): loss changed from 0.285 to 0.271\t\tVL:0.285\t\tAC:0.919\n",
      "Epoch 650 (0.52 sec): loss changed from 0.289 to 0.273\t\tVL:0.281\t\tAC:0.924\n",
      "Epoch 660 (0.519 sec): loss changed from 0.278 to 0.264\t\tVL:0.280\t\tAC:0.923\n",
      "Epoch 670 (0.696 sec): loss changed from 0.273 to 0.259\t\tVL:0.278\t\tAC:0.928\n",
      "Epoch 680 (0.649 sec): loss changed from 0.262 to 0.248\t\tVL:0.276\t\tAC:0.927\n",
      "Epoch 690 (0.802 sec): loss changed from 0.279 to 0.264\t\tVL:0.272\t\tAC:0.933\n",
      "Epoch 700 (0.664 sec): loss changed from 0.259 to 0.244\t\tVL:0.268\t\tAC:0.934\n",
      "Epoch 710 (0.602 sec): loss changed from 0.271 to 0.256\t\tVL:0.267\t\tAC:0.936\n",
      "Epoch 720 (0.621 sec): loss changed from 0.275 to 0.258\t\tVL:0.264\t\tAC:0.941\n",
      "Epoch 730 (0.606 sec): loss changed from 0.274 to 0.258\t\tVL:0.261\t\tAC:0.940\n",
      "Epoch 740 (0.52 sec): loss changed from 0.263 to 0.251\t\tVL:0.256\t\tAC:0.943\n",
      "Epoch 750 (0.516 sec): loss changed from 0.254 to 0.239\t\tVL:0.258\t\tAC:0.942\n",
      "Epoch 760 (0.519 sec): loss changed from 0.246 to 0.233\t\tVL:0.255\t\tAC:0.942\n",
      "Epoch 770 (0.664 sec): loss changed from 0.247 to 0.232\t\tVL:0.251\t\tAC:0.948\n",
      "Epoch 780 (0.517 sec): loss changed from 0.254 to 0.237\t\tVL:0.250\t\tAC:0.951\n",
      "Epoch 790 (4.08e+04 sec): loss changed from 0.254 to 0.238\t\tVL:0.248\t\tAC:0.948\n",
      "Epoch 800 (1.13 sec): loss changed from 0.249 to 0.237\t\tVL:0.245\t\tAC:0.952\n",
      "Epoch 810 (0.795 sec): loss changed from 0.252 to 0.239\t\tVL:0.244\t\tAC:0.953\n",
      "Epoch 820 (0.533 sec): loss changed from 0.228 to 0.217\t\tVL:0.242\t\tAC:0.951\n",
      "Epoch 830 (0.628 sec): loss changed from 0.235 to 0.222\t\tVL:0.241\t\tAC:0.957\n",
      "Epoch 840 (0.635 sec): loss changed from 0.242 to 0.226\t\tVL:0.240\t\tAC:0.955\n",
      "Epoch 850 (0.738 sec): loss changed from 0.242 to 0.23\t\tVL:0.237\t\tAC:0.955\n",
      "Epoch 860 (0.735 sec): loss changed from 0.25 to 0.235\t\tVL:0.238\t\tAC:0.956\n",
      "Epoch 870 (0.673 sec): loss changed from 0.241 to 0.228\t\tVL:0.235\t\tAC:0.956\n",
      "Epoch 880 (0.525 sec): loss changed from 0.228 to 0.212\t\tVL:0.236\t\tAC:0.960\n",
      "Epoch 890 (0.608 sec): loss changed from 0.221 to 0.209\t\tVL:0.234\t\tAC:0.958\n",
      "Epoch 900 (0.524 sec): loss changed from 0.225 to 0.211\t\tVL:0.230\t\tAC:0.960\n",
      "Epoch 910 (0.627 sec): loss changed from 0.231 to 0.214\t\tVL:0.232\t\tAC:0.958\n",
      "Epoch 920 (0.612 sec): loss changed from 0.235 to 0.219\t\tVL:0.228\t\tAC:0.961\n",
      "Epoch 930 (0.522 sec): loss changed from 0.232 to 0.218\t\tVL:0.229\t\tAC:0.958\n",
      "Epoch 940 (0.523 sec): loss changed from 0.24 to 0.221\t\tVL:0.225\t\tAC:0.962\n",
      "Epoch 950 (0.526 sec): loss changed from 0.231 to 0.213\t\tVL:0.226\t\tAC:0.961\n",
      "Epoch 960 (0.523 sec): loss changed from 0.225 to 0.211\t\tVL:0.220\t\tAC:0.962\n",
      "Epoch 970 (0.711 sec): loss changed from 0.217 to 0.198\t\tVL:0.222\t\tAC:0.962\n",
      "Epoch 980 (0.529 sec): loss changed from 0.215 to 0.203\t\tVL:0.218\t\tAC:0.963\n",
      "Epoch 990 (0.73 sec): loss changed from 0.211 to 0.195\t\tVL:0.219\t\tAC:0.965\n",
      "Model saved at checkpoint: D:/Jupyter/mltest/Models-12RNN07/model-1000.ckpt\n",
      "Epoch 1000 (0.737 sec): loss changed from 0.214 to 0.202\t\tVL:0.218\t\tAC:0.964\n",
      "Epoch 1010 (0.597 sec): loss changed from 0.219 to 0.203\t\tVL:0.217\t\tAC:0.965\n",
      "Epoch 1020 (0.581 sec): loss changed from 0.222 to 0.204\t\tVL:0.213\t\tAC:0.968\n",
      "Epoch 1030 (0.572 sec): loss changed from 0.205 to 0.193\t\tVL:0.214\t\tAC:0.967\n",
      "Epoch 1040 (0.676 sec): loss changed from 0.214 to 0.203\t\tVL:0.210\t\tAC:0.968\n",
      "Epoch 1050 (0.613 sec): loss changed from 0.206 to 0.19\t\tVL:0.212\t\tAC:0.966\n",
      "Epoch 1060 (0.61 sec): loss changed from 0.217 to 0.201\t\tVL:0.213\t\tAC:0.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1070 (0.577 sec): loss changed from 0.2 to 0.188\t\tVL:0.207\t\tAC:0.967\n",
      "Epoch 1080 (0.568 sec): loss changed from 0.204 to 0.193\t\tVL:0.209\t\tAC:0.970\n",
      "Epoch 1090 (0.521 sec): loss changed from 0.213 to 0.189\t\tVL:0.209\t\tAC:0.967\n",
      "Epoch 1100 (0.841 sec): loss changed from 0.205 to 0.194\t\tVL:0.204\t\tAC:0.970\n",
      "Epoch 1110 (0.675 sec): loss changed from 0.187 to 0.176\t\tVL:0.205\t\tAC:0.970\n",
      "Epoch 1120 (0.618 sec): loss changed from 0.195 to 0.183\t\tVL:0.204\t\tAC:0.971\n",
      "Epoch 1130 (0.6 sec): loss changed from 0.202 to 0.19\t\tVL:0.202\t\tAC:0.972\n",
      "Epoch 1140 (0.619 sec): loss changed from 0.197 to 0.186\t\tVL:0.203\t\tAC:0.971\n",
      "Epoch 1150 (0.52 sec): loss changed from 0.211 to 0.193\t\tVL:0.203\t\tAC:0.972\n",
      "Epoch 1160 (0.586 sec): loss changed from 0.201 to 0.186\t\tVL:0.202\t\tAC:0.971\n",
      "Epoch 1170 (0.642 sec): loss changed from 0.194 to 0.179\t\tVL:0.200\t\tAC:0.973\n",
      "Epoch 1180 (0.523 sec): loss changed from 0.186 to 0.171\t\tVL:0.200\t\tAC:0.971\n",
      "Epoch 1190 (0.68 sec): loss changed from 0.203 to 0.186\t\tVL:0.200\t\tAC:0.972\n",
      "Epoch 1200 (0.529 sec): loss changed from 0.194 to 0.18\t\tVL:0.197\t\tAC:0.973\n",
      "Epoch 1210 (0.562 sec): loss changed from 0.201 to 0.184\t\tVL:0.198\t\tAC:0.974\n",
      "Epoch 1220 (0.563 sec): loss changed from 0.196 to 0.182\t\tVL:0.195\t\tAC:0.974\n",
      "Epoch 1230 (0.537 sec): loss changed from 0.197 to 0.182\t\tVL:0.197\t\tAC:0.977\n",
      "Epoch 1240 (0.523 sec): loss changed from 0.19 to 0.178\t\tVL:0.195\t\tAC:0.975\n",
      "Epoch 1250 (0.635 sec): loss changed from 0.187 to 0.175\t\tVL:0.195\t\tAC:0.975\n",
      "Epoch 1260 (0.643 sec): loss changed from 0.191 to 0.178\t\tVL:0.193\t\tAC:0.976\n",
      "Epoch 1270 (0.575 sec): loss changed from 0.192 to 0.172\t\tVL:0.194\t\tAC:0.974\n",
      "Epoch 1280 (0.675 sec): loss changed from 0.191 to 0.178\t\tVL:0.192\t\tAC:0.976\n",
      "Epoch 1290 (0.528 sec): loss changed from 0.195 to 0.183\t\tVL:0.191\t\tAC:0.978\n",
      "Epoch 1300 (0.533 sec): loss changed from 0.186 to 0.171\t\tVL:0.193\t\tAC:0.974\n",
      "Epoch 1310 (0.517 sec): loss changed from 0.183 to 0.171\t\tVL:0.189\t\tAC:0.978\n",
      "Epoch 1320 (0.634 sec): loss changed from 0.204 to 0.193\t\tVL:0.190\t\tAC:0.977\n",
      "Epoch 1330 (0.522 sec): loss changed from 0.194 to 0.181\t\tVL:0.193\t\tAC:0.976\n",
      "Epoch 1340 (0.526 sec): loss changed from 0.188 to 0.173\t\tVL:0.190\t\tAC:0.976\n",
      "Epoch 1350 (0.527 sec): loss changed from 0.199 to 0.177\t\tVL:0.191\t\tAC:0.978\n",
      "Epoch 1360 (0.523 sec): loss changed from 0.188 to 0.172\t\tVL:0.188\t\tAC:0.978\n",
      "Epoch 1370 (0.527 sec): loss changed from 0.183 to 0.169\t\tVL:0.186\t\tAC:0.981\n",
      "Epoch 1380 (0.555 sec): loss changed from 0.181 to 0.168\t\tVL:0.185\t\tAC:0.979\n",
      "Epoch 1390 (0.52 sec): loss changed from 0.186 to 0.173\t\tVL:0.190\t\tAC:0.976\n",
      "Epoch 1400 (0.524 sec): loss changed from 0.183 to 0.168\t\tVL:0.187\t\tAC:0.978\n",
      "Epoch 1410 (0.521 sec): loss changed from 0.175 to 0.16\t\tVL:0.186\t\tAC:0.979\n",
      "Epoch 1420 (0.523 sec): loss changed from 0.187 to 0.172\t\tVL:0.185\t\tAC:0.981\n",
      "Epoch 1430 (0.519 sec): loss changed from 0.182 to 0.169\t\tVL:0.183\t\tAC:0.981\n",
      "Epoch 1440 (0.699 sec): loss changed from 0.184 to 0.169\t\tVL:0.184\t\tAC:0.982\n",
      "Epoch 1450 (0.714 sec): loss changed from 0.184 to 0.168\t\tVL:0.182\t\tAC:0.979\n",
      "Epoch 1460 (0.549 sec): loss changed from 0.184 to 0.173\t\tVL:0.182\t\tAC:0.982\n",
      "Epoch 1470 (0.66 sec): loss changed from 0.193 to 0.174\t\tVL:0.182\t\tAC:0.981\n",
      "Epoch 1480 (0.714 sec): loss changed from 0.189 to 0.173\t\tVL:0.181\t\tAC:0.984\n",
      "Epoch 1490 (0.548 sec): loss changed from 0.182 to 0.168\t\tVL:0.181\t\tAC:0.981\n",
      "Model saved at checkpoint: D:/Jupyter/mltest/Models-12RNN07/model-1500.ckpt\n",
      "Epoch 1500 (0.609 sec): loss changed from 0.173 to 0.163\t\tVL:0.178\t\tAC:0.984\n",
      "Epoch 1510 (0.632 sec): loss changed from 0.183 to 0.166\t\tVL:0.179\t\tAC:0.986\n",
      "Epoch 1520 (0.629 sec): loss changed from 0.175 to 0.161\t\tVL:0.179\t\tAC:0.983\n",
      "Epoch 1530 (0.579 sec): loss changed from 0.182 to 0.168\t\tVL:0.182\t\tAC:0.980\n",
      "Epoch 1540 (0.556 sec): loss changed from 0.174 to 0.164\t\tVL:0.177\t\tAC:0.984\n",
      "Epoch 1550 (0.518 sec): loss changed from 0.17 to 0.157\t\tVL:0.178\t\tAC:0.982\n",
      "Epoch 1560 (0.653 sec): loss changed from 0.17 to 0.161\t\tVL:0.177\t\tAC:0.983\n",
      "Epoch 1570 (0.529 sec): loss changed from 0.168 to 0.158\t\tVL:0.174\t\tAC:0.985\n",
      "Epoch 1580 (0.597 sec): loss changed from 0.161 to 0.149\t\tVL:0.176\t\tAC:0.980\n",
      "Epoch 1590 (0.685 sec): loss changed from 0.171 to 0.163\t\tVL:0.172\t\tAC:0.985\n",
      "Epoch 1600 (0.631 sec): loss changed from 0.178 to 0.163\t\tVL:0.172\t\tAC:0.986\n",
      "Epoch 1610 (0.528 sec): loss changed from 0.166 to 0.155\t\tVL:0.172\t\tAC:0.984\n",
      "Epoch 1620 (0.523 sec): loss changed from 0.176 to 0.159\t\tVL:0.173\t\tAC:0.985\n",
      "Epoch 1630 (0.542 sec): loss changed from 0.175 to 0.163\t\tVL:0.169\t\tAC:0.988\n",
      "Epoch 1640 (0.551 sec): loss changed from 0.172 to 0.159\t\tVL:0.170\t\tAC:0.986\n",
      "Epoch 1650 (0.573 sec): loss changed from 0.169 to 0.16\t\tVL:0.169\t\tAC:0.983\n",
      "Epoch 1660 (0.513 sec): loss changed from 0.16 to 0.151\t\tVL:0.167\t\tAC:0.987\n",
      "Epoch 1670 (0.573 sec): loss changed from 0.167 to 0.157\t\tVL:0.168\t\tAC:0.985\n",
      "Epoch 1680 (0.512 sec): loss changed from 0.165 to 0.153\t\tVL:0.166\t\tAC:0.987\n",
      "Epoch 1690 (0.523 sec): loss changed from 0.163 to 0.15\t\tVL:0.165\t\tAC:0.987\n",
      "Epoch 1700 (0.525 sec): loss changed from 0.163 to 0.15\t\tVL:0.164\t\tAC:0.986\n",
      "Epoch 1710 (0.626 sec): loss changed from 0.151 to 0.14\t\tVL:0.165\t\tAC:0.986\n",
      "Epoch 1720 (0.635 sec): loss changed from 0.156 to 0.145\t\tVL:0.161\t\tAC:0.989\n",
      "Epoch 1730 (0.537 sec): loss changed from 0.163 to 0.151\t\tVL:0.160\t\tAC:0.989\n",
      "Epoch 1740 (0.543 sec): loss changed from 0.162 to 0.146\t\tVL:0.161\t\tAC:0.989\n",
      "Epoch 1750 (0.538 sec): loss changed from 0.161 to 0.149\t\tVL:0.158\t\tAC:0.991\n",
      "Epoch 1760 (0.536 sec): loss changed from 0.149 to 0.137\t\tVL:0.156\t\tAC:0.989\n",
      "Epoch 1770 (0.742 sec): loss changed from 0.156 to 0.146\t\tVL:0.158\t\tAC:0.986\n",
      "Epoch 1780 (0.595 sec): loss changed from 0.151 to 0.14\t\tVL:0.156\t\tAC:0.989\n",
      "Epoch 1790 (0.521 sec): loss changed from 0.163 to 0.152\t\tVL:0.155\t\tAC:0.990\n",
      "Epoch 1800 (0.589 sec): loss changed from 0.157 to 0.141\t\tVL:0.155\t\tAC:0.991\n",
      "Epoch 1810 (0.516 sec): loss changed from 0.164 to 0.149\t\tVL:0.154\t\tAC:0.990\n",
      "Epoch 1820 (0.531 sec): loss changed from 0.154 to 0.141\t\tVL:0.151\t\tAC:0.991\n",
      "Epoch 1830 (0.551 sec): loss changed from 0.157 to 0.148\t\tVL:0.151\t\tAC:0.991\n",
      "Epoch 1840 (0.518 sec): loss changed from 0.147 to 0.136\t\tVL:0.151\t\tAC:0.990\n",
      "Epoch 1850 (0.656 sec): loss changed from 0.157 to 0.147\t\tVL:0.152\t\tAC:0.991\n",
      "Epoch 1860 (0.678 sec): loss changed from 0.143 to 0.133\t\tVL:0.149\t\tAC:0.991\n",
      "Epoch 1870 (0.56 sec): loss changed from 0.144 to 0.134\t\tVL:0.150\t\tAC:0.991\n",
      "Epoch 1880 (0.537 sec): loss changed from 0.145 to 0.133\t\tVL:0.148\t\tAC:0.992\n",
      "Epoch 1890 (0.691 sec): loss changed from 0.145 to 0.134\t\tVL:0.147\t\tAC:0.992\n",
      "Epoch 1900 (0.612 sec): loss changed from 0.151 to 0.134\t\tVL:0.147\t\tAC:0.993\n",
      "Epoch 1910 (0.69 sec): loss changed from 0.142 to 0.13\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 1920 (0.539 sec): loss changed from 0.151 to 0.141\t\tVL:0.144\t\tAC:0.994\n",
      "Epoch 1930 (0.637 sec): loss changed from 0.14 to 0.13\t\tVL:0.144\t\tAC:0.994\n",
      "Epoch 1940 (0.539 sec): loss changed from 0.142 to 0.129\t\tVL:0.145\t\tAC:0.993\n",
      "Epoch 1950 (0.661 sec): loss changed from 0.142 to 0.133\t\tVL:0.143\t\tAC:0.994\n",
      "Epoch 1960 (0.543 sec): loss changed from 0.146 to 0.134\t\tVL:0.144\t\tAC:0.994\n",
      "Epoch 1970 (0.595 sec): loss changed from 0.145 to 0.133\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 1980 (0.554 sec): loss changed from 0.132 to 0.12\t\tVL:0.142\t\tAC:0.994\n",
      "Epoch 1990 (0.519 sec): loss changed from 0.134 to 0.126\t\tVL:0.140\t\tAC:0.994\n",
      "Model saved at checkpoint: D:/Jupyter/mltest/Models-12RNN07/model-2000.ckpt\n",
      "Epoch 2000 (0.521 sec): loss changed from 0.136 to 0.125\t\tVL:0.141\t\tAC:0.993\n",
      "Epoch 2010 (0.519 sec): loss changed from 0.131 to 0.121\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 2020 (0.525 sec): loss changed from 0.137 to 0.128\t\tVL:0.140\t\tAC:0.994\n",
      "Epoch 2030 (0.577 sec): loss changed from 0.144 to 0.128\t\tVL:0.139\t\tAC:0.995\n",
      "Epoch 2040 (0.619 sec): loss changed from 0.141 to 0.124\t\tVL:0.141\t\tAC:0.994\n",
      "Epoch 2050 (0.533 sec): loss changed from 0.135 to 0.124\t\tVL:0.139\t\tAC:0.994\n",
      "Epoch 2060 (0.763 sec): loss changed from 0.139 to 0.129\t\tVL:0.137\t\tAC:0.996\n",
      "Epoch 2070 (0.61 sec): loss changed from 0.14 to 0.128\t\tVL:0.139\t\tAC:0.994\n",
      "Epoch 2080 (0.595 sec): loss changed from 0.135 to 0.127\t\tVL:0.135\t\tAC:0.994\n",
      "Epoch 2090 (0.513 sec): loss changed from 0.14 to 0.129\t\tVL:0.138\t\tAC:0.994\n",
      "Epoch 2100 (0.522 sec): loss changed from 0.142 to 0.13\t\tVL:0.136\t\tAC:0.995\n",
      "Epoch 2110 (0.523 sec): loss changed from 0.138 to 0.124\t\tVL:0.138\t\tAC:0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2120 (0.605 sec): loss changed from 0.141 to 0.128\t\tVL:0.137\t\tAC:0.995\n",
      "Epoch 2130 (0.521 sec): loss changed from 0.136 to 0.126\t\tVL:0.135\t\tAC:0.995\n",
      "Epoch 2140 (0.611 sec): loss changed from 0.129 to 0.116\t\tVL:0.137\t\tAC:0.995\n",
      "Epoch 2150 (0.517 sec): loss changed from 0.136 to 0.121\t\tVL:0.135\t\tAC:0.996\n",
      "Epoch 2160 (0.514 sec): loss changed from 0.13 to 0.121\t\tVL:0.133\t\tAC:0.995\n",
      "Epoch 2170 (0.518 sec): loss changed from 0.124 to 0.114\t\tVL:0.133\t\tAC:0.995\n",
      "Epoch 2180 (0.716 sec): loss changed from 0.131 to 0.121\t\tVL:0.134\t\tAC:0.995\n",
      "Epoch 2190 (0.741 sec): loss changed from 0.127 to 0.119\t\tVL:0.132\t\tAC:0.996\n",
      "Epoch 2200 (0.598 sec): loss changed from 0.134 to 0.122\t\tVL:0.132\t\tAC:0.996\n",
      "Epoch 2210 (0.73 sec): loss changed from 0.134 to 0.125\t\tVL:0.133\t\tAC:0.996\n",
      "Epoch 2220 (0.622 sec): loss changed from 0.129 to 0.12\t\tVL:0.133\t\tAC:0.996\n",
      "Epoch 2230 (0.738 sec): loss changed from 0.131 to 0.124\t\tVL:0.132\t\tAC:0.995\n",
      "Epoch 2240 (0.606 sec): loss changed from 0.138 to 0.125\t\tVL:0.131\t\tAC:0.996\n",
      "Epoch 2250 (0.61 sec): loss changed from 0.132 to 0.121\t\tVL:0.131\t\tAC:0.996\n",
      "Epoch 2260 (0.626 sec): loss changed from 0.121 to 0.111\t\tVL:0.130\t\tAC:0.996\n",
      "Epoch 2270 (0.594 sec): loss changed from 0.127 to 0.116\t\tVL:0.133\t\tAC:0.996\n",
      "Epoch 2280 (0.533 sec): loss changed from 0.133 to 0.124\t\tVL:0.129\t\tAC:0.997\n",
      "Epoch 2290 (0.618 sec): loss changed from 0.128 to 0.117\t\tVL:0.129\t\tAC:0.997\n",
      "Epoch 2300 (0.522 sec): loss changed from 0.122 to 0.113\t\tVL:0.128\t\tAC:0.996\n",
      "Epoch 2310 (0.524 sec): loss changed from 0.132 to 0.123\t\tVL:0.131\t\tAC:0.995\n",
      "Epoch 2320 (0.523 sec): loss changed from 0.13 to 0.117\t\tVL:0.130\t\tAC:0.997\n",
      "Epoch 2330 (0.52 sec): loss changed from 0.127 to 0.116\t\tVL:0.130\t\tAC:0.995\n",
      "Epoch 2340 (0.519 sec): loss changed from 0.138 to 0.127\t\tVL:0.129\t\tAC:0.997\n",
      "Epoch 2350 (0.521 sec): loss changed from 0.122 to 0.111\t\tVL:0.128\t\tAC:0.996\n",
      "Epoch 2360 (0.568 sec): loss changed from 0.129 to 0.115\t\tVL:0.129\t\tAC:0.996\n",
      "Epoch 2370 (0.519 sec): loss changed from 0.125 to 0.114\t\tVL:0.128\t\tAC:0.997\n",
      "Epoch 2380 (0.697 sec): loss changed from 0.133 to 0.118\t\tVL:0.126\t\tAC:0.997\n",
      "Epoch 2390 (0.681 sec): loss changed from 0.121 to 0.113\t\tVL:0.129\t\tAC:0.997\n",
      "Epoch 2400 (0.68 sec): loss changed from 0.125 to 0.112\t\tVL:0.128\t\tAC:0.996\n",
      "Epoch 2410 (0.547 sec): loss changed from 0.129 to 0.118\t\tVL:0.129\t\tAC:0.995\n",
      "Epoch 2420 (0.646 sec): loss changed from 0.128 to 0.117\t\tVL:0.126\t\tAC:0.996\n",
      "Epoch 2430 (0.538 sec): loss changed from 0.118 to 0.109\t\tVL:0.128\t\tAC:0.996\n",
      "Epoch 2440 (0.549 sec): loss changed from 0.125 to 0.116\t\tVL:0.126\t\tAC:0.997\n",
      "Epoch 2450 (0.634 sec): loss changed from 0.124 to 0.115\t\tVL:0.126\t\tAC:0.996\n",
      "Epoch 2460 (0.619 sec): loss changed from 0.117 to 0.109\t\tVL:0.127\t\tAC:0.996\n",
      "Epoch 2470 (0.599 sec): loss changed from 0.12 to 0.111\t\tVL:0.127\t\tAC:0.997\n",
      "Epoch 2480 (0.619 sec): loss changed from 0.122 to 0.113\t\tVL:0.125\t\tAC:0.997\n",
      "Epoch 2490 (0.523 sec): loss changed from 0.124 to 0.113\t\tVL:0.125\t\tAC:0.997\n"
     ]
    }
   ],
   "source": [
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/12RNN07-{0}'.format(dt_now), tf.get_default_graph())\n",
    "\n",
    "batch_size = 1000\n",
    "num_steps  = 30\n",
    "num_epochs = 5000\n",
    "checkpoints = 500\n",
    "\n",
    "fmtstr = 'Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.3f}\\t\\tAC:{5:1.3f}'\n",
    "valid_batch = {tfi_x: valid_x, tfi_y: valid_y}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini_x, mini_y = randomBatch((train_x, train_y), batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini_x, tfi_y:mini_y}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        [lv,ac,summary] = tfs.run([tfLoss, tfAccuracy, tfsAll], feed_dict=valid_batch)\n",
    "        tffw.add_summary(summary, i)\n",
    "        if i%checkpoints == 0 and i > 0:\n",
    "            p = tfsSaver.save(tfs, 'D:/Jupyter/mltest/Models-12RNN07/model-{0:04d}.ckpt'.format(i))\n",
    "            print('Model saved at checkpoint: {0}'.format(p))\n",
    "        if i%10 == 0 or i == num_epochs - 1:\n",
    "            print(fmtstr.format(i,t1-t0,l0,l1,lv,ac))\n",
    "    valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/Jupyter/mltest/Models-12RNN07/model-4500.ckpt\n",
      "Epoch 4500 (0.637 sec): loss changed from 0.0994 to 0.0991\t\tVL:0.101\t\tAC:0.997\n",
      "Epoch 4510 (0.551 sec): loss changed from 0.0974 to 0.097\t\tVL:0.101\t\tAC:0.998\n",
      "Epoch 4520 (0.717 sec): loss changed from 0.0939 to 0.0925\t\tVL:0.101\t\tAC:0.998\n",
      "Epoch 4530 (0.557 sec): loss changed from 0.0986 to 0.098\t\tVL:0.101\t\tAC:0.997\n",
      "Epoch 4540 (0.683 sec): loss changed from 0.0997 to 0.0983\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4550 (0.545 sec): loss changed from 0.0979 to 0.0976\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4560 (0.63 sec): loss changed from 0.093 to 0.0923\t\tVL:0.101\t\tAC:0.998\n",
      "Epoch 4570 (0.794 sec): loss changed from 0.0953 to 0.0942\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4580 (0.591 sec): loss changed from 0.101 to 0.1\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4590 (0.796 sec): loss changed from 0.0921 to 0.0918\t\tVL:0.100\t\tAC:0.997\n",
      "Epoch 4600 (0.734 sec): loss changed from 0.092 to 0.0912\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4610 (0.586 sec): loss changed from 0.098 to 0.0975\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4620 (0.648 sec): loss changed from 0.0981 to 0.0977\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4630 (0.724 sec): loss changed from 0.096 to 0.0957\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4640 (0.768 sec): loss changed from 0.102 to 0.102\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4650 (0.696 sec): loss changed from 0.0958 to 0.0956\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4660 (0.734 sec): loss changed from 0.096 to 0.0953\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4670 (0.596 sec): loss changed from 0.0905 to 0.0902\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4680 (0.744 sec): loss changed from 0.101 to 0.101\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4690 (0.592 sec): loss changed from 0.0881 to 0.0878\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4700 (0.586 sec): loss changed from 0.103 to 0.103\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4710 (1.76 sec): loss changed from 0.0944 to 0.0936\t\tVL:0.100\t\tAC:0.998\n",
      "Epoch 4720 (1.07 sec): loss changed from 0.105 to 0.105\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4730 (0.675 sec): loss changed from 0.0936 to 0.0933\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4740 (0.601 sec): loss changed from 0.0982 to 0.0973\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4750 (0.848 sec): loss changed from 0.0955 to 0.0953\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4760 (0.771 sec): loss changed from 0.0953 to 0.0951\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4770 (0.791 sec): loss changed from 0.1 to 0.0998\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4780 (0.726 sec): loss changed from 0.0926 to 0.0917\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4790 (0.697 sec): loss changed from 0.0977 to 0.0971\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4800 (0.753 sec): loss changed from 0.101 to 0.101\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4810 (0.695 sec): loss changed from 0.092 to 0.0917\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4820 (0.699 sec): loss changed from 0.0886 to 0.0882\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4830 (0.935 sec): loss changed from 0.0954 to 0.0943\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4840 (0.821 sec): loss changed from 0.101 to 0.101\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4850 (0.8 sec): loss changed from 0.1 to 0.1\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4860 (0.82 sec): loss changed from 0.0993 to 0.099\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4870 (0.753 sec): loss changed from 0.0933 to 0.0929\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4880 (0.696 sec): loss changed from 0.095 to 0.0948\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4890 (0.66 sec): loss changed from 0.0981 to 0.0974\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4900 (0.634 sec): loss changed from 0.096 to 0.0954\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4910 (0.672 sec): loss changed from 0.0922 to 0.0921\t\tVL:0.098\t\tAC:0.998\n",
      "Epoch 4920 (0.711 sec): loss changed from 0.102 to 0.102\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4930 (0.603 sec): loss changed from 0.104 to 0.103\t\tVL:0.098\t\tAC:0.998\n",
      "Epoch 4940 (0.703 sec): loss changed from 0.0943 to 0.0941\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4950 (0.782 sec): loss changed from 0.105 to 0.105\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4960 (0.634 sec): loss changed from 0.105 to 0.104\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 4970 (0.701 sec): loss changed from 0.0895 to 0.0891\t\tVL:0.098\t\tAC:0.998\n",
      "Epoch 4980 (0.597 sec): loss changed from 0.0975 to 0.0972\t\tVL:0.098\t\tAC:0.998\n",
      "Epoch 4990 (0.61 sec): loss changed from 0.0906 to 0.0902\t\tVL:0.098\t\tAC:0.998\n",
      "Model saved at checkpoint: D:/Jupyter/mltest/Models-12RNN07/model-5000.ckpt\n",
      "Epoch 5000 (0.621 sec): loss changed from 0.0988 to 0.0985\t\tVL:0.099\t\tAC:0.998\n",
      "Epoch 5010 (0.587 sec): loss changed from 0.0978 to 0.0973\t\tVL:0.099\t\tAC:0.998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f1f82f4dfe00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \"\"\"\n\u001b[1;32m-> 1706\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3961\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3963\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/12RNN07-{0}'.format(dt_now), tf.get_default_graph())\n",
    "\n",
    "batch_size = 1000\n",
    "num_steps  = 30\n",
    "start_offset = 4500\n",
    "num_epochs = 8000\n",
    "checkpoints = 500\n",
    "\n",
    "fmtstr = 'Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.3f}\\t\\tAC:{5:1.3f}'\n",
    "valid_batch = {tfi_x: valid_x, tfi_y: valid_y}\n",
    "with tf.Session() as tfs:\n",
    "    tfsSaver.restore(tfs, 'D:/Jupyter/mltest/Models-12RNN07/model-{0:04d}.ckpt'.format(start_offset))\n",
    "    for i in range(start_offset, num_epochs):\n",
    "        mini_x, mini_y = randomBatch((train_x, train_y), batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini_x, tfi_y:mini_y}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        [lv,ac,summary] = tfs.run([tfLoss, tfAccuracy, tfsAll], feed_dict=valid_batch)\n",
    "        tffw.add_summary(summary, i)\n",
    "        if i%checkpoints == 0 and i > start_offset:\n",
    "            p = tfsSaver.save(tfs, 'D:/Jupyter/mltest/Models-12RNN07/model-{0:04d}.ckpt'.format(i))\n",
    "            print('Model saved at checkpoint: {0}'.format(p))\n",
    "        if i%10 == 0 or i == num_epochs - 1:\n",
    "            print(fmtstr.format(i,t1-t0,l0,l1,lv,ac))\n",
    "    valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 2, 2, 1, 2, 2, 2, 4, 3]),\n",
       " array([3, 3, 2, 3, 2, 2, 3, 2, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic-rnn-5     1.140 loss, 0.303 accuracy (stopped at 200 epochs)\n",
    "#gru-rnn-5       0.998 loss, 0.378 accuracy\n",
    "#gru-rnn-10      0.524 loss, 0.681 accuracy (and still improving fast) -> 0.135 and 0.995 -> 0.098 and 0.998\n",
    "#gru-rnn-5-5     0.590 loss, 0.664 accuracy (and still improving fast)\n",
    "valid_y[:10], valid_r[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
