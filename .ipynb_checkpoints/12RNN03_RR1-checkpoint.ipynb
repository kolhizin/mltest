{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "startup_state = 2\n",
    "symbols = set('abcd')\n",
    "\n",
    "prefixes = ['']\n",
    "for i in range(startup_state):\n",
    "    prefixes = [x + y for x in prefixes for y in symbols]\n",
    "\n",
    "rr = {x:np.random.choice(np.array(list(symbols))) for x in prefixes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genObs(length, rr, key_length, startup_length, symbols):\n",
    "    x = ''.join(np.random.choice(symbols, size=startup_length))\n",
    "    for i in range(length - startup_length):\n",
    "        x = x + rr[x[-key_length:]]\n",
    "    return x\n",
    "\n",
    "def genRR(symbols, key_length):\n",
    "    prefixes = ['']\n",
    "    for i in range(key_length):\n",
    "        prefixes = [x + y for x in prefixes for y in symbols]\n",
    "    symarr = np.array(list(symbols))\n",
    "    return {x:np.random.choice(symarr) for x in prefixes}\n",
    "\n",
    "def genSample(num, rr, length=20, startup_length=5):\n",
    "    keylen = max([len(x) for x,_  in rr.items()])\n",
    "    symarr = np.array(list(set(''.join([x for x,_  in rr.items()]))))\n",
    "    return [genObs(length, rr, keylen, startup_length, symarr) for _ in range(num)]\n",
    "\n",
    "def randomBatch(tensor, batchSize=64):\n",
    "    if type(tensor) is tuple:\n",
    "        ids = np.random.choice(range(tensor[0].shape[0]), batchSize)\n",
    "        return (x[ids,] for x in tensor)\n",
    "    ids = np.random.choice(range(tensor.shape[0]), batchSize)\n",
    "    return tensor[ids,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = genRR('01234567', 5)\n",
    "train0 = genSample(10000, rr)\n",
    "valid0 = genSample(2000, rr)\n",
    "train = np.array([np.array([int(y) for y in x]) for x in train0])\n",
    "valid = np.array([np.array([int(y) for y in x]) for x in valid0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 1, 5, 5, 6, 7, 1, 2, 6, 6, 2, 3, 5, 1, 0, 5, 2, 2],\n",
       "       [1, 3, 5, 3, 7, 7, 7, 0, 6, 0, 1, 7, 2, 6, 1, 6, 4, 5, 2, 2],\n",
       "       [1, 0, 1, 6, 5, 4, 6, 0, 0, 2, 1, 2, 3, 5, 3, 1, 5, 5, 1, 3],\n",
       "       [4, 6, 4, 3, 1, 2, 7, 4, 0, 2, 1, 5, 1, 1, 6, 3, 6, 5, 3, 7],\n",
       "       [6, 2, 0, 0, 1, 3, 4, 0, 1, 7, 0, 3, 5, 6, 1, 2, 6, 0, 3, 4],\n",
       "       [1, 0, 4, 2, 5, 5, 1, 2, 6, 0, 1, 0, 0, 2, 4, 3, 1, 1, 5, 5],\n",
       "       [4, 4, 2, 7, 7, 2, 0, 0, 4, 5, 2, 1, 6, 3, 3, 1, 1, 2, 0, 0],\n",
       "       [1, 1, 4, 4, 0, 5, 2, 5, 3, 3, 1, 6, 5, 5, 1, 1, 0, 1, 3, 5],\n",
       "       [0, 4, 0, 3, 2, 6, 1, 2, 0, 3, 3, 1, 1, 4, 4, 6, 6, 6, 1, 0],\n",
       "       [4, 6, 7, 3, 2, 7, 3, 4, 7, 1, 2, 5, 3, 7, 2, 3, 2, 2, 3, 0]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "CHARSET_SIZE = 8\n",
    "RNN_SIZE = [100, 100]\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.BasicRNNCell(num_units=n, activation=tf.nn.tanh)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.relu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.int32)\n",
    "\n",
    "tfX = tf.one_hot(tfi_x, CHARSET_SIZE, dtype=tf.float32)\n",
    "tfY = tfX[:,1:,:]\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE], state_is_tuple=True)\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0], activation=tf.nn.elu)\n",
    "\n",
    "tfH, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfHOut = tf.layers.dense(tfH, CHARSET_SIZE)\n",
    "\n",
    "\n",
    "with tf.name_scope('LOSS'):\n",
    "    tfDiff = tf.nn.softmax_cross_entropy_with_logits(labels=tfY, logits=tfHOut[:,:-1,:])\n",
    "    tfLoss = tf.reduce_mean(tfDiff[:,-10:], name='TRAIN-LOSS')\n",
    "    tfEqEw = tf.cast(tf.equal(tf.argmax(tf.nn.softmax(tfHOut[:,:-1,:],dim=2), axis=2), tf.argmax(tfY, axis=2)), dtype=tf.float32)\n",
    "    tfAccMax = tf.reduce_mean(tf.reduce_min(tfEqEw[:,-5:], axis=1), name='ACCURACY-OBS')\n",
    "    tfAccMean = tf.reduce_mean(tfEqEw[:,-5:], name='ACCURACY-SYM')\n",
    "    tfTrain = tf.train.AdamOptimizer(LEARNING_RATE).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.argmax(tf.nn.softmax(tfHOut[:,:-1,:],dim=2), axis=2)\n",
    "\n",
    "#tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tfi_y, tfOutR), dtype=tf.float32))\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.936 sec): loss changed from 2.14 to 2.09\t\tVL:2.12\t\tAC:0.163 (0.001)\n",
      "Epoch 1 (0.924 sec): loss changed from 2.13 to 2.1\t\tVL:2.12\t\tAC:0.143 (0.000)\n",
      "Epoch 2 (0.937 sec): loss changed from 2.12 to 2.08\t\tVL:2.08\t\tAC:0.146 (0.000)\n",
      "Epoch 3 (0.926 sec): loss changed from 2.09 to 2.07\t\tVL:2.07\t\tAC:0.162 (0.000)\n",
      "Epoch 4 (0.934 sec): loss changed from 2.08 to 2.05\t\tVL:2.06\t\tAC:0.179 (0.001)\n",
      "Epoch 5 (0.929 sec): loss changed from 2.06 to 2.05\t\tVL:2.06\t\tAC:0.178 (0.000)\n",
      "Epoch 6 (0.938 sec): loss changed from 2.06 to 2.04\t\tVL:2.05\t\tAC:0.196 (0.000)\n",
      "Epoch 7 (1.15 sec): loss changed from 2.05 to 2.02\t\tVL:2.04\t\tAC:0.207 (0.001)\n",
      "Epoch 8 (0.985 sec): loss changed from 2.04 to 2.02\t\tVL:2.04\t\tAC:0.206 (0.000)\n",
      "Epoch 9 (0.924 sec): loss changed from 2.03 to 2.0\t\tVL:2.03\t\tAC:0.214 (0.001)\n",
      "Epoch 10 (0.948 sec): loss changed from 2.03 to 2.01\t\tVL:2.03\t\tAC:0.212 (0.001)\n",
      "Epoch 11 (0.919 sec): loss changed from 2.03 to 2.01\t\tVL:2.04\t\tAC:0.216 (0.001)\n",
      "Epoch 12 (0.926 sec): loss changed from 2.04 to 1.99\t\tVL:2.01\t\tAC:0.236 (0.004)\n",
      "Epoch 13 (0.921 sec): loss changed from 2.01 to 1.97\t\tVL:1.99\t\tAC:0.247 (0.002)\n",
      "Epoch 14 (1.04 sec): loss changed from 1.99 to 1.94\t\tVL:1.98\t\tAC:0.254 (0.002)\n",
      "Epoch 15 (0.93 sec): loss changed from 1.99 to 1.92\t\tVL:1.96\t\tAC:0.275 (0.004)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-4cb729d4c8f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \"\"\"\n\u001b[1;32m-> 1706\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3961\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3963\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_steps  = 5\n",
    "num_epochs = 200\n",
    "\n",
    "valid_batch = {tfi_x: valid}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini = randomBatch(train, batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        lv, ac, acm = tfs.run([tfLoss, tfAccMean, tfAccMax], feed_dict=valid_batch)\n",
    "        \n",
    "        #if i % 10 == 0 and i > 0:\n",
    "        #    print(tfOutR.eval(feed_dict=valid_batch)[:10] - valid[:10,1:])\n",
    "        \n",
    "        print('Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.2f}\\t\\tAC:{5:1.3f} ({6:1.3f})'.format(i,t1-t0,l0,l1,lv,ac, acm))\n",
    "    #valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 2, 5, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 2, 2, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [5, 4, 2, 3, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 2, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 3, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [4, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 3, 5, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 3, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 3, 4, 3, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
