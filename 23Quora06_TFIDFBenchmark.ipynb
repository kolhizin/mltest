{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import modutils\n",
    "import pickle\n",
    "import time\n",
    "import sklearn, sklearn.metrics\n",
    "\n",
    "src_file = '../DataSets/Quora/tfidf_src_180124.pickle'\n",
    "label_file = '../DataSets/Quora/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(src_file, 'rb') as f:\n",
    "    (src_data, src_vocab_size) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242506\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src_full = pd.read_csv(label_file)\n",
    "print(len(src_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_target = src_full.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_target), (valid_data, valid_target) = modutils.splitSample((src_data, src_target), pcts=[0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dense(values, size):\n",
    "    res = np.zeros(shape=(size,))\n",
    "    for x in values:\n",
    "        if x[0] < size:\n",
    "            res[x[0]] = x[1]\n",
    "    return res\n",
    "\n",
    "def make_features(src, vocab_size=100):\n",
    "    p1 = np.array([make_dense(x[0], size=vocab_size) for x in src])\n",
    "    p2 = np.array([make_dense(x[1], size=vocab_size) for x in src])\n",
    "    f1 = p1 * p2\n",
    "    f2 = np.square(p1-p2)\n",
    "    f3 = 0.5 * (p1 + p2)\n",
    "    return np.hstack([f1, f2, f3, np.array([x[2] for x in src])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "src_vocab_size = 1000 #override vocab size\n",
    "valid_set = make_features(valid_data, vocab_size=src_vocab_size)\n",
    "valid_trg = np.array(valid_target).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tf_in_x = tf.placeholder(tf.float32, shape=(None, valid_set.shape[1]))\n",
    "tf_in_y = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "tf_logit = tf.layers.dense(tf_in_x, 2)\n",
    "tf_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf_in_y, logits=tf_logit))\n",
    "tf_train = tf.train.AdamOptimizer(1e-2).minimize(tf_loss)\n",
    "\n",
    "tf_prob = tf.nn.softmax(tf_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501 -> 0.499\n",
      "Epoch 0: 0.772 -> 0.487 in 13.36 sec, gini=0.656, accur=0.748\n",
      "0.492 -> 0.489\n",
      "Epoch 1: 0.487 -> 0.486 in 13.80 sec, gini=0.658, accur=0.750\n",
      "0.465 -> 0.463\n",
      "Epoch 2: 0.486 -> 0.482 in 13.63 sec, gini=0.662, accur=0.751\n",
      "0.471 -> 0.469\n",
      "Epoch 3: 0.482 -> 0.482 in 13.76 sec, gini=0.663, accur=0.753\n",
      "0.474 -> 0.473\n",
      "Epoch 4: 0.482 -> 0.483 in 14.08 sec, gini=0.664, accur=0.754\n",
      "0.473 -> 0.471\n",
      "Epoch 5: 0.483 -> 0.482 in 13.76 sec, gini=0.663, accur=0.751\n",
      "0.472 -> 0.470\n",
      "Epoch 6: 0.482 -> 0.483 in 13.81 sec, gini=0.664, accur=0.751\n",
      "0.471 -> 0.467\n",
      "Epoch 7: 0.483 -> 0.482 in 13.82 sec, gini=0.664, accur=0.754\n",
      "0.487 -> 0.484\n",
      "Epoch 8: 0.482 -> 0.481 in 13.94 sec, gini=0.665, accur=0.754\n",
      "0.494 -> 0.490\n",
      "Epoch 9: 0.481 -> 0.481 in 13.69 sec, gini=0.664, accur=0.753\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "num_steps  = 2\n",
    "batch_size = 1024\n",
    "valid_dict = {tf_in_x: valid_set, tf_in_y: valid_trg}\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for n in range(num_epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        l0 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        for bx, by in modutils.shuffleBatches((train_data, train_target), batchSize=batch_size):\n",
    "            train_x = make_features(bx, vocab_size=src_vocab_size)\n",
    "            train_y = np.array(by).reshape(-1)\n",
    "            train_dict = {tf_in_x: train_x, tf_in_y: train_y}\n",
    "            tl0 = tf_loss.eval(feed_dict=train_dict)\n",
    "            for i in range(num_steps):\n",
    "                tf_train.run(feed_dict=train_dict)\n",
    "            tl1 = tf_loss.eval(feed_dict=train_dict)\n",
    "            print('{0:.3f} -> {1:.3f}'.format(tl0, tl1), end='\\r')\n",
    "\n",
    "        valid_p = tf_prob.eval(feed_dict=valid_dict)\n",
    "        gini = sklearn.metrics.roc_auc_score(valid_trg, valid_p[:,1])*2-1\n",
    "        accur = sklearn.metrics.accuracy_score(valid_trg, 1*(valid_p[:,1]>0.5))\n",
    "        l1 = tf_loss.eval(feed_dict=valid_dict)\n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        print('\\nEpoch {0}: {1:.3f} -> {2:.3f} in {3:.2f} sec, gini={4:.3f}, accur={5:.3f}'.format(n, l0, l1, t1-t0, gini, accur))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "1. tfidf-1000 => 72.1% gini, 78.0% accuracy\n",
    "2. tfidf-300 => 66.4% gini, 75.3% accuracy\n",
    "3. tfidf-100 => 61.9% gini, 73.5% accuracy\n",
    "4. virtual-tfidf-5000 => "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
