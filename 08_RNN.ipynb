{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_over_dirs(pth, fun, y):\n",
    "    for x in os.listdir(pth):\n",
    "        xf = pth + x\n",
    "        if os.path.isdir(xf):\n",
    "            y = iterate_over_dirs(xf + '/', fun, y)\n",
    "        elif os.path.isfile(xf):\n",
    "            y = fun(y, xf)\n",
    "    return y\n",
    "\n",
    "def sample_corpora(files, file_num=10):\n",
    "    ids = np.random.choice(len(files), size=file_num)\n",
    "    res = []\n",
    "    for i in ids:\n",
    "        with open(file=files[i], mode='rb') as f:\n",
    "            res += [f.read()]\n",
    "    return res\n",
    "\n",
    "def subsample_trunc_corpora(corpora, batch_num=100, batch_size=32):\n",
    "    data = np.random.choice(corpora, size=batch_num)\n",
    "    tmp = [(x, random.randint(0, len(x)-batch_size)) for x in data if len(x) >= batch_size]\n",
    "    return [x[i:(i+batch_size)] for (x,i) in tmp]\n",
    "    \n",
    "\n",
    "def gather_chars(files):\n",
    "    s = []\n",
    "    for fn in files:\n",
    "        with open(fn, 'rb') as f:\n",
    "            s = set(list(s) + [x for x in f.read()])\n",
    "    return list(s)\n",
    "\n",
    "def create_encoding(files, chars):\n",
    "    chars = gather_chars(files)\n",
    "    encoding = np.zeros((255, len(chars)), dtype=np.float32)\n",
    "    for i in range(len(chars)):\n",
    "        encoding[chars[i], i] = 1.0\n",
    "    return encoding\n",
    "\n",
    "def encode_file(file, encoding):\n",
    "    return np.array([encoding[int(i),:] for i in file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files = iterate_over_dirs('D:/Jupyter/Datasets/PaulGraham/', lambda y,x: y + [x], [])\n",
    "file_corpora = [x for x in all_files if os.path.splitext(x)[1] in ('.txt')]\n",
    "chars = gather_chars(file_corpora)\n",
    "encoding = create_encoding(file_corpora, chars)\n",
    "\n",
    "def next_batch(batch_num=50, batch_size=32, files_num=10):\n",
    "    texts = subsample_trunc_corpora(sample_corpora(all_files, files_num), batch_num, batch_size)\n",
    "    return np.array([encode_file(x, encoding) for x in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "(255, 95)\n"
     ]
    }
   ],
   "source": [
    "print(len(file_corpora))\n",
    "print(encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_units = 512\n",
    "num_layers = 10\n",
    "num_out = encoding.shape[1]\n",
    "\n",
    "def basic_cell():\n",
    "    return tf.contrib.rnn.BasicRNNCell(num_units=num_units, activation=tf.nn.relu)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfLength = tf.placeholder(shape=(None), dtype=tf.int32)\n",
    "tfSample = tf.placeholder(shape=(None, None, num_out), dtype=tf.float32)\n",
    "#tfRNN = tf.contrib.rnn.BasicRNNCell(num_units=num_units, activation=tf.nn.relu)\n",
    "#tfRNN = tf.nn.rnn_cell.GRUCell(num_units=num_units, activation=tf.nn.relu)\n",
    "#tfRNN0 = tf.contrib.rnn.BasicRNNCell(num_units=num_units, activation=tf.nn.relu)\n",
    "tfRNN  = tf.contrib.rnn.MultiRNNCell([basic_cell() for _ in range(num_layers)], state_is_tuple=True)\n",
    "\n",
    "tfTOut,_ = tf.nn.dynamic_rnn(tfRNN, inputs=tfSample, sequence_length=tfLength, dtype=tf.float32)\n",
    "\n",
    "tfTRes = tf.layers.dense(tfTOut, num_out, name='FNN')\n",
    "tfTW = tf.get_default_graph().get_tensor_by_name(os.path.split(tfTRes.name)[0] + '/kernel:0')\n",
    "tfTB = tf.get_default_graph().get_tensor_by_name(os.path.split(tfTRes.name)[0] + '/bias:0')\n",
    "\n",
    "tfLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tfSample[:,1:,:], logits=tfTRes[:,:-1,:]))\n",
    "\n",
    "#tfGenInput = tf.Variable(tf.zeros((1, num_out)), dtype=tf.float32)\n",
    "#tfGenState = tf.Variable(tf.zeros((1, num_units)), dtype=tf.float32)\n",
    "#tfOutput, tfNewState = tfRNN(inputs=tfGenInput, state=tfGenState)\n",
    "#tfOutputF = tf.matmul(tfOutput, tfTW) + tfTB\n",
    "#tfOutputP = tf.nn.softmax(tfOutputF)\n",
    "#tfNewInput = tf.one_hot(tf.multinomial(logits=tfOutputF, num_samples=1), depth=encoding.shape[1])\n",
    "\n",
    "#tfRunInit = tf.group(tf.assign(tfGenState, tf.zeros((1, num_units))), tf.assign(tfGenInput, tf.zeros((1, num_out))))\n",
    "#tfRunStep = tf.group(tf.assign(tfGenState, tfNewState), tf.assign(tfGenInput, tf.reshape(tfNewInput, (1, num_out))))\n",
    "\n",
    "tfTrain = tf.train.AdamOptimizer(1e-2).minimize(tfLoss)\n",
    "\n",
    "tfLossSummary = tf.summary.scalar('Loss', tfLoss)\n",
    "\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/TEST_RNN_{0}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")), tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5542 -> 56.921\n",
      "57.462 -> 4.0074\n",
      "3.971 -> 3.9858\n",
      "3.9055 -> 3.2575\n",
      "3.27 -> 3.2455\n",
      "3.3049 -> 3.2192\n",
      "3.1755 -> 3.1279\n",
      "3.161 -> 3.1493\n",
      "3.2191 -> 3.2015\n",
      "3.1324 -> 3.1231\n",
      "3.1697 -> 3.1601\n",
      "3.1803 -> 3.1691\n",
      "3.1728 -> 3.1658\n",
      "3.1749 -> 3.1677\n",
      "3.1725 -> 3.1613\n",
      "3.1793 -> 3.1709\n",
      "3.1929 -> 3.1814\n",
      "3.1774 -> 3.1698\n",
      "3.1188 -> 3.1134\n",
      "3.1416 -> 3.1322\n",
      "3.1679 -> 3.1581\n",
      "3.1654 -> 3.1551\n",
      "3.1669 -> 3.1505\n",
      "3.156 -> 3.1365\n",
      "3.1519 -> 3.0989\n",
      "3.1489 -> 3.0666\n",
      "3.0536 -> 3.0021\n",
      "3.0162 -> 2.8799\n",
      "2.9419 -> 2.865\n",
      "2.9112 -> 2.7965\n",
      "2.9248 -> 2.8304\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-9e6e386fcb67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstart_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#tfRunInit.run()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1704\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \"\"\"\n\u001b[1;32m-> 1706\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3961\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3963\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 5\n",
    "num_epochs = 200\n",
    "\n",
    "valid_corpora = next_batch(batch_num=1000)\n",
    "valid_batch = {tfSample: valid_corpora, tfLength: valid_corpora.shape[1]}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        batch = next_batch(batch_num=100, batch_size=32)\n",
    "        train_batch = {tfSample: batch, tfLength: batch.shape[1]}\n",
    "        start_loss = tfLoss.eval(feed_dict=train_batch)\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "            \n",
    "        #tfRunInit.run()\n",
    "        #res = []\n",
    "        #for k in range(20):\n",
    "        #    tfRunStep.run()\n",
    "        #    res += [np.argmax(tfOutputP.eval())]\n",
    "        \n",
    "        tffw.add_summary(tfLossSummary.eval(feed_dict=valid_batch), i)\n",
    "        print('{0:0.5} -> {1:0.5}'.format(start_loss, tfLoss.eval(feed_dict=train_batch)))\n",
    "        #if i%10 == 0:\n",
    "            #print(res)\n",
    "        #    print(''.join([chr(chars[x]) for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[3,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-630870e5c4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: randint() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
