{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObs(length, rr, key_length, startup_length, symbols):\n",
    "    x = ''.join(np.random.choice(symbols, size=startup_length))\n",
    "    for i in range(length - startup_length):\n",
    "        x = x + rr[x[-key_length:]]\n",
    "    return x\n",
    "\n",
    "def genRR(symbols, key_length):\n",
    "    prefixes = ['']\n",
    "    for i in range(key_length):\n",
    "        prefixes = [x + y for x in prefixes for y in symbols]\n",
    "    symarr = np.array(list(symbols))\n",
    "    return {x:np.random.choice(symarr) for x in prefixes}\n",
    "\n",
    "def genSample(num, rr, length=20, startup_length=5):\n",
    "    keylen = max([len(x) for x,_  in rr.items()])\n",
    "    symarr = np.array(list(set(''.join([x for x,_  in rr.items()]))))\n",
    "    return [genObs(length, rr, keylen, startup_length, symarr) for _ in range(num)]\n",
    "\n",
    "def randomBatch(tensor, batchSize=64):\n",
    "    if type(tensor) is tuple:\n",
    "        ids = np.random.choice(range(tensor[0].shape[0]), batchSize)\n",
    "        return (x[ids,] for x in tensor)\n",
    "    ids = np.random.choice(range(tensor.shape[0]), batchSize)\n",
    "    return tensor[ids,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr = genRR('01234567', 5)\n",
    "train0 = genSample(10000, rr)\n",
    "valid0 = genSample(2000, rr)\n",
    "train = np.array([np.array([int(y) for y in x]) for x in train0])\n",
    "valid = np.array([np.array([int(y) for y in x]) for x in valid0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 4, 6, 7, 4, 5, 4, 2, 2, 2, 1, 6, 2, 4, 2, 1, 3, 0, 6],\n",
       "       [3, 3, 6, 1, 6, 6, 4, 7, 3, 5, 3, 5, 5, 4, 6, 1, 5, 0, 0, 4],\n",
       "       [5, 7, 2, 5, 4, 4, 6, 2, 3, 4, 0, 2, 2, 0, 5, 7, 0, 5, 7, 7],\n",
       "       [6, 7, 1, 7, 3, 5, 1, 1, 0, 5, 7, 6, 0, 4, 3, 5, 5, 3, 2, 5],\n",
       "       [5, 0, 1, 0, 1, 6, 0, 5, 4, 7, 6, 4, 0, 6, 1, 2, 6, 0, 3, 0],\n",
       "       [1, 2, 0, 2, 3, 7, 7, 2, 6, 4, 0, 0, 3, 5, 3, 1, 3, 4, 4, 7],\n",
       "       [4, 3, 6, 5, 5, 1, 5, 2, 7, 4, 3, 1, 0, 1, 4, 1, 5, 5, 2, 1],\n",
       "       [6, 0, 3, 4, 2, 3, 4, 5, 3, 2, 3, 1, 6, 6, 1, 3, 7, 6, 3, 6],\n",
       "       [1, 7, 4, 0, 6, 2, 0, 3, 3, 4, 4, 2, 2, 4, 2, 7, 6, 2, 2, 3],\n",
       "       [3, 5, 6, 7, 0, 2, 7, 6, 3, 5, 3, 6, 7, 1, 7, 2, 2, 6, 7, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation complete\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "CHARSET_SIZE = 8\n",
    "RNN_SIZE = [50,50]\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "InnerCell = lambda n: tf.nn.rnn_cell.BasicRNNCell(num_units=n, activation=tf.nn.elu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.GRUCell(num_units=n, activation=tf.nn.relu)\n",
    "#InnerCell = lambda n: tf.nn.rnn_cell.LSTMCell(num_units=n, activation=tf.nn.relu, use_peepholes=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tfi_x = tf.placeholder(shape=(None, SEQ_LEN), dtype=tf.int32)\n",
    "\n",
    "tfX = tf.one_hot(tfi_x, CHARSET_SIZE, dtype=tf.float32)\n",
    "tfY = tfX[:,1:,:]\n",
    "\n",
    "rnnCell = tf.nn.rnn_cell.MultiRNNCell([InnerCell(s) for s in RNN_SIZE], state_is_tuple=True)\n",
    "#rnnCell = tf.nn.rnn_cell.GRUCell(RNN_SIZE[0], activation=tf.nn.elu)\n",
    "\n",
    "tfH, tfO = tf.nn.dynamic_rnn(rnnCell, inputs=tfX, dtype=tf.float32)\n",
    "\n",
    "tfHOut = tf.layers.dense(tfH, CHARSET_SIZE)\n",
    "\n",
    "\n",
    "with tf.name_scope('LOSS'):\n",
    "    tfDiff = tf.nn.softmax_cross_entropy_with_logits(labels=tfY, logits=tfHOut[:,:-1,:])\n",
    "    tfLoss = tf.reduce_mean(tfDiff[:,-10:], name='TRAIN-LOSS')\n",
    "    tfEqEw = tf.cast(tf.equal(tf.argmax(tf.nn.softmax(tfHOut[:,:-1,:],dim=2), axis=2), tf.argmax(tfY, axis=2)), dtype=tf.float32)\n",
    "    tfAccMax = tf.reduce_mean(tf.reduce_min(tfEqEw[:,-5:], axis=1), name='ACCURACY-OBS')\n",
    "    tfAccMean = tf.reduce_mean(tfEqEw[:,-5:], name='ACCURACY-SYM')\n",
    "    tfTrain = tf.train.AdamOptimizer(LEARNING_RATE).minimize(tfLoss)\n",
    "\n",
    "#tfOutP = tf.nn.softmax(tfOut)\n",
    "tfOutR = tf.argmax(tf.nn.softmax(tfHOut[:,:-1,:],dim=2), axis=2)\n",
    "\n",
    "#tfAccuracy = tf.reduce_mean(tf.cast(tf.equal(tfi_y, tfOutR), dtype=tf.float32))\n",
    "tffw = tf.summary.FileWriter('D:/Jupyter/Logs/00_A', tf.get_default_graph())\n",
    "print('Graph creation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.461 sec): loss changed from 2.16 to 2.04\t\tVL:2.07\t\tAC:0.169 (0.000)\n",
      "Epoch 1 (0.452 sec): loss changed from 2.06 to 2.02\t\tVL:2.06\t\tAC:0.184 (0.000)\n",
      "Epoch 2 (0.454 sec): loss changed from 2.06 to 2.02\t\tVL:2.05\t\tAC:0.187 (0.003)\n",
      "Epoch 3 (0.456 sec): loss changed from 2.04 to 2.01\t\tVL:2.05\t\tAC:0.193 (0.000)\n",
      "Epoch 4 (0.45 sec): loss changed from 2.04 to 2.0\t\tVL:2.04\t\tAC:0.199 (0.000)\n",
      "Epoch 5 (0.46 sec): loss changed from 2.04 to 2.01\t\tVL:2.03\t\tAC:0.202 (0.001)\n",
      "Epoch 6 (0.461 sec): loss changed from 2.04 to 2.0\t\tVL:2.03\t\tAC:0.213 (0.001)\n",
      "Epoch 7 (0.455 sec): loss changed from 2.02 to 1.98\t\tVL:2.02\t\tAC:0.219 (0.001)\n",
      "Epoch 8 (0.453 sec): loss changed from 2.02 to 1.98\t\tVL:2.01\t\tAC:0.230 (0.003)\n",
      "Epoch 9 (0.449 sec): loss changed from 2.0 to 1.95\t\tVL:2.00\t\tAC:0.240 (0.003)\n",
      "Epoch 10 (0.453 sec): loss changed from 1.99 to 1.93\t\tVL:1.98\t\tAC:0.253 (0.007)\n",
      "Epoch 11 (0.548 sec): loss changed from 1.97 to 1.9\t\tVL:1.97\t\tAC:0.265 (0.002)\n",
      "Epoch 12 (0.454 sec): loss changed from 1.94 to 1.86\t\tVL:1.96\t\tAC:0.268 (0.002)\n",
      "Epoch 13 (0.457 sec): loss changed from 1.95 to 1.86\t\tVL:1.94\t\tAC:0.290 (0.009)\n",
      "Epoch 14 (0.449 sec): loss changed from 1.92 to 1.84\t\tVL:1.92\t\tAC:0.303 (0.009)\n",
      "Epoch 15 (0.476 sec): loss changed from 1.91 to 1.83\t\tVL:1.91\t\tAC:0.320 (0.013)\n",
      "Epoch 16 (0.451 sec): loss changed from 1.89 to 1.79\t\tVL:1.88\t\tAC:0.338 (0.016)\n",
      "Epoch 17 (0.45 sec): loss changed from 1.85 to 1.75\t\tVL:1.87\t\tAC:0.345 (0.022)\n",
      "Epoch 18 (0.451 sec): loss changed from 1.84 to 1.73\t\tVL:1.85\t\tAC:0.353 (0.027)\n",
      "Epoch 19 (0.453 sec): loss changed from 1.82 to 1.71\t\tVL:1.82\t\tAC:0.366 (0.029)\n",
      "Epoch 20 (0.523 sec): loss changed from 1.8 to 1.69\t\tVL:1.80\t\tAC:0.388 (0.027)\n",
      "Epoch 21 (0.453 sec): loss changed from 1.76 to 1.65\t\tVL:1.78\t\tAC:0.403 (0.047)\n",
      "Epoch 22 (0.451 sec): loss changed from 1.75 to 1.63\t\tVL:1.75\t\tAC:0.422 (0.041)\n",
      "Epoch 23 (0.582 sec): loss changed from 1.73 to 1.61\t\tVL:1.74\t\tAC:0.434 (0.047)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4cb729d4c8f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mlv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfAccMean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfAccMax\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#if i % 10 == 0 and i > 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_steps  = 5\n",
    "num_epochs = 200\n",
    "\n",
    "valid_batch = {tfi_x: valid}\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epochs):\n",
    "        mini = randomBatch(train, batchSize=batch_size)\n",
    "        train_batch = {tfi_x:mini}\n",
    "        l0 = tfLoss.eval(feed_dict=train_batch)\n",
    "        t0 = time.perf_counter()\n",
    "        for j in range(num_steps):\n",
    "            tfTrain.run(feed_dict=train_batch)\n",
    "        t1 = time.perf_counter()\n",
    "        l1 = tfLoss.eval(feed_dict=train_batch)\n",
    "        lv, ac, acm = tfs.run([tfLoss, tfAccMean, tfAccMax], feed_dict=valid_batch)\n",
    "        \n",
    "        #if i % 10 == 0 and i > 0:\n",
    "        #    print(tfOutR.eval(feed_dict=valid_batch)[:10] - valid[:10,1:])\n",
    "        \n",
    "        print('Epoch {0} ({1:1.3} sec): loss changed from {2:1.3} to {3:1.3}\\t\\tVL:{4:1.2f}\\t\\tAC:{5:1.3f} ({6:1.3f})'.format(i,t1-t0,l0,l1,lv,ac, acm))\n",
    "    #valid_r = tfs.run(tfOutR, feed_dict=valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 2, 5, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 2, 2, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [5, 4, 2, 3, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 2, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 3, 1, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [4, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 3, 5, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 3, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 3, 4, 3, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
